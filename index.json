[{"categories":[],"content":"标题Markdown支持6种级别的标题，对应html标签 h1 ~ h6 # 一级标题 ## 二级标题 ### 三级标题 #### 四级标题 ##### 五级标题 ###### 六级标题 ","date":"2023-07-19","objectID":"/markdown/:1:0","series":null,"tags":[],"title":"Markdown语法","uri":"/markdown/#标题"},{"categories":[],"content":"链接或图片 插入链接：[点击跳转到百度](http://www.baidu.com) 插入图片：![图片](https://imgconvert.csdnimg.cn/aHR0cHM6Ly93d3cuYmFpZHUuY29tL2ltZy9iZF9sb2dvMS5wbmc) 效果： 点击跳转到百度 ","date":"2023-07-19","objectID":"/markdown/:2:0","series":null,"tags":[],"title":"Markdown语法","uri":"/markdown/#链接或图片"},{"categories":[],"content":"列表 无序列表用 - 标识 有序列表用 1. 标识 - 无序列表1 - 无序列表2 1. 有序列表1 2. 有序列表2 效果： 无序列表1 无序列表2 有序列表1 有序列表2 ","date":"2023-07-19","objectID":"/markdown/:3:0","series":null,"tags":[],"title":"Markdown语法","uri":"/markdown/#列表"},{"categories":[],"content":"引用 \u003e 引用段落 引用段落 ","date":"2023-07-19","objectID":"/markdown/:4:0","series":null,"tags":[],"title":"Markdown语法","uri":"/markdown/#引用"},{"categories":[],"content":"嵌套 \u003e 这段文字将被高亮显示... \u003e\u003e 这段文字将被高亮显示... \u003e\u003e\u003e 这段文字将被高亮显示... \u003e\u003e\u003e\u003e 这段文字将被高亮显示... 以此类推 - 列表嵌套引用段 \u003e 引用 \u003e\u003e 引用 \u003e 引用段嵌套列表 \u003e - 嵌套列表 \u003e - 嵌套列表 效果： 这段文字将被高亮显示… 这段文字将被高亮显示… 这段文字将被高亮显示… 这段文字将被高亮显示… 以此类推 列表嵌套引用段 引用 引用 引用段嵌套列表 嵌套列表 嵌套列表 ","date":"2023-07-19","objectID":"/markdown/:4:1","series":null,"tags":[],"title":"Markdown语法","uri":"/markdown/#嵌套"},{"categories":[],"content":"分割线三个***，或者— 效果： ","date":"2023-07-19","objectID":"/markdown/:5:0","series":null,"tags":[],"title":"Markdown语法","uri":"/markdown/#分割线"},{"categories":[],"content":"文本强调加粗、斜体、高亮标记、删除线 *这里是斜体* _这里是斜体_ **这里是加粗** __这里是加粗__ ==这里是标记== ~~这里是删除~~ 效果： 这里是斜体 这里是斜体 这里是加粗 这里是加粗 ==这里是标记== 这里是删除 ","date":"2023-07-19","objectID":"/markdown/:6:0","series":null,"tags":[],"title":"Markdown语法","uri":"/markdown/#文本强调"},{"categories":[],"content":"复选框复选框也可以叫任务列表，有完成和未完成的状态（打钩和空白）。 在无序列表符号后面加上[]或者[x]代表选中或者未选中情况。 - [ ] 任务一 - [x] 任务二 任务一 任务二 ","date":"2023-07-19","objectID":"/markdown/:7:0","series":null,"tags":[],"title":"Markdown语法","uri":"/markdown/#复选框"},{"categories":[],"content":"代码行内代码：用一个或两个反引号`包裹 `行内代码` 代码段：用3个反引号`包裹 ```代码段``` 代码段 ```代码段``` ","date":"2023-07-19","objectID":"/markdown/:8:0","series":null,"tags":[],"title":"Markdown语法","uri":"/markdown/#代码"},{"categories":[],"content":"表格 表头|条目一|条目二 :---:|:---:|:---: 项目|项目一|项目二 三个短斜杠左右的冒号用于控制对齐方式，只放置左边冒号表示文字居左，只放置右边冒号表示文字居右，如果两边都放置冒号表示文字居中。 表头 条目一 条目二 项目 项目一 项目二 ","date":"2023-07-19","objectID":"/markdown/:9:0","series":null,"tags":[],"title":"Markdown语法","uri":"/markdown/#表格"},{"categories":[],"content":"特殊符号处理在内容中输入以下特殊符号的时候一定要注意转义，否则将导致内容显示不全，甚至排版混乱。使用 \\ 进行转义处理。 \\ 反斜线 ` 反引号 * 星号 _ 底线 {} 花括号 [] 方括号 () 括弧 # 井字号 + 加号 - 减号 . 英文句点 ! 惊叹号 ","date":"2023-07-19","objectID":"/markdown/:10:0","series":null,"tags":[],"title":"Markdown语法","uri":"/markdown/#特殊符号处理"},{"categories":[],"content":"字体颜色、大小 \u003cfont face=\"黑体\"\u003e我是黑体字\u003c/font\u003e \u003cfont face=\"微软雅黑\"\u003e我是微软雅黑\u003c/font\u003e \u003cfont face=\"STCAIYUN\"\u003e我是华文彩云\u003c/font\u003e \u003cfont color=red\u003e我是红色\u003c/font\u003e \u003cfont color=#008000\u003e我是绿色\u003c/font\u003e \u003cfont color=Blue\u003e我是蓝色\u003c/font\u003e \u003cfont size=5\u003e我是尺寸\u003c/font\u003e \u003cfont face=\"黑体\" color=green size=5\u003e我是黑体，绿色，尺寸为5\u003c/font\u003e 我是黑体字 我是微软雅黑 我是华文彩云 我是红色 我是绿色 我是蓝色 我是尺寸 我是黑体，绿色，尺寸为5 ","date":"2023-07-19","objectID":"/markdown/:11:0","series":null,"tags":[],"title":"Markdown语法","uri":"/markdown/#字体颜色大小"},{"categories":[],"content":"流程图 graph TD A[A] --\u003e B[B] ","date":"2023-07-19","objectID":"/markdown/:12:0","series":null,"tags":[],"title":"Markdown语法","uri":"/markdown/#流程图"},{"categories":[],"content":"记录如何在客户端，服务端解密https抓包数据。 ","date":"2023-02-13","objectID":"/https-packet-capture/:0:0","series":null,"tags":[],"title":"Https 抓包-密文转明文","uri":"/https-packet-capture/#"},{"categories":[],"content":"前言 在我们日常工作中，经常需要抓包分析各种异常的网络常见。http是网络常见中最常见的一种，随着https的普及，我们生产环境中，大部分都为https的网站。而https所有的交互数据都是经过加密的。 ","date":"2023-02-13","objectID":"/https-packet-capture/:1:0","series":null,"tags":[],"title":"Https 抓包-密文转明文","uri":"/https-packet-capture/#前言"},{"categories":[],"content":"概述 https的核心原理并不复杂，通过非对称加密传递密钥，然后拿这个密钥通过对称加密传递密文数据。 tls1.2原理简单点，通过客户端随机数，服务端随机数，以及预主密钥生成主密钥，然后通过主密钥加密数据。所以tls1.2版本中，我们只要知道了主密钥，就能解密数据。 tls1.3更复杂点，需要的密钥更多。具体原理可以查看这篇文章了解：https://halfrost.com/https-key-cipher/。 其实，无论原理如何，我们作为使用方，解密明文数据其实很简单，主要分为两个过程： 记录密钥日志，抓取数据包 在wireshark中导入密钥日志，打开抓取的数据包即可。 记录密钥这个功能，想起来可以比较复杂，其实大部分使用tls的软件，库都是有记录密钥功能的。是一个通用的功能，一般通过SSLKEYLOGFILE这个环境变量，设置记录密钥的日志文件。 详细内容可参考：https://firefox-source-docs.mozilla.org/security/nss/legacy/key_log_format/index.html 。下面我们通过多个方面说明，如何记录密钥，使用密钥。 ","date":"2023-02-13","objectID":"/https-packet-capture/:2:0","series":null,"tags":[],"title":"Https 抓包-密文转明文","uri":"/https-packet-capture/#概述"},{"categories":[],"content":"如何获取密钥？","date":"2023-02-13","objectID":"/https-packet-capture/:3:0","series":null,"tags":[],"title":"Https 抓包-密文转明文","uri":"/https-packet-capture/#如何获取密钥"},{"categories":[],"content":"Windows环境添加用户环境变量 添加完之后，我们的windows电脑就以及打开了密钥记录功能。我们重启浏览器，访问https://www.baidu.com/ 后，查看D:\\ssl.log文件内容，就会发现密钥以及记录到文件中了。 wireshark中导入密钥 点击编辑-\u003e首选项 -\u003e protocol 在Protocols 标签下，找到TLS标签，旧版本可能是SSL标签 将密钥日志地址填入(Pre)-Master-Secret log filename中。然后点击ok保存。 输入过滤条件,比如我们要抓取www.baidu.com这个网站的数据包。我们就在过滤器输入框中填入：host www.baidu.com。 查看抓包内容，跟踪其中一条流，我们就会发现其中有tls的握手包，通过我们可以看到此条https请求，访问的是根路径。说明我们解密数据包已完成。 ","date":"2023-02-13","objectID":"/https-packet-capture/:3:1","series":null,"tags":[],"title":"Https 抓包-密文转明文","uri":"/https-packet-capture/#windows环境"},{"categories":[],"content":"Windows环境添加用户环境变量 添加完之后，我们的windows电脑就以及打开了密钥记录功能。我们重启浏览器，访问https://www.baidu.com/ 后，查看D:\\ssl.log文件内容，就会发现密钥以及记录到文件中了。 wireshark中导入密钥 点击编辑-首选项 - protocol 在Protocols 标签下，找到TLS标签，旧版本可能是SSL标签 将密钥日志地址填入(Pre)-Master-Secret log filename中。然后点击ok保存。 输入过滤条件,比如我们要抓取www.baidu.com这个网站的数据包。我们就在过滤器输入框中填入：host www.baidu.com。 查看抓包内容，跟踪其中一条流，我们就会发现其中有tls的握手包，通过我们可以看到此条https请求，访问的是根路径。说明我们解密数据包已完成。 ","date":"2023-02-13","objectID":"/https-packet-capture/:3:1","series":null,"tags":[],"title":"Https 抓包-密文转明文","uri":"/https-packet-capture/#wireshark中导入密钥"},{"categories":[],"content":"Linux系统客户端 curl 也是通过设置SSLKEYLOGFILE环境变量记录密钥日志的。比如： 添加环境变量：$ export SSLKEYLOGFILE=/tmp/ssl.log 访问：$ curl https://www.baidu.com 我们还可以选择tls的版本,比如 tls1.2： $ curl --tlsv1.2 https://www.baidu.com 查看ssl.log文件，发现密钥日志文件只有一行密钥内容。第一列是标签，tls1.2中就是客户端随机数。第二列就是客户端随机数。一次会话中客户端的随机数是固定的。所以，一般会用第二列标识会话。第二列相同就是同一个会话。第三列就是密钥了。在tls1.2中就是主密钥。 $ cat /tmp/ssl.log # SSL/TLS secrets log file, generated by NSS CLIENT_RANDOM 1b152f16c50cae5bcae6845dc1190e2b66d2ce5dfdcbcc3c59371911290aab08 dbc10f1d8ba7ee7b0cc6abc80ce51c2707cd547fa59e04810b2eabd455c59953430b53a06318e3ea9f946cfd4bbf0355 我们把tls版本切换为tls1.3: $ curl --tlsv1.3 [https://www.baidu.com](https://www.baidu.com) 再次查看密钥文件,就会发现多了几行，这是tls1.3 版本的https在整个协议过程中，需要用到的密钥，比较多。当然，我们仅仅是使用的话，不用过分深究。 CLIENT_RANDOM 1695f088e0d89b5fd878799216638024a2ec2beac41ce6b62eefcae03f64fd18 49301b8e74869d647449177a4fe38a70632f72290dbad620de5f8f056e88789cf99fee2ee328c7e4cd0e06491ff835d9 CLIENT_HANDSHAKE_TRAFFIC_SECRET 212a11025b3beb91bf6b155053df0fd810ccf87fe0aa9f77a96aabfba904e85d 9dba8701d6610613fc33d803117a31d74b9b586e7e122442d8703558a7af2d3599ad3e3f282def968d782e1ba0c80af1 SERVER_HANDSHAKE_TRAFFIC_SECRET 212a11025b3beb91bf6b155053df0fd810ccf87fe0aa9f77a96aabfba904e85d 909915c792f5d8f831540b878d39c8aba37ef1b7562f512a0bc58c99fe91951a1cb617ab7b62f9d712ae43b330cf2888 CLIENT_TRAFFIC_SECRET_0 212a11025b3beb91bf6b155053df0fd810ccf87fe0aa9f77a96aabfba904e85d 0d6ebd5ace7d3a98fee708b6ef8a49806e723cceccfb6460b28b905a3941f4c59ba254ba6536776ac5080304b8e75156 SERVER_TRAFFIC_SECRET_0 212a11025b3beb91bf6b155053df0fd810ccf87fe0aa9f77a96aabfba904e85d eac9be50abd2489cea9f6b9cb1ca382e0a75a23e6df4a2d5f04e2d350806507e43f1cb2d940c266d4e7edc260bf0e6ea EXPORTER_SECRET 212a11025b3beb91bf6b155053df0fd810ccf87fe0aa9f77a96aabfba904e85d 389bf874068ab12d872a4da94703150fac9255c9d4c5dc1abda242df9197c840746d94e5af220fe215c6a909e582ff98 我们可以查看curl的文档：https://everything.curl.dev/usingcurl/tls/sslkeylogfile， 其实并不是说curl自己实现了密钥日志文件记录，而且利用各种ssl库，比如openssl。这些库本身提供了记录密钥日志文件的功能。 这句话很重要后面会考。 ","date":"2023-02-13","objectID":"/https-packet-capture/:3:2","series":null,"tags":[],"title":"Https 抓包-密文转明文","uri":"/https-packet-capture/#linux系统客户端"},{"categories":[],"content":"Linux系统服务端作为sre，其实我们大部分接触的反而是服务器，我们知道，客户端和服务器能通过密文传递数据，既然客户端都能获取密钥。那是否服务端也能呢？答案是显而易见的。 在生产环境中，我们常常使用nginx做反向代理，并让其代理tls。那我们如何在nginx中记录密钥文件呢。主要有以下思路： 1. Nginx模块比如：https://github.com/tiandrey/nginx-sslkeylog。 我们在编译nginx的时候，把这个开源库编译进nginx。nginx就可以通过访问日志的记录形式，记录tls密钥。我测试了tlsv1.2 ，因为会记录client 随机数和主密钥，所以是可以使用的。tlsv1.3的话，感觉其提供的数据不足，估计不太行。 2. wireshark提供的库代码地址如下：https://git.lekensteyn.nl/peter/wireshark-notes/tree/src/sslkeylog.c 操作如下： https://security.stackexchange.com/questions/216065/extracting-openssl-pre-master-secret-from-nginx 当然，我没侧出来。 原理如下： LD_PRELOAD这是共享库的标准的环境变量，LD_PRELOAD指定的共享库中的函数会覆盖nginx依赖的openssl共享库中的函数。 也就是sslkeylog.c中的函数会把openssl中的函数覆盖掉，从而达到改写共享库中某几个函数而不影响其他函数的目的。 3. ecapture此抓包软件，通过ebpf实现。通过ebpf在程序或库中注入，数据处理的ebpf代码。直接在用户态抓取数据包。 此工具我倒是没测试过，因为ebpf比内核版本是有要求的，比如：linux内核4.18。而我们常用的centos7的内核版本是3.10。 ","date":"2023-02-13","objectID":"/https-packet-capture/:3:3","series":null,"tags":[],"title":"Https 抓包-密文转明文","uri":"/https-packet-capture/#linux系统服务端"},{"categories":[],"content":"Linux系统服务端作为sre，其实我们大部分接触的反而是服务器，我们知道，客户端和服务器能通过密文传递数据，既然客户端都能获取密钥。那是否服务端也能呢？答案是显而易见的。 在生产环境中，我们常常使用nginx做反向代理，并让其代理tls。那我们如何在nginx中记录密钥文件呢。主要有以下思路： 1. Nginx模块比如：https://github.com/tiandrey/nginx-sslkeylog。 我们在编译nginx的时候，把这个开源库编译进nginx。nginx就可以通过访问日志的记录形式，记录tls密钥。我测试了tlsv1.2 ，因为会记录client 随机数和主密钥，所以是可以使用的。tlsv1.3的话，感觉其提供的数据不足，估计不太行。 2. wireshark提供的库代码地址如下：https://git.lekensteyn.nl/peter/wireshark-notes/tree/src/sslkeylog.c 操作如下： https://security.stackexchange.com/questions/216065/extracting-openssl-pre-master-secret-from-nginx 当然，我没侧出来。 原理如下： LD_PRELOAD这是共享库的标准的环境变量，LD_PRELOAD指定的共享库中的函数会覆盖nginx依赖的openssl共享库中的函数。 也就是sslkeylog.c中的函数会把openssl中的函数覆盖掉，从而达到改写共享库中某几个函数而不影响其他函数的目的。 3. ecapture此抓包软件，通过ebpf实现。通过ebpf在程序或库中注入，数据处理的ebpf代码。直接在用户态抓取数据包。 此工具我倒是没测试过，因为ebpf比内核版本是有要求的，比如：linux内核4.18。而我们常用的centos7的内核版本是3.10。 ","date":"2023-02-13","objectID":"/https-packet-capture/:3:3","series":null,"tags":[],"title":"Https 抓包-密文转明文","uri":"/https-packet-capture/#1-nginx模块"},{"categories":[],"content":"Linux系统服务端作为sre，其实我们大部分接触的反而是服务器，我们知道，客户端和服务器能通过密文传递数据，既然客户端都能获取密钥。那是否服务端也能呢？答案是显而易见的。 在生产环境中，我们常常使用nginx做反向代理，并让其代理tls。那我们如何在nginx中记录密钥文件呢。主要有以下思路： 1. Nginx模块比如：https://github.com/tiandrey/nginx-sslkeylog。 我们在编译nginx的时候，把这个开源库编译进nginx。nginx就可以通过访问日志的记录形式，记录tls密钥。我测试了tlsv1.2 ，因为会记录client 随机数和主密钥，所以是可以使用的。tlsv1.3的话，感觉其提供的数据不足，估计不太行。 2. wireshark提供的库代码地址如下：https://git.lekensteyn.nl/peter/wireshark-notes/tree/src/sslkeylog.c 操作如下： https://security.stackexchange.com/questions/216065/extracting-openssl-pre-master-secret-from-nginx 当然，我没侧出来。 原理如下： LD_PRELOAD这是共享库的标准的环境变量，LD_PRELOAD指定的共享库中的函数会覆盖nginx依赖的openssl共享库中的函数。 也就是sslkeylog.c中的函数会把openssl中的函数覆盖掉，从而达到改写共享库中某几个函数而不影响其他函数的目的。 3. ecapture此抓包软件，通过ebpf实现。通过ebpf在程序或库中注入，数据处理的ebpf代码。直接在用户态抓取数据包。 此工具我倒是没测试过，因为ebpf比内核版本是有要求的，比如：linux内核4.18。而我们常用的centos7的内核版本是3.10。 ","date":"2023-02-13","objectID":"/https-packet-capture/:3:3","series":null,"tags":[],"title":"Https 抓包-密文转明文","uri":"/https-packet-capture/#2-wireshark提供的库"},{"categories":[],"content":"Linux系统服务端作为sre，其实我们大部分接触的反而是服务器，我们知道，客户端和服务器能通过密文传递数据，既然客户端都能获取密钥。那是否服务端也能呢？答案是显而易见的。 在生产环境中，我们常常使用nginx做反向代理，并让其代理tls。那我们如何在nginx中记录密钥文件呢。主要有以下思路： 1. Nginx模块比如：https://github.com/tiandrey/nginx-sslkeylog。 我们在编译nginx的时候，把这个开源库编译进nginx。nginx就可以通过访问日志的记录形式，记录tls密钥。我测试了tlsv1.2 ，因为会记录client 随机数和主密钥，所以是可以使用的。tlsv1.3的话，感觉其提供的数据不足，估计不太行。 2. wireshark提供的库代码地址如下：https://git.lekensteyn.nl/peter/wireshark-notes/tree/src/sslkeylog.c 操作如下： https://security.stackexchange.com/questions/216065/extracting-openssl-pre-master-secret-from-nginx 当然，我没侧出来。 原理如下： LD_PRELOAD这是共享库的标准的环境变量，LD_PRELOAD指定的共享库中的函数会覆盖nginx依赖的openssl共享库中的函数。 也就是sslkeylog.c中的函数会把openssl中的函数覆盖掉，从而达到改写共享库中某几个函数而不影响其他函数的目的。 3. ecapture此抓包软件，通过ebpf实现。通过ebpf在程序或库中注入，数据处理的ebpf代码。直接在用户态抓取数据包。 此工具我倒是没测试过，因为ebpf比内核版本是有要求的，比如：linux内核4.18。而我们常用的centos7的内核版本是3.10。 ","date":"2023-02-13","objectID":"/https-packet-capture/:3:3","series":null,"tags":[],"title":"Https 抓包-密文转明文","uri":"/https-packet-capture/#3-ecapture"},{"categories":[],"content":"uprobe 题外话: 作为一名sre，我们最常用的排查故障的方法是什么？监控，日志，抓包。监控数据是宏观的，日志能不能记录到错误信息，全凭开发的经验。哪怕开发记录了日志，也不一定与错误信息相关。最好的情况可能就是，错误能在线下复现，通过gdb等调试工具排错。要是只能在生产复现，生产又不能随随便便更新呢。uprobe，kprobe以及后来的ebpf就登场了。 uprobe相关的内容可以查看文档：https://www.kernel.org/doc/html/latest/trace/uprobetracer.html 其实uprobe的原理很简单，我们都知道，我们编译后的程序其实都是汇编程序，一堆汇编指令。uprobe就是可以在这对汇编指令中插入其他的指令。比如我们在bash命令的readline函数入口出，插入uprobe，每当bash命令执行到readline函数时，会先执行uprobe，然后才会执行readline函数本身。除了函数的开始，我们还能在函数的返回处插入uprobe。当程序，比如bash，执行到readline处时，我们就可以获取到此时的函数参数。其实本质上上寄存器，以及内存中的值。比如函数的第一个参数保存在rdi这个寄存器中，第二个保存在rsi这个寄存器中，后面就是rdx、rcx、r8、r9等等。详细介绍可参考：https://cclinuxer.github.io/2021/04/Linux-kprobe%E5%B7%A5%E5%85%B7%E6%B7%B1%E5%BA%A6%E4%BD%BF%E7%94%A8/ 所以，只要我们找到处理ssl的函数，在函数入口处插入uprobe，在找到保存各种密钥的对象，将其输出出来。就可以获取到密钥信息，解析https密文了。 总体过程较为繁琐，如下所示： ","date":"2023-02-13","objectID":"/https-packet-capture/:4:0","series":null,"tags":[],"title":"Https 抓包-密文转明文","uri":"/https-packet-capture/#uprobe"},{"categories":[],"content":"1. 找处理ssl的函数前文我们以及说过，openssl这种常用的库，都提供了记录密钥日志文件的功能。只要我们找到了记录密钥的函数，是不是通过探测它就可以获取密钥了？ 密钥记录函数如下所示： int ssl_log_secret(SSL *ssl, const char *label, const uint8_t *secret, size_t secret_len) ssl的加密过程主要在tls13_change_cipher_state函数中，我们通过查看此函数，如下所示：在tls的各种状态中，都会执行ssl_log_secret函数，并不会先判断环境变量再执行。所以哪怕我们没开启密钥日志记录功能，此函数也会执行。 if (!tls13_hkdf_expand(s, md, insecret, early_exporter_master_secret, sizeof(early_exporter_master_secret) - 1, hashval, hashlen, s-\u003eearly_exporter_master_secret, hashlen, 1)) { SSLfatal(s, SSL_AD_INTERNAL_ERROR, SSL_F_TLS13_CHANGE_CIPHER_STATE, ERR_R_INTERNAL_ERROR); goto err; } if (!ssl_log_secret(s, EARLY_EXPORTER_SECRET_LABEL, s-\u003eearly_exporter_master_secret, hashlen)) { /* SSLfatal() already called */ goto err; } ","date":"2023-02-13","objectID":"/https-packet-capture/:4:1","series":null,"tags":[],"title":"Https 抓包-密文转明文","uri":"/https-packet-capture/#1-找处理ssl的函数"},{"categories":[],"content":"2. 分析函数此函数有四个参数，第一个参数是ssl对象，ssl对象里会保存客户端，服务端的随机数。第二个参数label，就是密钥日志文件的第一列，密钥标签。第三个参数secret,就是我们需要的密钥。第四个参数secret_len就是就是密钥的长度。 所以，这四个参数我们都是构成密钥日志文件的重要组成部分。 (SSL ssl, const char label, const uint8_t *secret, size_t secret_len) ","date":"2023-02-13","objectID":"/https-packet-capture/:4:2","series":null,"tags":[],"title":"Https 抓包-密文转明文","uri":"/https-packet-capture/#2-分析函数"},{"categories":[],"content":"3. 解析参数要是了解uprobe的话就知道，ssl对象的指针保存再rdi这个寄存器中，label对象的指针保存在rsi这个寄存器中，secret的指针保存rdx这个寄存器中，secret_len的值保存在rcx寄存器中。 我们由简单到复杂进行说明，如何解析这些参数。 secret_len最简单，因为保存的时值，uprobe可以直接读取。所以就是： secret_len=%cx （在uprobe表达式中，我们一般不带r，直接把寄存器记做di,si,dx,cx等） label 作为字符串指针也简单，%cx 保存这label指针，uprobe中通过+偏移量圆括号形式： +0() 将指针解析成地址。比如+0(%cx):string, +0 表示我们要读取(%cx)这个地址偏移量为0的地址，:string 表示我们要从+0(%cx)这个地址中读取字符串。所以解析label这个参数就是： label=+0(%cx):string secret 是一个子节数组，暂且我们通过u64 无符号整型进行解析。即为：secret1=+0(%dx):u64 ","date":"2023-02-13","objectID":"/https-packet-capture/:4:3","series":null,"tags":[],"title":"Https 抓包-密文转明文","uri":"/https-packet-capture/#3-解析参数"},{"categories":[],"content":"4. 从ssl对象中获取client_random对象其实使用多个成员变量组成，由于子节对齐的原因，我们很难通过计算得出对象的某个成员变量相对这个对象的偏移量。其实一个c 对象的值就是一个定长的子节数组。第一个成员变量的地址为 对象的地址+偏移量0 的地址。第二个成员变量的地址为 对象的地址+第一个对象的字节长度 的地址，第三个 成员变量的地址就是 对象的地址+第一个对象的子节长度+第二个对象的子节长度+子节对齐的长度。 如果没有子节对齐，其实我们很容器计算出对象某个成员，相对于对象的偏移量。从而得到成员的地址。但是一定会存在子节对齐，所以获取某个成员的地址，颇为复杂。 debuginfo主要保存的是程序的元数据，比如符号表等。我们可以使用gdb解析包含debuginfo的程序。就可以很容易的获取成员的偏移。 编译带debug信息libssl.so系统内的openssl库是不带符号表的。nginx主要依赖libssl.so这个库。我们可以通过包管理工具安装debuginfo包。因为openssl本身编译比较简单。所以我们直接编译带debug信息的libss.so // centos7系统 // 检查nginx依赖的openssl版本 $ nginx -V 2\u003e\u00261 |grep SSL built with OpenSSL 1.1.1k FIPS 25 Mar 2021 // 安装编译环境 $ yum install -y wget tar make gcc perl pcre-devel zlib-devel // 下载对应版本的openssl $ wget https://www.openssl.org/source/old/1.1.1/openssl-1.1.1k.tar.gz --no-check-certificate // 解压 $ tar -xf openssl-1.1.1k.tar.gz cd openssl-1.1.1k // -d选项就是带debuginfo的编译配置 $ ./config -d --prefix=/usr/local/ssl --openssldir=/usr/local/ssl -Wl,-rpath,/usr/local/ssl/lib shared make gdb查看ssl对象 // 执行gdb gdb libssl.so.1.1 // 通过ptype 命令查看 ssl对象，ssl结构体的定义名为：struct ssl_st // 输出信息中，第一列为成员相对于结构体的偏移量，第二列为成员的大小，第三列就是成员的源码。 // 注意偏移量为 168 的对象：struct ssl3_state_st *s3; // client_random 其实是保存在struct ssl3_state_st 结构体中。 (gdb) ptype /o struct ssl_st /* offset | size */ type = struct ssl_st { /* 0 | 4 */ int version; /* XXX 4-byte hole */ /* 8 | 8 */ const SSL_METHOD *method; /* 16 | 8 */ BIO *rbio; /* 24 | 8 */ BIO *wbio; /* 32 | 8 */ BIO *bbio; /* 40 | 4 */ int rwstate; /* XXX 4-byte hole */ /* 48 | 8 */ int (*handshake_func)(SSL *); /* 56 | 4 */ int server; /* 60 | 4 */ int new_session; /* 64 | 4 */ int quiet_shutdown; /* 68 | 4 */ int shutdown; /* 72 | 60 */ OSSL_STATEM statem; /* 132 | 4 */ SSL_EARLY_DATA_STATE early_data_state; /* 136 | 8 */ BUF_MEM *init_buf; /* 144 | 8 */ void *init_msg; /* 152 | 8 */ size_t init_num; /* 160 | 8 */ size_t init_off; /* 168 | 8 */ struct ssl3_state_st *s3; /* 176 | 8 */ struct dtls1_state_st *d1; /* 184 | 8 */ void (*msg_callback)(int, int, int, const void *, size_t, SSL *, void *); /* 192 | 8 */ void *msg_callback_arg; /* 200 | 4 */ int hit; /* XXX 4-byte hole */ /* 208 | 8 */ X509_VERIFY_PARAM *param; /* 216 | 64 */ SSL_DANE dane; /* 280 | 8 */ struct stack_st_SSL_CIPHER *peer_ciphers; /* 288 | 8 */ struct stack_st_SSL_CIPHER *cipher_list; /* 296 | 8 */ struct stack_st_SSL_CIPHER *cipher_list_by_id; /* 304 | 8 */ struct stack_st_SSL_CIPHER *tls13_ciphersuites; // 我们继续通过pteyp命令查看 struct ssl3_state_st 结构体。 // 偏移量为 184的位置就是我们需要的client_random (gdb) ptype /o struct ssl3_state_st /* offset | size */ type = struct ssl3_state_st { /* 0 | 8 */ long flags; /* 8 | 8 */ size_t read_mac_secret_size; /* 16 | 64 */ unsigned char read_mac_secret[64]; /* 80 | 8 */ size_t write_mac_secret_size; /* 88 | 64 */ unsigned char write_mac_secret[64]; /* 152 | 32 */ unsigned char server_random[32]; /* 184 | 32 */ unsigned char client_random[32]; /* 216 | 4 */ int need_empty_fragments; /* 220 | 4 */ int empty_fragment_done; /* 224 | 8 */ BIO *handshake_buffer; /* 232 | 8 */ EVP_MD_CTX *handshake_dgst; /* 240 | 4 */ int change_cipher_spec; /* 244 | 4 */ int warn_alert; /* 248 | 4 */ int fatal_alert; /* 252 | 4 */ int alert_dispatch; /* 256 | 2 */ unsigned char send_alert[2]; /* XXX 2-byte hole */ /* 260 | 4 */ int renegotiate; /* 264 | 4 */ int total_renegotiations; /* 268 | 4 */ int num_renegotiations; /* 272 | 4 */ int in_read_app_data; 找到了我们需要的成员，uprobe表达式改如何写呢?,我们这样写：client_random=+192(+168(%di)):u64 di 寄存器就是ssl_log_secret函数的第一个参数。保存的是对象ssl的地址。 +168(%di)：就是相对 struct ssl_st 这个结构体的地址偏移168的位置，此位置是一个结构体地址：struct ssl3_state_st *s3; +192(+168(%di)):u64： 再次通过圆括号对上面的地址进行解析，就是相对于 struct ssl3_state_st这个地址偏移量192的位置。此位置是一个字符数组。然后我们通过u64，无符号整型保存。 构造uprobe表达式uprobe的表达式如下所示： ‘p:/usr/lib64/libssl.so.1.1:ssl_log_secret lable=+0(%si):string client_random=+184(+168(%di)):u64 secret=+0(%dx):u64 secret_len=%cx’ 其中 p 表示，探测函数入口。 /usr/lib64/libssl.so.1.1 为我们要探测是进程的地址。 ssl_log_secret 就是我们要探测是函数。 lable=+0(%si):string 是我们要探测的其中一个参数，其他参数类似，这种形式的表达式可以写多个。其实label 表示变量名，主要是表标识这个表达式的结果。 ","date":"2023-02-13","objectID":"/https-packet-capture/:4:4","series":null,"tags":[],"title":"Https 抓包-密文转明文","uri":"/https-packet-capture/#4-从ssl对象中获取client_random"},{"categories":[],"content":"4. 从ssl对象中获取client_random对象其实使用多个成员变量组成，由于子节对齐的原因，我们很难通过计算得出对象的某个成员变量相对这个对象的偏移量。其实一个c 对象的值就是一个定长的子节数组。第一个成员变量的地址为 对象的地址+偏移量0 的地址。第二个成员变量的地址为 对象的地址+第一个对象的字节长度 的地址，第三个 成员变量的地址就是 对象的地址+第一个对象的子节长度+第二个对象的子节长度+子节对齐的长度。 如果没有子节对齐，其实我们很容器计算出对象某个成员，相对于对象的偏移量。从而得到成员的地址。但是一定会存在子节对齐，所以获取某个成员的地址，颇为复杂。 debuginfo主要保存的是程序的元数据，比如符号表等。我们可以使用gdb解析包含debuginfo的程序。就可以很容易的获取成员的偏移。 编译带debug信息libssl.so系统内的openssl库是不带符号表的。nginx主要依赖libssl.so这个库。我们可以通过包管理工具安装debuginfo包。因为openssl本身编译比较简单。所以我们直接编译带debug信息的libss.so // centos7系统 // 检查nginx依赖的openssl版本 $ nginx -V 2\u00261 |grep SSL built with OpenSSL 1.1.1k FIPS 25 Mar 2021 // 安装编译环境 $ yum install -y wget tar make gcc perl pcre-devel zlib-devel // 下载对应版本的openssl $ wget https://www.openssl.org/source/old/1.1.1/openssl-1.1.1k.tar.gz --no-check-certificate // 解压 $ tar -xf openssl-1.1.1k.tar.gz cd openssl-1.1.1k // -d选项就是带debuginfo的编译配置 $ ./config -d --prefix=/usr/local/ssl --openssldir=/usr/local/ssl -Wl,-rpath,/usr/local/ssl/lib shared make gdb查看ssl对象 // 执行gdb gdb libssl.so.1.1 // 通过ptype 命令查看 ssl对象，ssl结构体的定义名为：struct ssl_st // 输出信息中，第一列为成员相对于结构体的偏移量，第二列为成员的大小，第三列就是成员的源码。 // 注意偏移量为 168 的对象：struct ssl3_state_st *s3; // client_random 其实是保存在struct ssl3_state_st 结构体中。 (gdb) ptype /o struct ssl_st /* offset | size */ type = struct ssl_st { /* 0 | 4 */ int version; /* XXX 4-byte hole */ /* 8 | 8 */ const SSL_METHOD *method; /* 16 | 8 */ BIO *rbio; /* 24 | 8 */ BIO *wbio; /* 32 | 8 */ BIO *bbio; /* 40 | 4 */ int rwstate; /* XXX 4-byte hole */ /* 48 | 8 */ int (*handshake_func)(SSL *); /* 56 | 4 */ int server; /* 60 | 4 */ int new_session; /* 64 | 4 */ int quiet_shutdown; /* 68 | 4 */ int shutdown; /* 72 | 60 */ OSSL_STATEM statem; /* 132 | 4 */ SSL_EARLY_DATA_STATE early_data_state; /* 136 | 8 */ BUF_MEM *init_buf; /* 144 | 8 */ void *init_msg; /* 152 | 8 */ size_t init_num; /* 160 | 8 */ size_t init_off; /* 168 | 8 */ struct ssl3_state_st *s3; /* 176 | 8 */ struct dtls1_state_st *d1; /* 184 | 8 */ void (*msg_callback)(int, int, int, const void *, size_t, SSL *, void *); /* 192 | 8 */ void *msg_callback_arg; /* 200 | 4 */ int hit; /* XXX 4-byte hole */ /* 208 | 8 */ X509_VERIFY_PARAM *param; /* 216 | 64 */ SSL_DANE dane; /* 280 | 8 */ struct stack_st_SSL_CIPHER *peer_ciphers; /* 288 | 8 */ struct stack_st_SSL_CIPHER *cipher_list; /* 296 | 8 */ struct stack_st_SSL_CIPHER *cipher_list_by_id; /* 304 | 8 */ struct stack_st_SSL_CIPHER *tls13_ciphersuites; // 我们继续通过pteyp命令查看 struct ssl3_state_st 结构体。 // 偏移量为 184的位置就是我们需要的client_random (gdb) ptype /o struct ssl3_state_st /* offset | size */ type = struct ssl3_state_st { /* 0 | 8 */ long flags; /* 8 | 8 */ size_t read_mac_secret_size; /* 16 | 64 */ unsigned char read_mac_secret[64]; /* 80 | 8 */ size_t write_mac_secret_size; /* 88 | 64 */ unsigned char write_mac_secret[64]; /* 152 | 32 */ unsigned char server_random[32]; /* 184 | 32 */ unsigned char client_random[32]; /* 216 | 4 */ int need_empty_fragments; /* 220 | 4 */ int empty_fragment_done; /* 224 | 8 */ BIO *handshake_buffer; /* 232 | 8 */ EVP_MD_CTX *handshake_dgst; /* 240 | 4 */ int change_cipher_spec; /* 244 | 4 */ int warn_alert; /* 248 | 4 */ int fatal_alert; /* 252 | 4 */ int alert_dispatch; /* 256 | 2 */ unsigned char send_alert[2]; /* XXX 2-byte hole */ /* 260 | 4 */ int renegotiate; /* 264 | 4 */ int total_renegotiations; /* 268 | 4 */ int num_renegotiations; /* 272 | 4 */ int in_read_app_data; 找到了我们需要的成员，uprobe表达式改如何写呢?,我们这样写：client_random=+192(+168(%di)):u64 di 寄存器就是ssl_log_secret函数的第一个参数。保存的是对象ssl的地址。 +168(%di)：就是相对 struct ssl_st 这个结构体的地址偏移168的位置，此位置是一个结构体地址：struct ssl3_state_st *s3; +192(+168(%di)):u64： 再次通过圆括号对上面的地址进行解析，就是相对于 struct ssl3_state_st这个地址偏移量192的位置。此位置是一个字符数组。然后我们通过u64，无符号整型保存。 构造uprobe表达式uprobe的表达式如下所示： ‘p:/usr/lib64/libssl.so.1.1:ssl_log_secret lable=+0(%si):string client_random=+184(+168(%di)):u64 secret=+0(%dx):u64 secret_len=%cx’ 其中 p 表示，探测函数入口。 /usr/lib64/libssl.so.1.1 为我们要探测是进程的地址。 ssl_log_secret 就是我们要探测是函数。 lable=+0(%si):string 是我们要探测的其中一个参数，其他参数类似，这种形式的表达式可以写多个。其实label 表示变量名，主要是表标识这个表达式的结果。 ","date":"2023-02-13","objectID":"/https-packet-capture/:4:4","series":null,"tags":[],"title":"Https 抓包-密文转明文","uri":"/https-packet-capture/#编译带debug信息libsslso"},{"categories":[],"content":"4. 从ssl对象中获取client_random对象其实使用多个成员变量组成，由于子节对齐的原因，我们很难通过计算得出对象的某个成员变量相对这个对象的偏移量。其实一个c 对象的值就是一个定长的子节数组。第一个成员变量的地址为 对象的地址+偏移量0 的地址。第二个成员变量的地址为 对象的地址+第一个对象的字节长度 的地址，第三个 成员变量的地址就是 对象的地址+第一个对象的子节长度+第二个对象的子节长度+子节对齐的长度。 如果没有子节对齐，其实我们很容器计算出对象某个成员，相对于对象的偏移量。从而得到成员的地址。但是一定会存在子节对齐，所以获取某个成员的地址，颇为复杂。 debuginfo主要保存的是程序的元数据，比如符号表等。我们可以使用gdb解析包含debuginfo的程序。就可以很容易的获取成员的偏移。 编译带debug信息libssl.so系统内的openssl库是不带符号表的。nginx主要依赖libssl.so这个库。我们可以通过包管理工具安装debuginfo包。因为openssl本身编译比较简单。所以我们直接编译带debug信息的libss.so // centos7系统 // 检查nginx依赖的openssl版本 $ nginx -V 2\u00261 |grep SSL built with OpenSSL 1.1.1k FIPS 25 Mar 2021 // 安装编译环境 $ yum install -y wget tar make gcc perl pcre-devel zlib-devel // 下载对应版本的openssl $ wget https://www.openssl.org/source/old/1.1.1/openssl-1.1.1k.tar.gz --no-check-certificate // 解压 $ tar -xf openssl-1.1.1k.tar.gz cd openssl-1.1.1k // -d选项就是带debuginfo的编译配置 $ ./config -d --prefix=/usr/local/ssl --openssldir=/usr/local/ssl -Wl,-rpath,/usr/local/ssl/lib shared make gdb查看ssl对象 // 执行gdb gdb libssl.so.1.1 // 通过ptype 命令查看 ssl对象，ssl结构体的定义名为：struct ssl_st // 输出信息中，第一列为成员相对于结构体的偏移量，第二列为成员的大小，第三列就是成员的源码。 // 注意偏移量为 168 的对象：struct ssl3_state_st *s3; // client_random 其实是保存在struct ssl3_state_st 结构体中。 (gdb) ptype /o struct ssl_st /* offset | size */ type = struct ssl_st { /* 0 | 4 */ int version; /* XXX 4-byte hole */ /* 8 | 8 */ const SSL_METHOD *method; /* 16 | 8 */ BIO *rbio; /* 24 | 8 */ BIO *wbio; /* 32 | 8 */ BIO *bbio; /* 40 | 4 */ int rwstate; /* XXX 4-byte hole */ /* 48 | 8 */ int (*handshake_func)(SSL *); /* 56 | 4 */ int server; /* 60 | 4 */ int new_session; /* 64 | 4 */ int quiet_shutdown; /* 68 | 4 */ int shutdown; /* 72 | 60 */ OSSL_STATEM statem; /* 132 | 4 */ SSL_EARLY_DATA_STATE early_data_state; /* 136 | 8 */ BUF_MEM *init_buf; /* 144 | 8 */ void *init_msg; /* 152 | 8 */ size_t init_num; /* 160 | 8 */ size_t init_off; /* 168 | 8 */ struct ssl3_state_st *s3; /* 176 | 8 */ struct dtls1_state_st *d1; /* 184 | 8 */ void (*msg_callback)(int, int, int, const void *, size_t, SSL *, void *); /* 192 | 8 */ void *msg_callback_arg; /* 200 | 4 */ int hit; /* XXX 4-byte hole */ /* 208 | 8 */ X509_VERIFY_PARAM *param; /* 216 | 64 */ SSL_DANE dane; /* 280 | 8 */ struct stack_st_SSL_CIPHER *peer_ciphers; /* 288 | 8 */ struct stack_st_SSL_CIPHER *cipher_list; /* 296 | 8 */ struct stack_st_SSL_CIPHER *cipher_list_by_id; /* 304 | 8 */ struct stack_st_SSL_CIPHER *tls13_ciphersuites; // 我们继续通过pteyp命令查看 struct ssl3_state_st 结构体。 // 偏移量为 184的位置就是我们需要的client_random (gdb) ptype /o struct ssl3_state_st /* offset | size */ type = struct ssl3_state_st { /* 0 | 8 */ long flags; /* 8 | 8 */ size_t read_mac_secret_size; /* 16 | 64 */ unsigned char read_mac_secret[64]; /* 80 | 8 */ size_t write_mac_secret_size; /* 88 | 64 */ unsigned char write_mac_secret[64]; /* 152 | 32 */ unsigned char server_random[32]; /* 184 | 32 */ unsigned char client_random[32]; /* 216 | 4 */ int need_empty_fragments; /* 220 | 4 */ int empty_fragment_done; /* 224 | 8 */ BIO *handshake_buffer; /* 232 | 8 */ EVP_MD_CTX *handshake_dgst; /* 240 | 4 */ int change_cipher_spec; /* 244 | 4 */ int warn_alert; /* 248 | 4 */ int fatal_alert; /* 252 | 4 */ int alert_dispatch; /* 256 | 2 */ unsigned char send_alert[2]; /* XXX 2-byte hole */ /* 260 | 4 */ int renegotiate; /* 264 | 4 */ int total_renegotiations; /* 268 | 4 */ int num_renegotiations; /* 272 | 4 */ int in_read_app_data; 找到了我们需要的成员，uprobe表达式改如何写呢?,我们这样写：client_random=+192(+168(%di)):u64 di 寄存器就是ssl_log_secret函数的第一个参数。保存的是对象ssl的地址。 +168(%di)：就是相对 struct ssl_st 这个结构体的地址偏移168的位置，此位置是一个结构体地址：struct ssl3_state_st *s3; +192(+168(%di)):u64： 再次通过圆括号对上面的地址进行解析，就是相对于 struct ssl3_state_st这个地址偏移量192的位置。此位置是一个字符数组。然后我们通过u64，无符号整型保存。 构造uprobe表达式uprobe的表达式如下所示： ‘p:/usr/lib64/libssl.so.1.1:ssl_log_secret lable=+0(%si):string client_random=+184(+168(%di)):u64 secret=+0(%dx):u64 secret_len=%cx’ 其中 p 表示，探测函数入口。 /usr/lib64/libssl.so.1.1 为我们要探测是进程的地址。 ssl_log_secret 就是我们要探测是函数。 lable=+0(%si):string 是我们要探测的其中一个参数，其他参数类似，这种形式的表达式可以写多个。其实label 表示变量名，主要是表标识这个表达式的结果。 ","date":"2023-02-13","objectID":"/https-packet-capture/:4:4","series":null,"tags":[],"title":"Https 抓包-密文转明文","uri":"/https-packet-capture/#gdb查看ssl对象"},{"categories":[],"content":"4. 从ssl对象中获取client_random对象其实使用多个成员变量组成，由于子节对齐的原因，我们很难通过计算得出对象的某个成员变量相对这个对象的偏移量。其实一个c 对象的值就是一个定长的子节数组。第一个成员变量的地址为 对象的地址+偏移量0 的地址。第二个成员变量的地址为 对象的地址+第一个对象的字节长度 的地址，第三个 成员变量的地址就是 对象的地址+第一个对象的子节长度+第二个对象的子节长度+子节对齐的长度。 如果没有子节对齐，其实我们很容器计算出对象某个成员，相对于对象的偏移量。从而得到成员的地址。但是一定会存在子节对齐，所以获取某个成员的地址，颇为复杂。 debuginfo主要保存的是程序的元数据，比如符号表等。我们可以使用gdb解析包含debuginfo的程序。就可以很容易的获取成员的偏移。 编译带debug信息libssl.so系统内的openssl库是不带符号表的。nginx主要依赖libssl.so这个库。我们可以通过包管理工具安装debuginfo包。因为openssl本身编译比较简单。所以我们直接编译带debug信息的libss.so // centos7系统 // 检查nginx依赖的openssl版本 $ nginx -V 2\u00261 |grep SSL built with OpenSSL 1.1.1k FIPS 25 Mar 2021 // 安装编译环境 $ yum install -y wget tar make gcc perl pcre-devel zlib-devel // 下载对应版本的openssl $ wget https://www.openssl.org/source/old/1.1.1/openssl-1.1.1k.tar.gz --no-check-certificate // 解压 $ tar -xf openssl-1.1.1k.tar.gz cd openssl-1.1.1k // -d选项就是带debuginfo的编译配置 $ ./config -d --prefix=/usr/local/ssl --openssldir=/usr/local/ssl -Wl,-rpath,/usr/local/ssl/lib shared make gdb查看ssl对象 // 执行gdb gdb libssl.so.1.1 // 通过ptype 命令查看 ssl对象，ssl结构体的定义名为：struct ssl_st // 输出信息中，第一列为成员相对于结构体的偏移量，第二列为成员的大小，第三列就是成员的源码。 // 注意偏移量为 168 的对象：struct ssl3_state_st *s3; // client_random 其实是保存在struct ssl3_state_st 结构体中。 (gdb) ptype /o struct ssl_st /* offset | size */ type = struct ssl_st { /* 0 | 4 */ int version; /* XXX 4-byte hole */ /* 8 | 8 */ const SSL_METHOD *method; /* 16 | 8 */ BIO *rbio; /* 24 | 8 */ BIO *wbio; /* 32 | 8 */ BIO *bbio; /* 40 | 4 */ int rwstate; /* XXX 4-byte hole */ /* 48 | 8 */ int (*handshake_func)(SSL *); /* 56 | 4 */ int server; /* 60 | 4 */ int new_session; /* 64 | 4 */ int quiet_shutdown; /* 68 | 4 */ int shutdown; /* 72 | 60 */ OSSL_STATEM statem; /* 132 | 4 */ SSL_EARLY_DATA_STATE early_data_state; /* 136 | 8 */ BUF_MEM *init_buf; /* 144 | 8 */ void *init_msg; /* 152 | 8 */ size_t init_num; /* 160 | 8 */ size_t init_off; /* 168 | 8 */ struct ssl3_state_st *s3; /* 176 | 8 */ struct dtls1_state_st *d1; /* 184 | 8 */ void (*msg_callback)(int, int, int, const void *, size_t, SSL *, void *); /* 192 | 8 */ void *msg_callback_arg; /* 200 | 4 */ int hit; /* XXX 4-byte hole */ /* 208 | 8 */ X509_VERIFY_PARAM *param; /* 216 | 64 */ SSL_DANE dane; /* 280 | 8 */ struct stack_st_SSL_CIPHER *peer_ciphers; /* 288 | 8 */ struct stack_st_SSL_CIPHER *cipher_list; /* 296 | 8 */ struct stack_st_SSL_CIPHER *cipher_list_by_id; /* 304 | 8 */ struct stack_st_SSL_CIPHER *tls13_ciphersuites; // 我们继续通过pteyp命令查看 struct ssl3_state_st 结构体。 // 偏移量为 184的位置就是我们需要的client_random (gdb) ptype /o struct ssl3_state_st /* offset | size */ type = struct ssl3_state_st { /* 0 | 8 */ long flags; /* 8 | 8 */ size_t read_mac_secret_size; /* 16 | 64 */ unsigned char read_mac_secret[64]; /* 80 | 8 */ size_t write_mac_secret_size; /* 88 | 64 */ unsigned char write_mac_secret[64]; /* 152 | 32 */ unsigned char server_random[32]; /* 184 | 32 */ unsigned char client_random[32]; /* 216 | 4 */ int need_empty_fragments; /* 220 | 4 */ int empty_fragment_done; /* 224 | 8 */ BIO *handshake_buffer; /* 232 | 8 */ EVP_MD_CTX *handshake_dgst; /* 240 | 4 */ int change_cipher_spec; /* 244 | 4 */ int warn_alert; /* 248 | 4 */ int fatal_alert; /* 252 | 4 */ int alert_dispatch; /* 256 | 2 */ unsigned char send_alert[2]; /* XXX 2-byte hole */ /* 260 | 4 */ int renegotiate; /* 264 | 4 */ int total_renegotiations; /* 268 | 4 */ int num_renegotiations; /* 272 | 4 */ int in_read_app_data; 找到了我们需要的成员，uprobe表达式改如何写呢?,我们这样写：client_random=+192(+168(%di)):u64 di 寄存器就是ssl_log_secret函数的第一个参数。保存的是对象ssl的地址。 +168(%di)：就是相对 struct ssl_st 这个结构体的地址偏移168的位置，此位置是一个结构体地址：struct ssl3_state_st *s3; +192(+168(%di)):u64： 再次通过圆括号对上面的地址进行解析，就是相对于 struct ssl3_state_st这个地址偏移量192的位置。此位置是一个字符数组。然后我们通过u64，无符号整型保存。 构造uprobe表达式uprobe的表达式如下所示： ‘p:/usr/lib64/libssl.so.1.1:ssl_log_secret lable=+0(%si):string client_random=+184(+168(%di)):u64 secret=+0(%dx):u64 secret_len=%cx’ 其中 p 表示，探测函数入口。 /usr/lib64/libssl.so.1.1 为我们要探测是进程的地址。 ssl_log_secret 就是我们要探测是函数。 lable=+0(%si):string 是我们要探测的其中一个参数，其他参数类似，这种形式的表达式可以写多个。其实label 表示变量名，主要是表标识这个表达式的结果。 ","date":"2023-02-13","objectID":"/https-packet-capture/:4:4","series":null,"tags":[],"title":"Https 抓包-密文转明文","uri":"/https-packet-capture/#构造uprobe表达式"},{"categories":[],"content":"4. 从ssl对象中获取client_random对象其实使用多个成员变量组成，由于子节对齐的原因，我们很难通过计算得出对象的某个成员变量相对这个对象的偏移量。其实一个c 对象的值就是一个定长的子节数组。第一个成员变量的地址为 对象的地址+偏移量0 的地址。第二个成员变量的地址为 对象的地址+第一个对象的字节长度 的地址，第三个 成员变量的地址就是 对象的地址+第一个对象的子节长度+第二个对象的子节长度+子节对齐的长度。 如果没有子节对齐，其实我们很容器计算出对象某个成员，相对于对象的偏移量。从而得到成员的地址。但是一定会存在子节对齐，所以获取某个成员的地址，颇为复杂。 debuginfo主要保存的是程序的元数据，比如符号表等。我们可以使用gdb解析包含debuginfo的程序。就可以很容易的获取成员的偏移。 编译带debug信息libssl.so系统内的openssl库是不带符号表的。nginx主要依赖libssl.so这个库。我们可以通过包管理工具安装debuginfo包。因为openssl本身编译比较简单。所以我们直接编译带debug信息的libss.so // centos7系统 // 检查nginx依赖的openssl版本 $ nginx -V 2\u00261 |grep SSL built with OpenSSL 1.1.1k FIPS 25 Mar 2021 // 安装编译环境 $ yum install -y wget tar make gcc perl pcre-devel zlib-devel // 下载对应版本的openssl $ wget https://www.openssl.org/source/old/1.1.1/openssl-1.1.1k.tar.gz --no-check-certificate // 解压 $ tar -xf openssl-1.1.1k.tar.gz cd openssl-1.1.1k // -d选项就是带debuginfo的编译配置 $ ./config -d --prefix=/usr/local/ssl --openssldir=/usr/local/ssl -Wl,-rpath,/usr/local/ssl/lib shared make gdb查看ssl对象 // 执行gdb gdb libssl.so.1.1 // 通过ptype 命令查看 ssl对象，ssl结构体的定义名为：struct ssl_st // 输出信息中，第一列为成员相对于结构体的偏移量，第二列为成员的大小，第三列就是成员的源码。 // 注意偏移量为 168 的对象：struct ssl3_state_st *s3; // client_random 其实是保存在struct ssl3_state_st 结构体中。 (gdb) ptype /o struct ssl_st /* offset | size */ type = struct ssl_st { /* 0 | 4 */ int version; /* XXX 4-byte hole */ /* 8 | 8 */ const SSL_METHOD *method; /* 16 | 8 */ BIO *rbio; /* 24 | 8 */ BIO *wbio; /* 32 | 8 */ BIO *bbio; /* 40 | 4 */ int rwstate; /* XXX 4-byte hole */ /* 48 | 8 */ int (*handshake_func)(SSL *); /* 56 | 4 */ int server; /* 60 | 4 */ int new_session; /* 64 | 4 */ int quiet_shutdown; /* 68 | 4 */ int shutdown; /* 72 | 60 */ OSSL_STATEM statem; /* 132 | 4 */ SSL_EARLY_DATA_STATE early_data_state; /* 136 | 8 */ BUF_MEM *init_buf; /* 144 | 8 */ void *init_msg; /* 152 | 8 */ size_t init_num; /* 160 | 8 */ size_t init_off; /* 168 | 8 */ struct ssl3_state_st *s3; /* 176 | 8 */ struct dtls1_state_st *d1; /* 184 | 8 */ void (*msg_callback)(int, int, int, const void *, size_t, SSL *, void *); /* 192 | 8 */ void *msg_callback_arg; /* 200 | 4 */ int hit; /* XXX 4-byte hole */ /* 208 | 8 */ X509_VERIFY_PARAM *param; /* 216 | 64 */ SSL_DANE dane; /* 280 | 8 */ struct stack_st_SSL_CIPHER *peer_ciphers; /* 288 | 8 */ struct stack_st_SSL_CIPHER *cipher_list; /* 296 | 8 */ struct stack_st_SSL_CIPHER *cipher_list_by_id; /* 304 | 8 */ struct stack_st_SSL_CIPHER *tls13_ciphersuites; // 我们继续通过pteyp命令查看 struct ssl3_state_st 结构体。 // 偏移量为 184的位置就是我们需要的client_random (gdb) ptype /o struct ssl3_state_st /* offset | size */ type = struct ssl3_state_st { /* 0 | 8 */ long flags; /* 8 | 8 */ size_t read_mac_secret_size; /* 16 | 64 */ unsigned char read_mac_secret[64]; /* 80 | 8 */ size_t write_mac_secret_size; /* 88 | 64 */ unsigned char write_mac_secret[64]; /* 152 | 32 */ unsigned char server_random[32]; /* 184 | 32 */ unsigned char client_random[32]; /* 216 | 4 */ int need_empty_fragments; /* 220 | 4 */ int empty_fragment_done; /* 224 | 8 */ BIO *handshake_buffer; /* 232 | 8 */ EVP_MD_CTX *handshake_dgst; /* 240 | 4 */ int change_cipher_spec; /* 244 | 4 */ int warn_alert; /* 248 | 4 */ int fatal_alert; /* 252 | 4 */ int alert_dispatch; /* 256 | 2 */ unsigned char send_alert[2]; /* XXX 2-byte hole */ /* 260 | 4 */ int renegotiate; /* 264 | 4 */ int total_renegotiations; /* 268 | 4 */ int num_renegotiations; /* 272 | 4 */ int in_read_app_data; 找到了我们需要的成员，uprobe表达式改如何写呢?,我们这样写：client_random=+192(+168(%di)):u64 di 寄存器就是ssl_log_secret函数的第一个参数。保存的是对象ssl的地址。 +168(%di)：就是相对 struct ssl_st 这个结构体的地址偏移168的位置，此位置是一个结构体地址：struct ssl3_state_st *s3; +192(+168(%di)):u64： 再次通过圆括号对上面的地址进行解析，就是相对于 struct ssl3_state_st这个地址偏移量192的位置。此位置是一个字符数组。然后我们通过u64，无符号整型保存。 构造uprobe表达式uprobe的表达式如下所示： ‘p:/usr/lib64/libssl.so.1.1:ssl_log_secret lable=+0(%si):string client_random=+184(+168(%di)):u64 secret=+0(%dx):u64 secret_len=%cx’ 其中 p 表示，探测函数入口。 /usr/lib64/libssl.so.1.1 为我们要探测是进程的地址。 ssl_log_secret 就是我们要探测是函数。 lable=+0(%si):string 是我们要探测的其中一个参数，其他参数类似，这种形式的表达式可以写多个。其实label 表示变量名，主要是表标识这个表达式的结果。 ","date":"2023-02-13","objectID":"/https-packet-capture/:4:4","series":null,"tags":[],"title":"Https 抓包-密文转明文","uri":"/https-packet-capture/#执行uprobe"},{"categories":[],"content":"4. 从ssl对象中获取client_random对象其实使用多个成员变量组成，由于子节对齐的原因，我们很难通过计算得出对象的某个成员变量相对这个对象的偏移量。其实一个c 对象的值就是一个定长的子节数组。第一个成员变量的地址为 对象的地址+偏移量0 的地址。第二个成员变量的地址为 对象的地址+第一个对象的字节长度 的地址，第三个 成员变量的地址就是 对象的地址+第一个对象的子节长度+第二个对象的子节长度+子节对齐的长度。 如果没有子节对齐，其实我们很容器计算出对象某个成员，相对于对象的偏移量。从而得到成员的地址。但是一定会存在子节对齐，所以获取某个成员的地址，颇为复杂。 debuginfo主要保存的是程序的元数据，比如符号表等。我们可以使用gdb解析包含debuginfo的程序。就可以很容易的获取成员的偏移。 编译带debug信息libssl.so系统内的openssl库是不带符号表的。nginx主要依赖libssl.so这个库。我们可以通过包管理工具安装debuginfo包。因为openssl本身编译比较简单。所以我们直接编译带debug信息的libss.so // centos7系统 // 检查nginx依赖的openssl版本 $ nginx -V 2\u00261 |grep SSL built with OpenSSL 1.1.1k FIPS 25 Mar 2021 // 安装编译环境 $ yum install -y wget tar make gcc perl pcre-devel zlib-devel // 下载对应版本的openssl $ wget https://www.openssl.org/source/old/1.1.1/openssl-1.1.1k.tar.gz --no-check-certificate // 解压 $ tar -xf openssl-1.1.1k.tar.gz cd openssl-1.1.1k // -d选项就是带debuginfo的编译配置 $ ./config -d --prefix=/usr/local/ssl --openssldir=/usr/local/ssl -Wl,-rpath,/usr/local/ssl/lib shared make gdb查看ssl对象 // 执行gdb gdb libssl.so.1.1 // 通过ptype 命令查看 ssl对象，ssl结构体的定义名为：struct ssl_st // 输出信息中，第一列为成员相对于结构体的偏移量，第二列为成员的大小，第三列就是成员的源码。 // 注意偏移量为 168 的对象：struct ssl3_state_st *s3; // client_random 其实是保存在struct ssl3_state_st 结构体中。 (gdb) ptype /o struct ssl_st /* offset | size */ type = struct ssl_st { /* 0 | 4 */ int version; /* XXX 4-byte hole */ /* 8 | 8 */ const SSL_METHOD *method; /* 16 | 8 */ BIO *rbio; /* 24 | 8 */ BIO *wbio; /* 32 | 8 */ BIO *bbio; /* 40 | 4 */ int rwstate; /* XXX 4-byte hole */ /* 48 | 8 */ int (*handshake_func)(SSL *); /* 56 | 4 */ int server; /* 60 | 4 */ int new_session; /* 64 | 4 */ int quiet_shutdown; /* 68 | 4 */ int shutdown; /* 72 | 60 */ OSSL_STATEM statem; /* 132 | 4 */ SSL_EARLY_DATA_STATE early_data_state; /* 136 | 8 */ BUF_MEM *init_buf; /* 144 | 8 */ void *init_msg; /* 152 | 8 */ size_t init_num; /* 160 | 8 */ size_t init_off; /* 168 | 8 */ struct ssl3_state_st *s3; /* 176 | 8 */ struct dtls1_state_st *d1; /* 184 | 8 */ void (*msg_callback)(int, int, int, const void *, size_t, SSL *, void *); /* 192 | 8 */ void *msg_callback_arg; /* 200 | 4 */ int hit; /* XXX 4-byte hole */ /* 208 | 8 */ X509_VERIFY_PARAM *param; /* 216 | 64 */ SSL_DANE dane; /* 280 | 8 */ struct stack_st_SSL_CIPHER *peer_ciphers; /* 288 | 8 */ struct stack_st_SSL_CIPHER *cipher_list; /* 296 | 8 */ struct stack_st_SSL_CIPHER *cipher_list_by_id; /* 304 | 8 */ struct stack_st_SSL_CIPHER *tls13_ciphersuites; // 我们继续通过pteyp命令查看 struct ssl3_state_st 结构体。 // 偏移量为 184的位置就是我们需要的client_random (gdb) ptype /o struct ssl3_state_st /* offset | size */ type = struct ssl3_state_st { /* 0 | 8 */ long flags; /* 8 | 8 */ size_t read_mac_secret_size; /* 16 | 64 */ unsigned char read_mac_secret[64]; /* 80 | 8 */ size_t write_mac_secret_size; /* 88 | 64 */ unsigned char write_mac_secret[64]; /* 152 | 32 */ unsigned char server_random[32]; /* 184 | 32 */ unsigned char client_random[32]; /* 216 | 4 */ int need_empty_fragments; /* 220 | 4 */ int empty_fragment_done; /* 224 | 8 */ BIO *handshake_buffer; /* 232 | 8 */ EVP_MD_CTX *handshake_dgst; /* 240 | 4 */ int change_cipher_spec; /* 244 | 4 */ int warn_alert; /* 248 | 4 */ int fatal_alert; /* 252 | 4 */ int alert_dispatch; /* 256 | 2 */ unsigned char send_alert[2]; /* XXX 2-byte hole */ /* 260 | 4 */ int renegotiate; /* 264 | 4 */ int total_renegotiations; /* 268 | 4 */ int num_renegotiations; /* 272 | 4 */ int in_read_app_data; 找到了我们需要的成员，uprobe表达式改如何写呢?,我们这样写：client_random=+192(+168(%di)):u64 di 寄存器就是ssl_log_secret函数的第一个参数。保存的是对象ssl的地址。 +168(%di)：就是相对 struct ssl_st 这个结构体的地址偏移168的位置，此位置是一个结构体地址：struct ssl3_state_st *s3; +192(+168(%di)):u64： 再次通过圆括号对上面的地址进行解析，就是相对于 struct ssl3_state_st这个地址偏移量192的位置。此位置是一个字符数组。然后我们通过u64，无符号整型保存。 构造uprobe表达式uprobe的表达式如下所示： ‘p:/usr/lib64/libssl.so.1.1:ssl_log_secret lable=+0(%si):string client_random=+184(+168(%di)):u64 secret=+0(%dx):u64 secret_len=%cx’ 其中 p 表示，探测函数入口。 /usr/lib64/libssl.so.1.1 为我们要探测是进程的地址。 ssl_log_secret 就是我们要探测是函数。 lable=+0(%si):string 是我们要探测的其中一个参数，其他参数类似，这种形式的表达式可以写多个。其实label 表示变量名，主要是表标识这个表达式的结果。 ","date":"2023-02-13","objectID":"/https-packet-capture/:4:4","series":null,"tags":[],"title":"Https 抓包-密文转明文","uri":"/https-packet-capture/#补充"},{"categories":[],"content":"文件服务直接查看server块配置 server { listen 1234; server_name 127.0.0.1; charset utf-8; # 避免中文乱码 location / { root /download; autoindex on; # 索引,开启目录文件列表 autoindex_exact_size on; # 显示文件大小 autoindex_localtime on; # 显示文件时间 # 密码，按需开启 auth_basic \"Some description\"; auth_basic_user_file /nginx/passwd; # 自定义一个绝对路径的密码文件 access_log /var/log/nginx/download-access.log; error_log /var/log/nginx/download-error.log; } } 到这里就搭建好了简单的文件服务，可以在浏览器中输入ip或域名访问目录文件了。 ","date":"2022-06-29","objectID":"/nginx-file-server/:1:0","series":null,"tags":[],"title":"Nginx搭建文件服务器以及文件在线预览和强制下载","uri":"/nginx-file-server/#文件服务"},{"categories":[],"content":"身份认证如果不希望自己的文件被他人所下载和访问，可以增加一下身份验证。幸运的是，Nginx 已经为我们提供了简单的身份认证的功能，开箱即用。 概述ngx_http_auth_basic_module模块允许通过使用“HTTP基本认证”协议验证用户名和密码来限制对资源的访问。 访问还可以根据地址、子请求的结果或JWT进行限制。同时通过地址和密码限制访问由满足指令控制。 配置Nginx在location块中添加以下配置： location / { auth_basic \"Some description\"; auth_basic_user_file /nginx/passwd; # 自定义一个绝对路径的文件 生成密码为了安全考虑，auth_basic 功能必须在起“用户名:密码”文件中使用经过 Hash 的密码值，故需要对明文密码进行处理。 可以选择的生成工具有 Apache 服务器发行版中提供的 htpasswd 工具，以及 openssl passwd 命令。 echo \"账户名:$(openssl passwd 密码)\" \u003e /nginx/passwd $ echo \"nginx:$(openssl passwd 123456)\" \u003e /nginx/passwd $ cat /nginx/passwd nginx:Kj1uQfCRjT/9g nginx -s reload 重启一下nginx服务就可以了。 ","date":"2022-06-29","objectID":"/nginx-file-server/:1:1","series":null,"tags":[],"title":"Nginx搭建文件服务器以及文件在线预览和强制下载","uri":"/nginx-file-server/#身份认证"},{"categories":[],"content":"身份认证如果不希望自己的文件被他人所下载和访问，可以增加一下身份验证。幸运的是，Nginx 已经为我们提供了简单的身份认证的功能，开箱即用。 概述ngx_http_auth_basic_module模块允许通过使用“HTTP基本认证”协议验证用户名和密码来限制对资源的访问。 访问还可以根据地址、子请求的结果或JWT进行限制。同时通过地址和密码限制访问由满足指令控制。 配置Nginx在location块中添加以下配置： location / { auth_basic \"Some description\"; auth_basic_user_file /nginx/passwd; # 自定义一个绝对路径的文件 生成密码为了安全考虑，auth_basic 功能必须在起“用户名:密码”文件中使用经过 Hash 的密码值，故需要对明文密码进行处理。 可以选择的生成工具有 Apache 服务器发行版中提供的 htpasswd 工具，以及 openssl passwd 命令。 echo \"账户名:$(openssl passwd 密码)\" /nginx/passwd $ echo \"nginx:$(openssl passwd 123456)\" /nginx/passwd $ cat /nginx/passwd nginx:Kj1uQfCRjT/9g nginx -s reload 重启一下nginx服务就可以了。 ","date":"2022-06-29","objectID":"/nginx-file-server/:1:1","series":null,"tags":[],"title":"Nginx搭建文件服务器以及文件在线预览和强制下载","uri":"/nginx-file-server/#概述"},{"categories":[],"content":"身份认证如果不希望自己的文件被他人所下载和访问，可以增加一下身份验证。幸运的是，Nginx 已经为我们提供了简单的身份认证的功能，开箱即用。 概述ngx_http_auth_basic_module模块允许通过使用“HTTP基本认证”协议验证用户名和密码来限制对资源的访问。 访问还可以根据地址、子请求的结果或JWT进行限制。同时通过地址和密码限制访问由满足指令控制。 配置Nginx在location块中添加以下配置： location / { auth_basic \"Some description\"; auth_basic_user_file /nginx/passwd; # 自定义一个绝对路径的文件 生成密码为了安全考虑，auth_basic 功能必须在起“用户名:密码”文件中使用经过 Hash 的密码值，故需要对明文密码进行处理。 可以选择的生成工具有 Apache 服务器发行版中提供的 htpasswd 工具，以及 openssl passwd 命令。 echo \"账户名:$(openssl passwd 密码)\" /nginx/passwd $ echo \"nginx:$(openssl passwd 123456)\" /nginx/passwd $ cat /nginx/passwd nginx:Kj1uQfCRjT/9g nginx -s reload 重启一下nginx服务就可以了。 ","date":"2022-06-29","objectID":"/nginx-file-server/:1:1","series":null,"tags":[],"title":"Nginx搭建文件服务器以及文件在线预览和强制下载","uri":"/nginx-file-server/#配置nginx"},{"categories":[],"content":"身份认证如果不希望自己的文件被他人所下载和访问，可以增加一下身份验证。幸运的是，Nginx 已经为我们提供了简单的身份认证的功能，开箱即用。 概述ngx_http_auth_basic_module模块允许通过使用“HTTP基本认证”协议验证用户名和密码来限制对资源的访问。 访问还可以根据地址、子请求的结果或JWT进行限制。同时通过地址和密码限制访问由满足指令控制。 配置Nginx在location块中添加以下配置： location / { auth_basic \"Some description\"; auth_basic_user_file /nginx/passwd; # 自定义一个绝对路径的文件 生成密码为了安全考虑，auth_basic 功能必须在起“用户名:密码”文件中使用经过 Hash 的密码值，故需要对明文密码进行处理。 可以选择的生成工具有 Apache 服务器发行版中提供的 htpasswd 工具，以及 openssl passwd 命令。 echo \"账户名:$(openssl passwd 密码)\" /nginx/passwd $ echo \"nginx:$(openssl passwd 123456)\" /nginx/passwd $ cat /nginx/passwd nginx:Kj1uQfCRjT/9g nginx -s reload 重启一下nginx服务就可以了。 ","date":"2022-06-29","objectID":"/nginx-file-server/:1:1","series":null,"tags":[],"title":"Nginx搭建文件服务器以及文件在线预览和强制下载","uri":"/nginx-file-server/#生成密码"},{"categories":[],"content":"开启文件在线预览和强制下载 nginx 默认配置下， .txt是可以在线打开，而.md 会有弹窗，也就是下载。 在上面的location代码块中，添加以下配置 #################default_type 方式 ################## # 配置在线预览 if ($request_filename ~* ^.*?\\.md { default_type text/plain; charset utf-8; } # 配置下载文件模式 if ($request_filename ~* ^.*?\\.txt { types { } default_type application/octet-stream; } #################add_header 方式 ################## # 配置在线预览 if ($request_filename ~* ^.*?\\.md { add_header Content-Type \"text/plain; charset=utf-8\"; } # 配置下载文件模式 if ($request_filename ~* ^.*?\\.txt { types { } add_header Content-Type \"application/octet-stream; charset=utf-8\"; } ##############Content-Disposition 方式############### # 配置文件为下载模式 if ($request_filename ~* ^.*?\\.(html|doc|zip|docx)$) { add_header Content-Disposition attachment; # 添加响应头，配置文件作为附件下载 add_header Content-Type application/octet-stream; } # 配置文件在线预览模式 if ($request_filename ~* ^.*?\\.(md)$) { add_header Content-Type \"text/plain;charset=utf-8\"; } Content-Disposition 是什么？ 在常规的 HTTP 应答中，Content-Disposition 响应头指示回复的内容该以何种形式展示，是以内联的形式（即网页或者页面的一部分），还是以附件的形式下载并保存到本地。 点击查看了解详情 ","date":"2022-06-29","objectID":"/nginx-file-server/:2:0","series":null,"tags":[],"title":"Nginx搭建文件服务器以及文件在线预览和强制下载","uri":"/nginx-file-server/#开启文件在线预览和强制下载"},{"categories":[],"content":"NGINX是如何配置生效的nginx.conf配置文件中有一段配置 http { include mime.types; default_type application/octet-stream; ··· ｝ application/octet-stream: 大多数浏览器会将其视为二进制文件并下载。default_type 仅适用于未在mime.types文件中定义的文件扩展名 首先nginx会读取 mime.types 中定义好的 数据类型与文件类型关系。然后使用default_type 将mime.types 中未定义的的都设置为application/octet-stream。 ","date":"2022-06-29","objectID":"/nginx-file-server/:3:0","series":null,"tags":[],"title":"Nginx搭建文件服务器以及文件在线预览和强制下载","uri":"/nginx-file-server/#nginx是如何配置生效的"},{"categories":[],"content":"参阅 如何让 Google Chrome 显示纯文本 HTTP 响应，而不是将其下载到文件中？ 反向 ssl 代理 Content-Disposition ","date":"2022-06-29","objectID":"/nginx-file-server/:4:0","series":null,"tags":[],"title":"Nginx搭建文件服务器以及文件在线预览和强制下载","uri":"/nginx-file-server/#参阅"},{"categories":[],"content":"This file exists solely to respond to /search URL with the related search layout template. No content shown here is rendered, all content is based in the template layouts/page/search.html Setting a very low sitemap priority will tell search engines this is not important content. This implementation uses Fusejs, jquery and mark.js ","date":"2022-01-06","objectID":"/search/:0:0","series":null,"tags":[],"title":"Search Results","uri":"/search/#"},{"categories":[],"content":"Initial setupSearch depends on additional output content type of JSON in config.toml [outputs] home = [\"HTML\", \"JSON\"] ","date":"2022-01-06","objectID":"/search/:1:0","series":null,"tags":[],"title":"Search Results","uri":"/search/#initial-setup"},{"categories":[],"content":"Searching additional filedsTo search additional fields defined in front matter, you must add it in 2 places. ","date":"2022-01-06","objectID":"/search/:2:0","series":null,"tags":[],"title":"Search Results","uri":"/search/#searching-additional-fileds"},{"categories":[],"content":"Edit layouts/_default/index.JSONThis exposes the values in /index.json i.e. add category ... \"contents\":{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \"tags\":{{ .Params.tags | jsonify }}{{end}}, \"categories\" : {{ .Params.categories | jsonify }}, ... ","date":"2022-01-06","objectID":"/search/:2:1","series":null,"tags":[],"title":"Search Results","uri":"/search/#edit-layouts_defaultindexjson"},{"categories":[],"content":"Edit fuse.js options to Searchstatic/js/search.js keys: [ \"title\", \"contents\", \"tags\", \"categories\" ] ","date":"2022-01-06","objectID":"/search/:2:2","series":null,"tags":[],"title":"Search Results","uri":"/search/#edit-fusejs-options-to-search"},{"categories":[],"content":"Prometheus（普罗米修斯）监控系统","date":"2022-01-05","objectID":"/prometheus/:1:0","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#prometheus普罗米修斯监控系统"},{"categories":[],"content":"一、Prometheus概述1、什么是Prometheus？Prometheus [prəˈmi:θi:əs, -ˌθju:s] 是由SoundCloud使用Go语言开发的开源监控报警系统和时间序列数据库(TSDB)。Prometheus于 2016 年加入 云原生计算基金会（CNCF），作为继Kubernetes之后的第二个托管项目，因为kubernetes的流行带动了prometheus的发展。 2、时间序列数据什么是时间序列数据？ 时间序列数据(TimeSeries Data):按照时间顺序记录系统、设备状态变化的数据被称为时序数据。 应用的场景很多, 如： 无人驾驶车辆运行中要记录的经度，纬度，速度，方向，旁边物体的距离等等。每时每刻都要将数据记录下来做分析。 某一个地区的各车辆的行驶轨迹数据 传统证券行业实时交易数据 实时运维监控数据，CPU、内存等实时数据 时间序列数据特点： 性能好 关系型数据库对于大规模数据的处理性能糟糕。NOSQL可以比较好的处理大规模数据，让依然比不上时间序列数据库。 存储成本低 高效的压缩算法，节省存储空间，有效降低IO Prometheus有着非常高效的时间序列数据存储方法，每个采样数据仅仅占用3.5byte左右空间，上百万条时间序列，30秒间隔，保留60天，大概花了200多G（来自官方数据) 3、Prometheus的主要特征 多维度数据模型 灵活的查询语言 不依赖分布式存储，单个服务器节点是自主的 以HTTP方式，通过pull模型拉去时间序列数据 也可以通过中间网关支持push模型 通过服务发现或者静态配置，来发现目标服务对象 支持多种多样的图表和界面展示 4、Prometheus基本原理Prometheus [prəˈmi:θi:əs, -ˌθju:s] 的基本原理是使用 Pull （抓取）的方式，通过HTTP协议周期性抓取被监控组件的Metrics 数据（监控指标数据），然后，再把这些数据保存在一个 TSDB （时间序列数据库，比如 OpenTSDB、InfluxDB 等）当中，任意组件只要提供对应的HTTP接口就可以接入监控。不需要任何SDK或者其他的集成过程。这样做非常适合做虚拟化环境监控系统，比如VM、Docker、Kubernetes等。 5、架构图6、组件说明 Prometheus Server：主要用于抓取数据和存储时序数据，在该组件上配置监控数据的采集和告警规则. Push Gateway: 主要用于短期的 jobs。由于这类 jobs 存在时间较短, 可能在 Prometheus 来 pull 之前就消失了。为此, 这类jobs 可以直接向 Prometheus server 端推送它们的 metrics. 这种方式主要用于服务层面的 metrics, 对于机器层面的 metrics, 需要使用 node exporter. Exporter: 是 Prometheus的一类数据采集组件的总称，用于暴露已有的第三方服务的 metrics 给Prometheus。 它负责从目标处搜集数据, 并将其转化为Prometheus支持的格式. 与传统的数据采集组件不同的是, 它并不向中央服务器发送数据, 而是等待中央服务器主动前来抓取. AlertManager: 用于接收promethues发出的告警做进一步处理，对告警进行聚合、下发、抑制等。常见的告警方式有：邮件，钉钉，webhook 等一些其他的工具。 Grafana: 第三方数据图表展示工具 Service Discovery: 动态发现待监控的Target，从而完成监控配置的重要组件，在容器化环境中尤为有用；该组件目前由Prometheus Server 内建支持。 每个组件都是独立工作的，不依赖其他组件。不同模块组件之间通过配置文件关联到一起，实现整个监控的功能。每个独立的模块都可以扩展，做高可用方案。 ","date":"2022-01-05","objectID":"/prometheus/:1:1","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#一prometheus概述"},{"categories":[],"content":"一、Prometheus概述1、什么是Prometheus？Prometheus [prəˈmi:θi:əs, -ˌθju:s] 是由SoundCloud使用Go语言开发的开源监控报警系统和时间序列数据库(TSDB)。Prometheus于 2016 年加入 云原生计算基金会（CNCF），作为继Kubernetes之后的第二个托管项目，因为kubernetes的流行带动了prometheus的发展。 2、时间序列数据什么是时间序列数据？ 时间序列数据(TimeSeries Data):按照时间顺序记录系统、设备状态变化的数据被称为时序数据。 应用的场景很多, 如： 无人驾驶车辆运行中要记录的经度，纬度，速度，方向，旁边物体的距离等等。每时每刻都要将数据记录下来做分析。 某一个地区的各车辆的行驶轨迹数据 传统证券行业实时交易数据 实时运维监控数据，CPU、内存等实时数据 时间序列数据特点： 性能好 关系型数据库对于大规模数据的处理性能糟糕。NOSQL可以比较好的处理大规模数据，让依然比不上时间序列数据库。 存储成本低 高效的压缩算法，节省存储空间，有效降低IO Prometheus有着非常高效的时间序列数据存储方法，每个采样数据仅仅占用3.5byte左右空间，上百万条时间序列，30秒间隔，保留60天，大概花了200多G（来自官方数据) 3、Prometheus的主要特征 多维度数据模型 灵活的查询语言 不依赖分布式存储，单个服务器节点是自主的 以HTTP方式，通过pull模型拉去时间序列数据 也可以通过中间网关支持push模型 通过服务发现或者静态配置，来发现目标服务对象 支持多种多样的图表和界面展示 4、Prometheus基本原理Prometheus [prəˈmi:θi:əs, -ˌθju:s] 的基本原理是使用 Pull （抓取）的方式，通过HTTP协议周期性抓取被监控组件的Metrics 数据（监控指标数据），然后，再把这些数据保存在一个 TSDB （时间序列数据库，比如 OpenTSDB、InfluxDB 等）当中，任意组件只要提供对应的HTTP接口就可以接入监控。不需要任何SDK或者其他的集成过程。这样做非常适合做虚拟化环境监控系统，比如VM、Docker、Kubernetes等。 5、架构图6、组件说明 Prometheus Server：主要用于抓取数据和存储时序数据，在该组件上配置监控数据的采集和告警规则. Push Gateway: 主要用于短期的 jobs。由于这类 jobs 存在时间较短, 可能在 Prometheus 来 pull 之前就消失了。为此, 这类jobs 可以直接向 Prometheus server 端推送它们的 metrics. 这种方式主要用于服务层面的 metrics, 对于机器层面的 metrics, 需要使用 node exporter. Exporter: 是 Prometheus的一类数据采集组件的总称，用于暴露已有的第三方服务的 metrics 给Prometheus。 它负责从目标处搜集数据, 并将其转化为Prometheus支持的格式. 与传统的数据采集组件不同的是, 它并不向中央服务器发送数据, 而是等待中央服务器主动前来抓取. AlertManager: 用于接收promethues发出的告警做进一步处理，对告警进行聚合、下发、抑制等。常见的告警方式有：邮件，钉钉，webhook 等一些其他的工具。 Grafana: 第三方数据图表展示工具 Service Discovery: 动态发现待监控的Target，从而完成监控配置的重要组件，在容器化环境中尤为有用；该组件目前由Prometheus Server 内建支持。 每个组件都是独立工作的，不依赖其他组件。不同模块组件之间通过配置文件关联到一起，实现整个监控的功能。每个独立的模块都可以扩展，做高可用方案。 ","date":"2022-01-05","objectID":"/prometheus/:1:1","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#1什么是prometheus"},{"categories":[],"content":"一、Prometheus概述1、什么是Prometheus？Prometheus [prəˈmi:θi:əs, -ˌθju:s] 是由SoundCloud使用Go语言开发的开源监控报警系统和时间序列数据库(TSDB)。Prometheus于 2016 年加入 云原生计算基金会（CNCF），作为继Kubernetes之后的第二个托管项目，因为kubernetes的流行带动了prometheus的发展。 2、时间序列数据什么是时间序列数据？ 时间序列数据(TimeSeries Data):按照时间顺序记录系统、设备状态变化的数据被称为时序数据。 应用的场景很多, 如： 无人驾驶车辆运行中要记录的经度，纬度，速度，方向，旁边物体的距离等等。每时每刻都要将数据记录下来做分析。 某一个地区的各车辆的行驶轨迹数据 传统证券行业实时交易数据 实时运维监控数据，CPU、内存等实时数据 时间序列数据特点： 性能好 关系型数据库对于大规模数据的处理性能糟糕。NOSQL可以比较好的处理大规模数据，让依然比不上时间序列数据库。 存储成本低 高效的压缩算法，节省存储空间，有效降低IO Prometheus有着非常高效的时间序列数据存储方法，每个采样数据仅仅占用3.5byte左右空间，上百万条时间序列，30秒间隔，保留60天，大概花了200多G（来自官方数据) 3、Prometheus的主要特征 多维度数据模型 灵活的查询语言 不依赖分布式存储，单个服务器节点是自主的 以HTTP方式，通过pull模型拉去时间序列数据 也可以通过中间网关支持push模型 通过服务发现或者静态配置，来发现目标服务对象 支持多种多样的图表和界面展示 4、Prometheus基本原理Prometheus [prəˈmi:θi:əs, -ˌθju:s] 的基本原理是使用 Pull （抓取）的方式，通过HTTP协议周期性抓取被监控组件的Metrics 数据（监控指标数据），然后，再把这些数据保存在一个 TSDB （时间序列数据库，比如 OpenTSDB、InfluxDB 等）当中，任意组件只要提供对应的HTTP接口就可以接入监控。不需要任何SDK或者其他的集成过程。这样做非常适合做虚拟化环境监控系统，比如VM、Docker、Kubernetes等。 5、架构图6、组件说明 Prometheus Server：主要用于抓取数据和存储时序数据，在该组件上配置监控数据的采集和告警规则. Push Gateway: 主要用于短期的 jobs。由于这类 jobs 存在时间较短, 可能在 Prometheus 来 pull 之前就消失了。为此, 这类jobs 可以直接向 Prometheus server 端推送它们的 metrics. 这种方式主要用于服务层面的 metrics, 对于机器层面的 metrics, 需要使用 node exporter. Exporter: 是 Prometheus的一类数据采集组件的总称，用于暴露已有的第三方服务的 metrics 给Prometheus。 它负责从目标处搜集数据, 并将其转化为Prometheus支持的格式. 与传统的数据采集组件不同的是, 它并不向中央服务器发送数据, 而是等待中央服务器主动前来抓取. AlertManager: 用于接收promethues发出的告警做进一步处理，对告警进行聚合、下发、抑制等。常见的告警方式有：邮件，钉钉，webhook 等一些其他的工具。 Grafana: 第三方数据图表展示工具 Service Discovery: 动态发现待监控的Target，从而完成监控配置的重要组件，在容器化环境中尤为有用；该组件目前由Prometheus Server 内建支持。 每个组件都是独立工作的，不依赖其他组件。不同模块组件之间通过配置文件关联到一起，实现整个监控的功能。每个独立的模块都可以扩展，做高可用方案。 ","date":"2022-01-05","objectID":"/prometheus/:1:1","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#2时间序列数据"},{"categories":[],"content":"一、Prometheus概述1、什么是Prometheus？Prometheus [prəˈmi:θi:əs, -ˌθju:s] 是由SoundCloud使用Go语言开发的开源监控报警系统和时间序列数据库(TSDB)。Prometheus于 2016 年加入 云原生计算基金会（CNCF），作为继Kubernetes之后的第二个托管项目，因为kubernetes的流行带动了prometheus的发展。 2、时间序列数据什么是时间序列数据？ 时间序列数据(TimeSeries Data):按照时间顺序记录系统、设备状态变化的数据被称为时序数据。 应用的场景很多, 如： 无人驾驶车辆运行中要记录的经度，纬度，速度，方向，旁边物体的距离等等。每时每刻都要将数据记录下来做分析。 某一个地区的各车辆的行驶轨迹数据 传统证券行业实时交易数据 实时运维监控数据，CPU、内存等实时数据 时间序列数据特点： 性能好 关系型数据库对于大规模数据的处理性能糟糕。NOSQL可以比较好的处理大规模数据，让依然比不上时间序列数据库。 存储成本低 高效的压缩算法，节省存储空间，有效降低IO Prometheus有着非常高效的时间序列数据存储方法，每个采样数据仅仅占用3.5byte左右空间，上百万条时间序列，30秒间隔，保留60天，大概花了200多G（来自官方数据) 3、Prometheus的主要特征 多维度数据模型 灵活的查询语言 不依赖分布式存储，单个服务器节点是自主的 以HTTP方式，通过pull模型拉去时间序列数据 也可以通过中间网关支持push模型 通过服务发现或者静态配置，来发现目标服务对象 支持多种多样的图表和界面展示 4、Prometheus基本原理Prometheus [prəˈmi:θi:əs, -ˌθju:s] 的基本原理是使用 Pull （抓取）的方式，通过HTTP协议周期性抓取被监控组件的Metrics 数据（监控指标数据），然后，再把这些数据保存在一个 TSDB （时间序列数据库，比如 OpenTSDB、InfluxDB 等）当中，任意组件只要提供对应的HTTP接口就可以接入监控。不需要任何SDK或者其他的集成过程。这样做非常适合做虚拟化环境监控系统，比如VM、Docker、Kubernetes等。 5、架构图6、组件说明 Prometheus Server：主要用于抓取数据和存储时序数据，在该组件上配置监控数据的采集和告警规则. Push Gateway: 主要用于短期的 jobs。由于这类 jobs 存在时间较短, 可能在 Prometheus 来 pull 之前就消失了。为此, 这类jobs 可以直接向 Prometheus server 端推送它们的 metrics. 这种方式主要用于服务层面的 metrics, 对于机器层面的 metrics, 需要使用 node exporter. Exporter: 是 Prometheus的一类数据采集组件的总称，用于暴露已有的第三方服务的 metrics 给Prometheus。 它负责从目标处搜集数据, 并将其转化为Prometheus支持的格式. 与传统的数据采集组件不同的是, 它并不向中央服务器发送数据, 而是等待中央服务器主动前来抓取. AlertManager: 用于接收promethues发出的告警做进一步处理，对告警进行聚合、下发、抑制等。常见的告警方式有：邮件，钉钉，webhook 等一些其他的工具。 Grafana: 第三方数据图表展示工具 Service Discovery: 动态发现待监控的Target，从而完成监控配置的重要组件，在容器化环境中尤为有用；该组件目前由Prometheus Server 内建支持。 每个组件都是独立工作的，不依赖其他组件。不同模块组件之间通过配置文件关联到一起，实现整个监控的功能。每个独立的模块都可以扩展，做高可用方案。 ","date":"2022-01-05","objectID":"/prometheus/:1:1","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#3prometheus的主要特征"},{"categories":[],"content":"一、Prometheus概述1、什么是Prometheus？Prometheus [prəˈmi:θi:əs, -ˌθju:s] 是由SoundCloud使用Go语言开发的开源监控报警系统和时间序列数据库(TSDB)。Prometheus于 2016 年加入 云原生计算基金会（CNCF），作为继Kubernetes之后的第二个托管项目，因为kubernetes的流行带动了prometheus的发展。 2、时间序列数据什么是时间序列数据？ 时间序列数据(TimeSeries Data):按照时间顺序记录系统、设备状态变化的数据被称为时序数据。 应用的场景很多, 如： 无人驾驶车辆运行中要记录的经度，纬度，速度，方向，旁边物体的距离等等。每时每刻都要将数据记录下来做分析。 某一个地区的各车辆的行驶轨迹数据 传统证券行业实时交易数据 实时运维监控数据，CPU、内存等实时数据 时间序列数据特点： 性能好 关系型数据库对于大规模数据的处理性能糟糕。NOSQL可以比较好的处理大规模数据，让依然比不上时间序列数据库。 存储成本低 高效的压缩算法，节省存储空间，有效降低IO Prometheus有着非常高效的时间序列数据存储方法，每个采样数据仅仅占用3.5byte左右空间，上百万条时间序列，30秒间隔，保留60天，大概花了200多G（来自官方数据) 3、Prometheus的主要特征 多维度数据模型 灵活的查询语言 不依赖分布式存储，单个服务器节点是自主的 以HTTP方式，通过pull模型拉去时间序列数据 也可以通过中间网关支持push模型 通过服务发现或者静态配置，来发现目标服务对象 支持多种多样的图表和界面展示 4、Prometheus基本原理Prometheus [prəˈmi:θi:əs, -ˌθju:s] 的基本原理是使用 Pull （抓取）的方式，通过HTTP协议周期性抓取被监控组件的Metrics 数据（监控指标数据），然后，再把这些数据保存在一个 TSDB （时间序列数据库，比如 OpenTSDB、InfluxDB 等）当中，任意组件只要提供对应的HTTP接口就可以接入监控。不需要任何SDK或者其他的集成过程。这样做非常适合做虚拟化环境监控系统，比如VM、Docker、Kubernetes等。 5、架构图6、组件说明 Prometheus Server：主要用于抓取数据和存储时序数据，在该组件上配置监控数据的采集和告警规则. Push Gateway: 主要用于短期的 jobs。由于这类 jobs 存在时间较短, 可能在 Prometheus 来 pull 之前就消失了。为此, 这类jobs 可以直接向 Prometheus server 端推送它们的 metrics. 这种方式主要用于服务层面的 metrics, 对于机器层面的 metrics, 需要使用 node exporter. Exporter: 是 Prometheus的一类数据采集组件的总称，用于暴露已有的第三方服务的 metrics 给Prometheus。 它负责从目标处搜集数据, 并将其转化为Prometheus支持的格式. 与传统的数据采集组件不同的是, 它并不向中央服务器发送数据, 而是等待中央服务器主动前来抓取. AlertManager: 用于接收promethues发出的告警做进一步处理，对告警进行聚合、下发、抑制等。常见的告警方式有：邮件，钉钉，webhook 等一些其他的工具。 Grafana: 第三方数据图表展示工具 Service Discovery: 动态发现待监控的Target，从而完成监控配置的重要组件，在容器化环境中尤为有用；该组件目前由Prometheus Server 内建支持。 每个组件都是独立工作的，不依赖其他组件。不同模块组件之间通过配置文件关联到一起，实现整个监控的功能。每个独立的模块都可以扩展，做高可用方案。 ","date":"2022-01-05","objectID":"/prometheus/:1:1","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#4prometheus基本原理"},{"categories":[],"content":"一、Prometheus概述1、什么是Prometheus？Prometheus [prəˈmi:θi:əs, -ˌθju:s] 是由SoundCloud使用Go语言开发的开源监控报警系统和时间序列数据库(TSDB)。Prometheus于 2016 年加入 云原生计算基金会（CNCF），作为继Kubernetes之后的第二个托管项目，因为kubernetes的流行带动了prometheus的发展。 2、时间序列数据什么是时间序列数据？ 时间序列数据(TimeSeries Data):按照时间顺序记录系统、设备状态变化的数据被称为时序数据。 应用的场景很多, 如： 无人驾驶车辆运行中要记录的经度，纬度，速度，方向，旁边物体的距离等等。每时每刻都要将数据记录下来做分析。 某一个地区的各车辆的行驶轨迹数据 传统证券行业实时交易数据 实时运维监控数据，CPU、内存等实时数据 时间序列数据特点： 性能好 关系型数据库对于大规模数据的处理性能糟糕。NOSQL可以比较好的处理大规模数据，让依然比不上时间序列数据库。 存储成本低 高效的压缩算法，节省存储空间，有效降低IO Prometheus有着非常高效的时间序列数据存储方法，每个采样数据仅仅占用3.5byte左右空间，上百万条时间序列，30秒间隔，保留60天，大概花了200多G（来自官方数据) 3、Prometheus的主要特征 多维度数据模型 灵活的查询语言 不依赖分布式存储，单个服务器节点是自主的 以HTTP方式，通过pull模型拉去时间序列数据 也可以通过中间网关支持push模型 通过服务发现或者静态配置，来发现目标服务对象 支持多种多样的图表和界面展示 4、Prometheus基本原理Prometheus [prəˈmi:θi:əs, -ˌθju:s] 的基本原理是使用 Pull （抓取）的方式，通过HTTP协议周期性抓取被监控组件的Metrics 数据（监控指标数据），然后，再把这些数据保存在一个 TSDB （时间序列数据库，比如 OpenTSDB、InfluxDB 等）当中，任意组件只要提供对应的HTTP接口就可以接入监控。不需要任何SDK或者其他的集成过程。这样做非常适合做虚拟化环境监控系统，比如VM、Docker、Kubernetes等。 5、架构图6、组件说明 Prometheus Server：主要用于抓取数据和存储时序数据，在该组件上配置监控数据的采集和告警规则. Push Gateway: 主要用于短期的 jobs。由于这类 jobs 存在时间较短, 可能在 Prometheus 来 pull 之前就消失了。为此, 这类jobs 可以直接向 Prometheus server 端推送它们的 metrics. 这种方式主要用于服务层面的 metrics, 对于机器层面的 metrics, 需要使用 node exporter. Exporter: 是 Prometheus的一类数据采集组件的总称，用于暴露已有的第三方服务的 metrics 给Prometheus。 它负责从目标处搜集数据, 并将其转化为Prometheus支持的格式. 与传统的数据采集组件不同的是, 它并不向中央服务器发送数据, 而是等待中央服务器主动前来抓取. AlertManager: 用于接收promethues发出的告警做进一步处理，对告警进行聚合、下发、抑制等。常见的告警方式有：邮件，钉钉，webhook 等一些其他的工具。 Grafana: 第三方数据图表展示工具 Service Discovery: 动态发现待监控的Target，从而完成监控配置的重要组件，在容器化环境中尤为有用；该组件目前由Prometheus Server 内建支持。 每个组件都是独立工作的，不依赖其他组件。不同模块组件之间通过配置文件关联到一起，实现整个监控的功能。每个独立的模块都可以扩展，做高可用方案。 ","date":"2022-01-05","objectID":"/prometheus/:1:1","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#5架构图"},{"categories":[],"content":"一、Prometheus概述1、什么是Prometheus？Prometheus [prəˈmi:θi:əs, -ˌθju:s] 是由SoundCloud使用Go语言开发的开源监控报警系统和时间序列数据库(TSDB)。Prometheus于 2016 年加入 云原生计算基金会（CNCF），作为继Kubernetes之后的第二个托管项目，因为kubernetes的流行带动了prometheus的发展。 2、时间序列数据什么是时间序列数据？ 时间序列数据(TimeSeries Data):按照时间顺序记录系统、设备状态变化的数据被称为时序数据。 应用的场景很多, 如： 无人驾驶车辆运行中要记录的经度，纬度，速度，方向，旁边物体的距离等等。每时每刻都要将数据记录下来做分析。 某一个地区的各车辆的行驶轨迹数据 传统证券行业实时交易数据 实时运维监控数据，CPU、内存等实时数据 时间序列数据特点： 性能好 关系型数据库对于大规模数据的处理性能糟糕。NOSQL可以比较好的处理大规模数据，让依然比不上时间序列数据库。 存储成本低 高效的压缩算法，节省存储空间，有效降低IO Prometheus有着非常高效的时间序列数据存储方法，每个采样数据仅仅占用3.5byte左右空间，上百万条时间序列，30秒间隔，保留60天，大概花了200多G（来自官方数据) 3、Prometheus的主要特征 多维度数据模型 灵活的查询语言 不依赖分布式存储，单个服务器节点是自主的 以HTTP方式，通过pull模型拉去时间序列数据 也可以通过中间网关支持push模型 通过服务发现或者静态配置，来发现目标服务对象 支持多种多样的图表和界面展示 4、Prometheus基本原理Prometheus [prəˈmi:θi:əs, -ˌθju:s] 的基本原理是使用 Pull （抓取）的方式，通过HTTP协议周期性抓取被监控组件的Metrics 数据（监控指标数据），然后，再把这些数据保存在一个 TSDB （时间序列数据库，比如 OpenTSDB、InfluxDB 等）当中，任意组件只要提供对应的HTTP接口就可以接入监控。不需要任何SDK或者其他的集成过程。这样做非常适合做虚拟化环境监控系统，比如VM、Docker、Kubernetes等。 5、架构图6、组件说明 Prometheus Server：主要用于抓取数据和存储时序数据，在该组件上配置监控数据的采集和告警规则. Push Gateway: 主要用于短期的 jobs。由于这类 jobs 存在时间较短, 可能在 Prometheus 来 pull 之前就消失了。为此, 这类jobs 可以直接向 Prometheus server 端推送它们的 metrics. 这种方式主要用于服务层面的 metrics, 对于机器层面的 metrics, 需要使用 node exporter. Exporter: 是 Prometheus的一类数据采集组件的总称，用于暴露已有的第三方服务的 metrics 给Prometheus。 它负责从目标处搜集数据, 并将其转化为Prometheus支持的格式. 与传统的数据采集组件不同的是, 它并不向中央服务器发送数据, 而是等待中央服务器主动前来抓取. AlertManager: 用于接收promethues发出的告警做进一步处理，对告警进行聚合、下发、抑制等。常见的告警方式有：邮件，钉钉，webhook 等一些其他的工具。 Grafana: 第三方数据图表展示工具 Service Discovery: 动态发现待监控的Target，从而完成监控配置的重要组件，在容器化环境中尤为有用；该组件目前由Prometheus Server 内建支持。 每个组件都是独立工作的，不依赖其他组件。不同模块组件之间通过配置文件关联到一起，实现整个监控的功能。每个独立的模块都可以扩展，做高可用方案。 ","date":"2022-01-05","objectID":"/prometheus/:1:1","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#6组件说明"},{"categories":[],"content":"二、Prometheus 部署与配置1、安装prometheus从 https://prometheus.io/download/ 下载相应版本，安装到服务器上官网提供的是二进制版，解压就能用，不需要编译 $ tar xf prometheus-2.5.0.linuxamd64.tar.gz -C /usr/local/ $ mv /usr/local/prometheus-2.5.0.linuxamd64/ /usr/local/prometheus # 直接使用默认配置文件启动 $ /usr/local/prometheus/prometheus --config.file=\"/usr/local/prometheus/prometheus.yml\" --web.enable-lifecycle \u0026 # 启动时加上--web.enable-lifecycle启用远程热加载配置文件 # 调用指令是curl -X POST http://localhost:9090/-/reload # 确认端口(9090) $ lsof -i:9090 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME prometheu 85396 root 8u IPv6 2258519 0t0 TCP *:websm (LISTEN) 2、prometheus界面通过浏览器访问http://服务器IP:9090就可以访问到prometheus的主界面，点击Status –\u003e点Targets –\u003e可以看到只监控了prometheus server本机 访问http://10.101.1.51:9090/metrics可以查看到prometheus提供的自身 相关的metrics（指标）数据 # HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 3.6816e-05 go_gc_duration_seconds{quantile=\"0.25\"} 5.924e-05 go_gc_duration_seconds{quantile=\"0.5\"} 9.4932e-05 go_gc_duration_seconds{quantile=\"0.75\"} 0.000144405 go_gc_duration_seconds{quantile=\"1\"} 0.001375254 go_gc_duration_seconds_sum 0.036465283 go_gc_duration_seconds_count 270 # HELP go_goroutines Number of goroutines that currently exist. # TYPE go_goroutines gauge go_goroutines 31 ... ... 在主界面可以通过关键字查询监控项 3、 监控远程主机 在远程linux主机(被监控端agent1)上安装node_exporter组件，下载地址: https://prometheus.io/download/ $ tar xf node_exporter-0.16.0.linuxamd64.tar.gz -C /usr/local/ $ mv /usr/local/node_exporter-0.16.0.linuxamd64/ /usr/local/node_exporter # 里面就一个启动命令node_exporter,可以直接使用此命令启动 $ ls /usr/local/node_exporter/ LICENSE node_exporter NOTICE $ nohup /usr/local/node_exporter/node_exporter \u0026 # 确认端口(9100) $ lsof -i:9100 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME node_expo 83747 root 3u IPv6 2272614 0t0 TCP *:jetdirect (LISTEN) 通过浏览器访问http://被监控端ip:9100/metrics 就可以查看到node-exporter在被监控端收集到的信息 # HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 7.0401e-05 go_gc_duration_seconds{quantile=\"0.25\"} 7.0401e-05 go_gc_duration_seconds{quantile=\"0.5\"} 0.001011446 go_gc_duration_seconds{quantile=\"0.75\"} 0.001011446 go_gc_duration_seconds{quantile=\"1\"} 0.001011446 go_gc_duration_seconds_sum 0.001081847 go_gc_duration_seconds_count 2 # HELP go_goroutines Number of goroutines that currently exist. # TYPE go_goroutines gauge go_goroutines 8 # HELP go_info Information about the Go environment. # TYPE go_info gauge go_info{version=\"go1.16.7\"} 1 # HELP go_memstats_alloc_bytes Number of bytes allocated and still in use. # TYPE go_memstats_alloc_bytes gauge 回到prometheus服务器的配置文件里添加被监控机器的配置段 # 在yml文件的最后添加被监控器的配置段 $ vim /usr/local/prometheus.yml - job_name: \"node-exporter\" # 添加新的监控项 static_configs: - targets: [\"10.101.1.53:9100\"] # 修改完成后重新加载配置文件 $ curl -X POST http://localhost:9090/-/reload level=info ts=2021-10-15T08:41:40.889Z caller=main.go:1016 msg=\"Completed loading of configuration file\" filename=/usr/local/prometheus/prometheus.yml 回到web界面查看targets，可以看到多了一台监控目标 4、监控远程MySQL 在被管理机agent1上安装mysqld_exporter组件，下载地址: https://prometheus.io/download/。操作和监控远程主机类似 # 安装mysqld_exporter组件 [root@agent1 ~]# tar xf mysqld_exporter-0.11.0.linuxamd64. tar.gz -C /usr/local/ [root@agent1 ~]# mv /usr/local/mysqld_exporter-0.11.0.linux-amd64/ /usr/local/mysqld_exporter [root@agent1 ~]# ls /usr/local/mysqld_exporter/ LICENSE mysqld_exporter NOTICE # 安装mariadb数据库,并授权 [root@agent1 ~]# yum install mariadb\\* -y [root@agent1 ~]# systemctl restart mariadb [root@agent1 ~]# systemctl enable mariadb [root@agent1 ~]# mysql MariaDB [(none)]\u003e grant select,replication client,process ON *.* to 'mysql_monitor'@'localhost' identified by '123'; (注意:授权ip为localhost，因为不是prometheus服务器来直接找mariadb获取数据，而是prometheus服务器找mysql_exporter,mysql_exporter再找mariadb。所以这个localhost是指的mysql_exporter的IP) MariaDB [(none)]\u003e flush privileges; # 查询权限授予的表 MariaDB [(none)]\u003e select * fr","date":"2022-01-05","objectID":"/prometheus/:1:2","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#二prometheus-部署与配置"},{"categories":[],"content":"二、Prometheus 部署与配置1、安装prometheus从 https://prometheus.io/download/ 下载相应版本，安装到服务器上官网提供的是二进制版，解压就能用，不需要编译 $ tar xf prometheus-2.5.0.linuxamd64.tar.gz -C /usr/local/ $ mv /usr/local/prometheus-2.5.0.linuxamd64/ /usr/local/prometheus # 直接使用默认配置文件启动 $ /usr/local/prometheus/prometheus --config.file=\"/usr/local/prometheus/prometheus.yml\" --web.enable-lifecycle \u0026 # 启动时加上--web.enable-lifecycle启用远程热加载配置文件 # 调用指令是curl -X POST http://localhost:9090/-/reload # 确认端口(9090) $ lsof -i:9090 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME prometheu 85396 root 8u IPv6 2258519 0t0 TCP *:websm (LISTEN) 2、prometheus界面通过浏览器访问http://服务器IP:9090就可以访问到prometheus的主界面，点击Status –点Targets –可以看到只监控了prometheus server本机 访问http://10.101.1.51:9090/metrics可以查看到prometheus提供的自身 相关的metrics（指标）数据 # HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 3.6816e-05 go_gc_duration_seconds{quantile=\"0.25\"} 5.924e-05 go_gc_duration_seconds{quantile=\"0.5\"} 9.4932e-05 go_gc_duration_seconds{quantile=\"0.75\"} 0.000144405 go_gc_duration_seconds{quantile=\"1\"} 0.001375254 go_gc_duration_seconds_sum 0.036465283 go_gc_duration_seconds_count 270 # HELP go_goroutines Number of goroutines that currently exist. # TYPE go_goroutines gauge go_goroutines 31 ... ... 在主界面可以通过关键字查询监控项 3、 监控远程主机 在远程linux主机(被监控端agent1)上安装node_exporter组件，下载地址: https://prometheus.io/download/ $ tar xf node_exporter-0.16.0.linuxamd64.tar.gz -C /usr/local/ $ mv /usr/local/node_exporter-0.16.0.linuxamd64/ /usr/local/node_exporter # 里面就一个启动命令node_exporter,可以直接使用此命令启动 $ ls /usr/local/node_exporter/ LICENSE node_exporter NOTICE $ nohup /usr/local/node_exporter/node_exporter \u0026 # 确认端口(9100) $ lsof -i:9100 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME node_expo 83747 root 3u IPv6 2272614 0t0 TCP *:jetdirect (LISTEN) 通过浏览器访问http://被监控端ip:9100/metrics 就可以查看到node-exporter在被监控端收集到的信息 # HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 7.0401e-05 go_gc_duration_seconds{quantile=\"0.25\"} 7.0401e-05 go_gc_duration_seconds{quantile=\"0.5\"} 0.001011446 go_gc_duration_seconds{quantile=\"0.75\"} 0.001011446 go_gc_duration_seconds{quantile=\"1\"} 0.001011446 go_gc_duration_seconds_sum 0.001081847 go_gc_duration_seconds_count 2 # HELP go_goroutines Number of goroutines that currently exist. # TYPE go_goroutines gauge go_goroutines 8 # HELP go_info Information about the Go environment. # TYPE go_info gauge go_info{version=\"go1.16.7\"} 1 # HELP go_memstats_alloc_bytes Number of bytes allocated and still in use. # TYPE go_memstats_alloc_bytes gauge 回到prometheus服务器的配置文件里添加被监控机器的配置段 # 在yml文件的最后添加被监控器的配置段 $ vim /usr/local/prometheus.yml - job_name: \"node-exporter\" # 添加新的监控项 static_configs: - targets: [\"10.101.1.53:9100\"] # 修改完成后重新加载配置文件 $ curl -X POST http://localhost:9090/-/reload level=info ts=2021-10-15T08:41:40.889Z caller=main.go:1016 msg=\"Completed loading of configuration file\" filename=/usr/local/prometheus/prometheus.yml 回到web界面查看targets，可以看到多了一台监控目标 4、监控远程MySQL 在被管理机agent1上安装mysqld_exporter组件，下载地址: https://prometheus.io/download/。操作和监控远程主机类似 # 安装mysqld_exporter组件 [root@agent1 ~]# tar xf mysqld_exporter-0.11.0.linuxamd64. tar.gz -C /usr/local/ [root@agent1 ~]# mv /usr/local/mysqld_exporter-0.11.0.linux-amd64/ /usr/local/mysqld_exporter [root@agent1 ~]# ls /usr/local/mysqld_exporter/ LICENSE mysqld_exporter NOTICE # 安装mariadb数据库,并授权 [root@agent1 ~]# yum install mariadb\\* -y [root@agent1 ~]# systemctl restart mariadb [root@agent1 ~]# systemctl enable mariadb [root@agent1 ~]# mysql MariaDB [(none)] grant select,replication client,process ON *.* to 'mysql_monitor'@'localhost' identified by '123'; (注意:授权ip为localhost，因为不是prometheus服务器来直接找mariadb获取数据，而是prometheus服务器找mysql_exporter,mysql_exporter再找mariadb。所以这个localhost是指的mysql_exporter的IP) MariaDB [(none)] flush privileges; # 查询权限授予的表 MariaDB [(none)] select * fr","date":"2022-01-05","objectID":"/prometheus/:1:2","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#1安装prometheus"},{"categories":[],"content":"二、Prometheus 部署与配置1、安装prometheus从 https://prometheus.io/download/ 下载相应版本，安装到服务器上官网提供的是二进制版，解压就能用，不需要编译 $ tar xf prometheus-2.5.0.linuxamd64.tar.gz -C /usr/local/ $ mv /usr/local/prometheus-2.5.0.linuxamd64/ /usr/local/prometheus # 直接使用默认配置文件启动 $ /usr/local/prometheus/prometheus --config.file=\"/usr/local/prometheus/prometheus.yml\" --web.enable-lifecycle \u0026 # 启动时加上--web.enable-lifecycle启用远程热加载配置文件 # 调用指令是curl -X POST http://localhost:9090/-/reload # 确认端口(9090) $ lsof -i:9090 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME prometheu 85396 root 8u IPv6 2258519 0t0 TCP *:websm (LISTEN) 2、prometheus界面通过浏览器访问http://服务器IP:9090就可以访问到prometheus的主界面，点击Status –点Targets –可以看到只监控了prometheus server本机 访问http://10.101.1.51:9090/metrics可以查看到prometheus提供的自身 相关的metrics（指标）数据 # HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 3.6816e-05 go_gc_duration_seconds{quantile=\"0.25\"} 5.924e-05 go_gc_duration_seconds{quantile=\"0.5\"} 9.4932e-05 go_gc_duration_seconds{quantile=\"0.75\"} 0.000144405 go_gc_duration_seconds{quantile=\"1\"} 0.001375254 go_gc_duration_seconds_sum 0.036465283 go_gc_duration_seconds_count 270 # HELP go_goroutines Number of goroutines that currently exist. # TYPE go_goroutines gauge go_goroutines 31 ... ... 在主界面可以通过关键字查询监控项 3、 监控远程主机 在远程linux主机(被监控端agent1)上安装node_exporter组件，下载地址: https://prometheus.io/download/ $ tar xf node_exporter-0.16.0.linuxamd64.tar.gz -C /usr/local/ $ mv /usr/local/node_exporter-0.16.0.linuxamd64/ /usr/local/node_exporter # 里面就一个启动命令node_exporter,可以直接使用此命令启动 $ ls /usr/local/node_exporter/ LICENSE node_exporter NOTICE $ nohup /usr/local/node_exporter/node_exporter \u0026 # 确认端口(9100) $ lsof -i:9100 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME node_expo 83747 root 3u IPv6 2272614 0t0 TCP *:jetdirect (LISTEN) 通过浏览器访问http://被监控端ip:9100/metrics 就可以查看到node-exporter在被监控端收集到的信息 # HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 7.0401e-05 go_gc_duration_seconds{quantile=\"0.25\"} 7.0401e-05 go_gc_duration_seconds{quantile=\"0.5\"} 0.001011446 go_gc_duration_seconds{quantile=\"0.75\"} 0.001011446 go_gc_duration_seconds{quantile=\"1\"} 0.001011446 go_gc_duration_seconds_sum 0.001081847 go_gc_duration_seconds_count 2 # HELP go_goroutines Number of goroutines that currently exist. # TYPE go_goroutines gauge go_goroutines 8 # HELP go_info Information about the Go environment. # TYPE go_info gauge go_info{version=\"go1.16.7\"} 1 # HELP go_memstats_alloc_bytes Number of bytes allocated and still in use. # TYPE go_memstats_alloc_bytes gauge 回到prometheus服务器的配置文件里添加被监控机器的配置段 # 在yml文件的最后添加被监控器的配置段 $ vim /usr/local/prometheus.yml - job_name: \"node-exporter\" # 添加新的监控项 static_configs: - targets: [\"10.101.1.53:9100\"] # 修改完成后重新加载配置文件 $ curl -X POST http://localhost:9090/-/reload level=info ts=2021-10-15T08:41:40.889Z caller=main.go:1016 msg=\"Completed loading of configuration file\" filename=/usr/local/prometheus/prometheus.yml 回到web界面查看targets，可以看到多了一台监控目标 4、监控远程MySQL 在被管理机agent1上安装mysqld_exporter组件，下载地址: https://prometheus.io/download/。操作和监控远程主机类似 # 安装mysqld_exporter组件 [root@agent1 ~]# tar xf mysqld_exporter-0.11.0.linuxamd64. tar.gz -C /usr/local/ [root@agent1 ~]# mv /usr/local/mysqld_exporter-0.11.0.linux-amd64/ /usr/local/mysqld_exporter [root@agent1 ~]# ls /usr/local/mysqld_exporter/ LICENSE mysqld_exporter NOTICE # 安装mariadb数据库,并授权 [root@agent1 ~]# yum install mariadb\\* -y [root@agent1 ~]# systemctl restart mariadb [root@agent1 ~]# systemctl enable mariadb [root@agent1 ~]# mysql MariaDB [(none)] grant select,replication client,process ON *.* to 'mysql_monitor'@'localhost' identified by '123'; (注意:授权ip为localhost，因为不是prometheus服务器来直接找mariadb获取数据，而是prometheus服务器找mysql_exporter,mysql_exporter再找mariadb。所以这个localhost是指的mysql_exporter的IP) MariaDB [(none)] flush privileges; # 查询权限授予的表 MariaDB [(none)] select * fr","date":"2022-01-05","objectID":"/prometheus/:1:2","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#2prometheus界面"},{"categories":[],"content":"二、Prometheus 部署与配置1、安装prometheus从 https://prometheus.io/download/ 下载相应版本，安装到服务器上官网提供的是二进制版，解压就能用，不需要编译 $ tar xf prometheus-2.5.0.linuxamd64.tar.gz -C /usr/local/ $ mv /usr/local/prometheus-2.5.0.linuxamd64/ /usr/local/prometheus # 直接使用默认配置文件启动 $ /usr/local/prometheus/prometheus --config.file=\"/usr/local/prometheus/prometheus.yml\" --web.enable-lifecycle \u0026 # 启动时加上--web.enable-lifecycle启用远程热加载配置文件 # 调用指令是curl -X POST http://localhost:9090/-/reload # 确认端口(9090) $ lsof -i:9090 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME prometheu 85396 root 8u IPv6 2258519 0t0 TCP *:websm (LISTEN) 2、prometheus界面通过浏览器访问http://服务器IP:9090就可以访问到prometheus的主界面，点击Status –点Targets –可以看到只监控了prometheus server本机 访问http://10.101.1.51:9090/metrics可以查看到prometheus提供的自身 相关的metrics（指标）数据 # HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 3.6816e-05 go_gc_duration_seconds{quantile=\"0.25\"} 5.924e-05 go_gc_duration_seconds{quantile=\"0.5\"} 9.4932e-05 go_gc_duration_seconds{quantile=\"0.75\"} 0.000144405 go_gc_duration_seconds{quantile=\"1\"} 0.001375254 go_gc_duration_seconds_sum 0.036465283 go_gc_duration_seconds_count 270 # HELP go_goroutines Number of goroutines that currently exist. # TYPE go_goroutines gauge go_goroutines 31 ... ... 在主界面可以通过关键字查询监控项 3、 监控远程主机 在远程linux主机(被监控端agent1)上安装node_exporter组件，下载地址: https://prometheus.io/download/ $ tar xf node_exporter-0.16.0.linuxamd64.tar.gz -C /usr/local/ $ mv /usr/local/node_exporter-0.16.0.linuxamd64/ /usr/local/node_exporter # 里面就一个启动命令node_exporter,可以直接使用此命令启动 $ ls /usr/local/node_exporter/ LICENSE node_exporter NOTICE $ nohup /usr/local/node_exporter/node_exporter \u0026 # 确认端口(9100) $ lsof -i:9100 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME node_expo 83747 root 3u IPv6 2272614 0t0 TCP *:jetdirect (LISTEN) 通过浏览器访问http://被监控端ip:9100/metrics 就可以查看到node-exporter在被监控端收集到的信息 # HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 7.0401e-05 go_gc_duration_seconds{quantile=\"0.25\"} 7.0401e-05 go_gc_duration_seconds{quantile=\"0.5\"} 0.001011446 go_gc_duration_seconds{quantile=\"0.75\"} 0.001011446 go_gc_duration_seconds{quantile=\"1\"} 0.001011446 go_gc_duration_seconds_sum 0.001081847 go_gc_duration_seconds_count 2 # HELP go_goroutines Number of goroutines that currently exist. # TYPE go_goroutines gauge go_goroutines 8 # HELP go_info Information about the Go environment. # TYPE go_info gauge go_info{version=\"go1.16.7\"} 1 # HELP go_memstats_alloc_bytes Number of bytes allocated and still in use. # TYPE go_memstats_alloc_bytes gauge 回到prometheus服务器的配置文件里添加被监控机器的配置段 # 在yml文件的最后添加被监控器的配置段 $ vim /usr/local/prometheus.yml - job_name: \"node-exporter\" # 添加新的监控项 static_configs: - targets: [\"10.101.1.53:9100\"] # 修改完成后重新加载配置文件 $ curl -X POST http://localhost:9090/-/reload level=info ts=2021-10-15T08:41:40.889Z caller=main.go:1016 msg=\"Completed loading of configuration file\" filename=/usr/local/prometheus/prometheus.yml 回到web界面查看targets，可以看到多了一台监控目标 4、监控远程MySQL 在被管理机agent1上安装mysqld_exporter组件，下载地址: https://prometheus.io/download/。操作和监控远程主机类似 # 安装mysqld_exporter组件 [root@agent1 ~]# tar xf mysqld_exporter-0.11.0.linuxamd64. tar.gz -C /usr/local/ [root@agent1 ~]# mv /usr/local/mysqld_exporter-0.11.0.linux-amd64/ /usr/local/mysqld_exporter [root@agent1 ~]# ls /usr/local/mysqld_exporter/ LICENSE mysqld_exporter NOTICE # 安装mariadb数据库,并授权 [root@agent1 ~]# yum install mariadb\\* -y [root@agent1 ~]# systemctl restart mariadb [root@agent1 ~]# systemctl enable mariadb [root@agent1 ~]# mysql MariaDB [(none)] grant select,replication client,process ON *.* to 'mysql_monitor'@'localhost' identified by '123'; (注意:授权ip为localhost，因为不是prometheus服务器来直接找mariadb获取数据，而是prometheus服务器找mysql_exporter,mysql_exporter再找mariadb。所以这个localhost是指的mysql_exporter的IP) MariaDB [(none)] flush privileges; # 查询权限授予的表 MariaDB [(none)] select * fr","date":"2022-01-05","objectID":"/prometheus/:1:2","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#3-监控远程主机"},{"categories":[],"content":"二、Prometheus 部署与配置1、安装prometheus从 https://prometheus.io/download/ 下载相应版本，安装到服务器上官网提供的是二进制版，解压就能用，不需要编译 $ tar xf prometheus-2.5.0.linuxamd64.tar.gz -C /usr/local/ $ mv /usr/local/prometheus-2.5.0.linuxamd64/ /usr/local/prometheus # 直接使用默认配置文件启动 $ /usr/local/prometheus/prometheus --config.file=\"/usr/local/prometheus/prometheus.yml\" --web.enable-lifecycle \u0026 # 启动时加上--web.enable-lifecycle启用远程热加载配置文件 # 调用指令是curl -X POST http://localhost:9090/-/reload # 确认端口(9090) $ lsof -i:9090 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME prometheu 85396 root 8u IPv6 2258519 0t0 TCP *:websm (LISTEN) 2、prometheus界面通过浏览器访问http://服务器IP:9090就可以访问到prometheus的主界面，点击Status –点Targets –可以看到只监控了prometheus server本机 访问http://10.101.1.51:9090/metrics可以查看到prometheus提供的自身 相关的metrics（指标）数据 # HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 3.6816e-05 go_gc_duration_seconds{quantile=\"0.25\"} 5.924e-05 go_gc_duration_seconds{quantile=\"0.5\"} 9.4932e-05 go_gc_duration_seconds{quantile=\"0.75\"} 0.000144405 go_gc_duration_seconds{quantile=\"1\"} 0.001375254 go_gc_duration_seconds_sum 0.036465283 go_gc_duration_seconds_count 270 # HELP go_goroutines Number of goroutines that currently exist. # TYPE go_goroutines gauge go_goroutines 31 ... ... 在主界面可以通过关键字查询监控项 3、 监控远程主机 在远程linux主机(被监控端agent1)上安装node_exporter组件，下载地址: https://prometheus.io/download/ $ tar xf node_exporter-0.16.0.linuxamd64.tar.gz -C /usr/local/ $ mv /usr/local/node_exporter-0.16.0.linuxamd64/ /usr/local/node_exporter # 里面就一个启动命令node_exporter,可以直接使用此命令启动 $ ls /usr/local/node_exporter/ LICENSE node_exporter NOTICE $ nohup /usr/local/node_exporter/node_exporter \u0026 # 确认端口(9100) $ lsof -i:9100 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME node_expo 83747 root 3u IPv6 2272614 0t0 TCP *:jetdirect (LISTEN) 通过浏览器访问http://被监控端ip:9100/metrics 就可以查看到node-exporter在被监控端收集到的信息 # HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 7.0401e-05 go_gc_duration_seconds{quantile=\"0.25\"} 7.0401e-05 go_gc_duration_seconds{quantile=\"0.5\"} 0.001011446 go_gc_duration_seconds{quantile=\"0.75\"} 0.001011446 go_gc_duration_seconds{quantile=\"1\"} 0.001011446 go_gc_duration_seconds_sum 0.001081847 go_gc_duration_seconds_count 2 # HELP go_goroutines Number of goroutines that currently exist. # TYPE go_goroutines gauge go_goroutines 8 # HELP go_info Information about the Go environment. # TYPE go_info gauge go_info{version=\"go1.16.7\"} 1 # HELP go_memstats_alloc_bytes Number of bytes allocated and still in use. # TYPE go_memstats_alloc_bytes gauge 回到prometheus服务器的配置文件里添加被监控机器的配置段 # 在yml文件的最后添加被监控器的配置段 $ vim /usr/local/prometheus.yml - job_name: \"node-exporter\" # 添加新的监控项 static_configs: - targets: [\"10.101.1.53:9100\"] # 修改完成后重新加载配置文件 $ curl -X POST http://localhost:9090/-/reload level=info ts=2021-10-15T08:41:40.889Z caller=main.go:1016 msg=\"Completed loading of configuration file\" filename=/usr/local/prometheus/prometheus.yml 回到web界面查看targets，可以看到多了一台监控目标 4、监控远程MySQL 在被管理机agent1上安装mysqld_exporter组件，下载地址: https://prometheus.io/download/。操作和监控远程主机类似 # 安装mysqld_exporter组件 [root@agent1 ~]# tar xf mysqld_exporter-0.11.0.linuxamd64. tar.gz -C /usr/local/ [root@agent1 ~]# mv /usr/local/mysqld_exporter-0.11.0.linux-amd64/ /usr/local/mysqld_exporter [root@agent1 ~]# ls /usr/local/mysqld_exporter/ LICENSE mysqld_exporter NOTICE # 安装mariadb数据库,并授权 [root@agent1 ~]# yum install mariadb\\* -y [root@agent1 ~]# systemctl restart mariadb [root@agent1 ~]# systemctl enable mariadb [root@agent1 ~]# mysql MariaDB [(none)] grant select,replication client,process ON *.* to 'mysql_monitor'@'localhost' identified by '123'; (注意:授权ip为localhost，因为不是prometheus服务器来直接找mariadb获取数据，而是prometheus服务器找mysql_exporter,mysql_exporter再找mariadb。所以这个localhost是指的mysql_exporter的IP) MariaDB [(none)] flush privileges; # 查询权限授予的表 MariaDB [(none)] select * fr","date":"2022-01-05","objectID":"/prometheus/:1:2","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#4监控远程mysql"},{"categories":[],"content":"二、Prometheus 部署与配置1、安装prometheus从 https://prometheus.io/download/ 下载相应版本，安装到服务器上官网提供的是二进制版，解压就能用，不需要编译 $ tar xf prometheus-2.5.0.linuxamd64.tar.gz -C /usr/local/ $ mv /usr/local/prometheus-2.5.0.linuxamd64/ /usr/local/prometheus # 直接使用默认配置文件启动 $ /usr/local/prometheus/prometheus --config.file=\"/usr/local/prometheus/prometheus.yml\" --web.enable-lifecycle \u0026 # 启动时加上--web.enable-lifecycle启用远程热加载配置文件 # 调用指令是curl -X POST http://localhost:9090/-/reload # 确认端口(9090) $ lsof -i:9090 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME prometheu 85396 root 8u IPv6 2258519 0t0 TCP *:websm (LISTEN) 2、prometheus界面通过浏览器访问http://服务器IP:9090就可以访问到prometheus的主界面，点击Status –点Targets –可以看到只监控了prometheus server本机 访问http://10.101.1.51:9090/metrics可以查看到prometheus提供的自身 相关的metrics（指标）数据 # HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 3.6816e-05 go_gc_duration_seconds{quantile=\"0.25\"} 5.924e-05 go_gc_duration_seconds{quantile=\"0.5\"} 9.4932e-05 go_gc_duration_seconds{quantile=\"0.75\"} 0.000144405 go_gc_duration_seconds{quantile=\"1\"} 0.001375254 go_gc_duration_seconds_sum 0.036465283 go_gc_duration_seconds_count 270 # HELP go_goroutines Number of goroutines that currently exist. # TYPE go_goroutines gauge go_goroutines 31 ... ... 在主界面可以通过关键字查询监控项 3、 监控远程主机 在远程linux主机(被监控端agent1)上安装node_exporter组件，下载地址: https://prometheus.io/download/ $ tar xf node_exporter-0.16.0.linuxamd64.tar.gz -C /usr/local/ $ mv /usr/local/node_exporter-0.16.0.linuxamd64/ /usr/local/node_exporter # 里面就一个启动命令node_exporter,可以直接使用此命令启动 $ ls /usr/local/node_exporter/ LICENSE node_exporter NOTICE $ nohup /usr/local/node_exporter/node_exporter \u0026 # 确认端口(9100) $ lsof -i:9100 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME node_expo 83747 root 3u IPv6 2272614 0t0 TCP *:jetdirect (LISTEN) 通过浏览器访问http://被监控端ip:9100/metrics 就可以查看到node-exporter在被监控端收集到的信息 # HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 7.0401e-05 go_gc_duration_seconds{quantile=\"0.25\"} 7.0401e-05 go_gc_duration_seconds{quantile=\"0.5\"} 0.001011446 go_gc_duration_seconds{quantile=\"0.75\"} 0.001011446 go_gc_duration_seconds{quantile=\"1\"} 0.001011446 go_gc_duration_seconds_sum 0.001081847 go_gc_duration_seconds_count 2 # HELP go_goroutines Number of goroutines that currently exist. # TYPE go_goroutines gauge go_goroutines 8 # HELP go_info Information about the Go environment. # TYPE go_info gauge go_info{version=\"go1.16.7\"} 1 # HELP go_memstats_alloc_bytes Number of bytes allocated and still in use. # TYPE go_memstats_alloc_bytes gauge 回到prometheus服务器的配置文件里添加被监控机器的配置段 # 在yml文件的最后添加被监控器的配置段 $ vim /usr/local/prometheus.yml - job_name: \"node-exporter\" # 添加新的监控项 static_configs: - targets: [\"10.101.1.53:9100\"] # 修改完成后重新加载配置文件 $ curl -X POST http://localhost:9090/-/reload level=info ts=2021-10-15T08:41:40.889Z caller=main.go:1016 msg=\"Completed loading of configuration file\" filename=/usr/local/prometheus/prometheus.yml 回到web界面查看targets，可以看到多了一台监控目标 4、监控远程MySQL 在被管理机agent1上安装mysqld_exporter组件，下载地址: https://prometheus.io/download/。操作和监控远程主机类似 # 安装mysqld_exporter组件 [root@agent1 ~]# tar xf mysqld_exporter-0.11.0.linuxamd64. tar.gz -C /usr/local/ [root@agent1 ~]# mv /usr/local/mysqld_exporter-0.11.0.linux-amd64/ /usr/local/mysqld_exporter [root@agent1 ~]# ls /usr/local/mysqld_exporter/ LICENSE mysqld_exporter NOTICE # 安装mariadb数据库,并授权 [root@agent1 ~]# yum install mariadb\\* -y [root@agent1 ~]# systemctl restart mariadb [root@agent1 ~]# systemctl enable mariadb [root@agent1 ~]# mysql MariaDB [(none)] grant select,replication client,process ON *.* to 'mysql_monitor'@'localhost' identified by '123'; (注意:授权ip为localhost，因为不是prometheus服务器来直接找mariadb获取数据，而是prometheus服务器找mysql_exporter,mysql_exporter再找mariadb。所以这个localhost是指的mysql_exporter的IP) MariaDB [(none)] flush privileges; # 查询权限授予的表 MariaDB [(none)] select * fr","date":"2022-01-05","objectID":"/prometheus/:1:2","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#5prometheu配置文件"},{"categories":[],"content":"三、Grafana可视化图形展示工具Grafana是一个开源的度量分析和可视化工具，可以通过将采集的数据分析，查询，然后进行可视化的展示,并能实现报警 安装grafana # 我这里选择的rpm包，下载后直接rpm -ivh安装就OK $ wget https://dl.grafana.com/enterprise/release/grafana-enterprise-8.2.1-1.x86_64.rpm [root@grafana ~]# rpm -ivh /root/Desktop/grafana-5.3.4- 1.x86_64.rpm # 启动服务 [root@grafana ~]# systemctl start grafana-server [root@grafana ~]# systemctl enable grafana-server # 确认端口(3000) [root@grafana ~]# lsof -i:3000 访问：http://10.101.1.52:3000，在Configuration中添加DataSource为prometheus的地址 配置dashboard grafana官方图表库有很多优秀的数据图表，可以按需求下载使用。参考网址:https://grafana.com/grafana/dashboards/。 到官网直接搜索数据源为prometheus的dashboard，下载对应的json文件（这些json文件可以看作是开发人员开发的一个监控模板），导入到grafana即可展示。 ","date":"2022-01-05","objectID":"/prometheus/:1:3","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#三grafana可视化图形展示工具"},{"categories":[],"content":"四、PromQL基本使用1、PromQL基本使用PromQL(Prometheus Query Language)是prometheus自己开发的数据查询DSL语言，语言表现力非常丰富，内置函数很多，在日常数据可视化以及rule告警中都会使用到它。我们把每个查询对象的名字叫做metrics，类似于mysql中的表名。 查询结果 瞬时数据：包含一组时序，每个时序只有一个点，例如：prometheus_http_request_total 区间数据：包含一组时序，每个时序有多个点，例如：prometheus_http_request_total [5m] 纯量数据：纯量只有一个数字，没有时序，例如：count(prometheus_http_request_total) 可以指定label的name查询，还支持算术运算。例如：+，-，*，/，比较运算：==，!=，\u003e,\u003c,\u003c=,\u003e=，逻辑运算and,or，聚合运算：sum,min,max,avg,count，内置函数：rate、irate、abs 常用的查询举例 五分钟的CPU平均使用率：100 - (avg(irate(node_cpu_seconds_total{mode= “idle”}[5m])) * 100) 可用内存百分比：(node_memory_MemAvailable_bytes / (node_memory_MemTotal_bytes)) * 100 磁盘一分钟读的速率：irate(node_disk_reads_completed_total{instance=~\"$node\"}[1m]) 可以结合grafana丰富的dashboard，编辑图表查看PromQL更好的学习PromQL语法。 2、常用函数1、rate函数rate会取指定时间范围内所有数据点，算出一组速率，然后取平均值作为结果。 单个counter类型的指标是无意义的，因为其只增不减，且重置就清零了。 rate（）函数用于计算在指定时间范围内计数器每秒增加量的平均值。 进行 rate 计算的时候是选择指定时间范围下的第一和最后一个样本进行计算，下图是表示瞬时计算的计算方式： 往往我们需要的是绘制一个图形，那么就需要进行区间查询，指定一个时间范围内进行多次计算，将结果串联起来形成一个图形： 2、irate函数irate取的是在指定时间范围内的最近两个数据点来算速率。 irate 同样用于计算区间向量的计算率，但是其反应出的是瞬时增长率。irate 函数是通过区间向量中最后两个样本数据来计算区间向量的增长速率。这种方式可以避免在时间窗口范围内的长尾问题，并且体现出更好的灵敏度，通过 irate 函数绘制的图标能够更好的反应样本数据的瞬时变化状态。 3、其他函数increase() rate()、irate() 和 increase() 函数只能输出非负值的结果，对于跟踪一个可以上升或下降的值的指标（如温度、内存或磁盘空间），可以使用 delta() 和 deriv() 函数来代替。 还有另外一个 predict_linear() 函数可以预测一个 Gauge 类型的指标在未来指定一段时间内的值，例如我们可以根据过去 15 分钟的变化情况，来预测一个小时后的磁盘使用量是多少，可以用如下所示的表达式来查询： predict_linear(demo_disk_usage_bytes{job=\"demo\"}[15m], 3600) 这个函数可以用于报警，告诉我们磁盘是否会在几个小时候内用完。 ","date":"2022-01-05","objectID":"/prometheus/:1:4","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#四promql基本使用"},{"categories":[],"content":"四、PromQL基本使用1、PromQL基本使用PromQL(Prometheus Query Language)是prometheus自己开发的数据查询DSL语言，语言表现力非常丰富，内置函数很多，在日常数据可视化以及rule告警中都会使用到它。我们把每个查询对象的名字叫做metrics，类似于mysql中的表名。 查询结果 瞬时数据：包含一组时序，每个时序只有一个点，例如：prometheus_http_request_total 区间数据：包含一组时序，每个时序有多个点，例如：prometheus_http_request_total [5m] 纯量数据：纯量只有一个数字，没有时序，例如：count(prometheus_http_request_total) 可以指定label的name查询，还支持算术运算。例如：+，-，*，/，比较运算：==，!=，,=，逻辑运算and,or，聚合运算：sum,min,max,avg,count，内置函数：rate、irate、abs 常用的查询举例 五分钟的CPU平均使用率：100 - (avg(irate(node_cpu_seconds_total{mode= “idle”}[5m])) * 100) 可用内存百分比：(node_memory_MemAvailable_bytes / (node_memory_MemTotal_bytes)) * 100 磁盘一分钟读的速率：irate(node_disk_reads_completed_total{instance=~\"$node\"}[1m]) 可以结合grafana丰富的dashboard，编辑图表查看PromQL更好的学习PromQL语法。 2、常用函数1、rate函数rate会取指定时间范围内所有数据点，算出一组速率，然后取平均值作为结果。 单个counter类型的指标是无意义的，因为其只增不减，且重置就清零了。 rate（）函数用于计算在指定时间范围内计数器每秒增加量的平均值。 进行 rate 计算的时候是选择指定时间范围下的第一和最后一个样本进行计算，下图是表示瞬时计算的计算方式： 往往我们需要的是绘制一个图形，那么就需要进行区间查询，指定一个时间范围内进行多次计算，将结果串联起来形成一个图形： 2、irate函数irate取的是在指定时间范围内的最近两个数据点来算速率。 irate 同样用于计算区间向量的计算率，但是其反应出的是瞬时增长率。irate 函数是通过区间向量中最后两个样本数据来计算区间向量的增长速率。这种方式可以避免在时间窗口范围内的长尾问题，并且体现出更好的灵敏度，通过 irate 函数绘制的图标能够更好的反应样本数据的瞬时变化状态。 3、其他函数increase() rate()、irate() 和 increase() 函数只能输出非负值的结果，对于跟踪一个可以上升或下降的值的指标（如温度、内存或磁盘空间），可以使用 delta() 和 deriv() 函数来代替。 还有另外一个 predict_linear() 函数可以预测一个 Gauge 类型的指标在未来指定一段时间内的值，例如我们可以根据过去 15 分钟的变化情况，来预测一个小时后的磁盘使用量是多少，可以用如下所示的表达式来查询： predict_linear(demo_disk_usage_bytes{job=\"demo\"}[15m], 3600) 这个函数可以用于报警，告诉我们磁盘是否会在几个小时候内用完。 ","date":"2022-01-05","objectID":"/prometheus/:1:4","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#1promql基本使用"},{"categories":[],"content":"四、PromQL基本使用1、PromQL基本使用PromQL(Prometheus Query Language)是prometheus自己开发的数据查询DSL语言，语言表现力非常丰富，内置函数很多，在日常数据可视化以及rule告警中都会使用到它。我们把每个查询对象的名字叫做metrics，类似于mysql中的表名。 查询结果 瞬时数据：包含一组时序，每个时序只有一个点，例如：prometheus_http_request_total 区间数据：包含一组时序，每个时序有多个点，例如：prometheus_http_request_total [5m] 纯量数据：纯量只有一个数字，没有时序，例如：count(prometheus_http_request_total) 可以指定label的name查询，还支持算术运算。例如：+，-，*，/，比较运算：==，!=，,=，逻辑运算and,or，聚合运算：sum,min,max,avg,count，内置函数：rate、irate、abs 常用的查询举例 五分钟的CPU平均使用率：100 - (avg(irate(node_cpu_seconds_total{mode= “idle”}[5m])) * 100) 可用内存百分比：(node_memory_MemAvailable_bytes / (node_memory_MemTotal_bytes)) * 100 磁盘一分钟读的速率：irate(node_disk_reads_completed_total{instance=~\"$node\"}[1m]) 可以结合grafana丰富的dashboard，编辑图表查看PromQL更好的学习PromQL语法。 2、常用函数1、rate函数rate会取指定时间范围内所有数据点，算出一组速率，然后取平均值作为结果。 单个counter类型的指标是无意义的，因为其只增不减，且重置就清零了。 rate（）函数用于计算在指定时间范围内计数器每秒增加量的平均值。 进行 rate 计算的时候是选择指定时间范围下的第一和最后一个样本进行计算，下图是表示瞬时计算的计算方式： 往往我们需要的是绘制一个图形，那么就需要进行区间查询，指定一个时间范围内进行多次计算，将结果串联起来形成一个图形： 2、irate函数irate取的是在指定时间范围内的最近两个数据点来算速率。 irate 同样用于计算区间向量的计算率，但是其反应出的是瞬时增长率。irate 函数是通过区间向量中最后两个样本数据来计算区间向量的增长速率。这种方式可以避免在时间窗口范围内的长尾问题，并且体现出更好的灵敏度，通过 irate 函数绘制的图标能够更好的反应样本数据的瞬时变化状态。 3、其他函数increase() rate()、irate() 和 increase() 函数只能输出非负值的结果，对于跟踪一个可以上升或下降的值的指标（如温度、内存或磁盘空间），可以使用 delta() 和 deriv() 函数来代替。 还有另外一个 predict_linear() 函数可以预测一个 Gauge 类型的指标在未来指定一段时间内的值，例如我们可以根据过去 15 分钟的变化情况，来预测一个小时后的磁盘使用量是多少，可以用如下所示的表达式来查询： predict_linear(demo_disk_usage_bytes{job=\"demo\"}[15m], 3600) 这个函数可以用于报警，告诉我们磁盘是否会在几个小时候内用完。 ","date":"2022-01-05","objectID":"/prometheus/:1:4","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#2常用函数"},{"categories":[],"content":"四、PromQL基本使用1、PromQL基本使用PromQL(Prometheus Query Language)是prometheus自己开发的数据查询DSL语言，语言表现力非常丰富，内置函数很多，在日常数据可视化以及rule告警中都会使用到它。我们把每个查询对象的名字叫做metrics，类似于mysql中的表名。 查询结果 瞬时数据：包含一组时序，每个时序只有一个点，例如：prometheus_http_request_total 区间数据：包含一组时序，每个时序有多个点，例如：prometheus_http_request_total [5m] 纯量数据：纯量只有一个数字，没有时序，例如：count(prometheus_http_request_total) 可以指定label的name查询，还支持算术运算。例如：+，-，*，/，比较运算：==，!=，,=，逻辑运算and,or，聚合运算：sum,min,max,avg,count，内置函数：rate、irate、abs 常用的查询举例 五分钟的CPU平均使用率：100 - (avg(irate(node_cpu_seconds_total{mode= “idle”}[5m])) * 100) 可用内存百分比：(node_memory_MemAvailable_bytes / (node_memory_MemTotal_bytes)) * 100 磁盘一分钟读的速率：irate(node_disk_reads_completed_total{instance=~\"$node\"}[1m]) 可以结合grafana丰富的dashboard，编辑图表查看PromQL更好的学习PromQL语法。 2、常用函数1、rate函数rate会取指定时间范围内所有数据点，算出一组速率，然后取平均值作为结果。 单个counter类型的指标是无意义的，因为其只增不减，且重置就清零了。 rate（）函数用于计算在指定时间范围内计数器每秒增加量的平均值。 进行 rate 计算的时候是选择指定时间范围下的第一和最后一个样本进行计算，下图是表示瞬时计算的计算方式： 往往我们需要的是绘制一个图形，那么就需要进行区间查询，指定一个时间范围内进行多次计算，将结果串联起来形成一个图形： 2、irate函数irate取的是在指定时间范围内的最近两个数据点来算速率。 irate 同样用于计算区间向量的计算率，但是其反应出的是瞬时增长率。irate 函数是通过区间向量中最后两个样本数据来计算区间向量的增长速率。这种方式可以避免在时间窗口范围内的长尾问题，并且体现出更好的灵敏度，通过 irate 函数绘制的图标能够更好的反应样本数据的瞬时变化状态。 3、其他函数increase() rate()、irate() 和 increase() 函数只能输出非负值的结果，对于跟踪一个可以上升或下降的值的指标（如温度、内存或磁盘空间），可以使用 delta() 和 deriv() 函数来代替。 还有另外一个 predict_linear() 函数可以预测一个 Gauge 类型的指标在未来指定一段时间内的值，例如我们可以根据过去 15 分钟的变化情况，来预测一个小时后的磁盘使用量是多少，可以用如下所示的表达式来查询： predict_linear(demo_disk_usage_bytes{job=\"demo\"}[15m], 3600) 这个函数可以用于报警，告诉我们磁盘是否会在几个小时候内用完。 ","date":"2022-01-05","objectID":"/prometheus/:1:4","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#1rate函数"},{"categories":[],"content":"四、PromQL基本使用1、PromQL基本使用PromQL(Prometheus Query Language)是prometheus自己开发的数据查询DSL语言，语言表现力非常丰富，内置函数很多，在日常数据可视化以及rule告警中都会使用到它。我们把每个查询对象的名字叫做metrics，类似于mysql中的表名。 查询结果 瞬时数据：包含一组时序，每个时序只有一个点，例如：prometheus_http_request_total 区间数据：包含一组时序，每个时序有多个点，例如：prometheus_http_request_total [5m] 纯量数据：纯量只有一个数字，没有时序，例如：count(prometheus_http_request_total) 可以指定label的name查询，还支持算术运算。例如：+，-，*，/，比较运算：==，!=，,=，逻辑运算and,or，聚合运算：sum,min,max,avg,count，内置函数：rate、irate、abs 常用的查询举例 五分钟的CPU平均使用率：100 - (avg(irate(node_cpu_seconds_total{mode= “idle”}[5m])) * 100) 可用内存百分比：(node_memory_MemAvailable_bytes / (node_memory_MemTotal_bytes)) * 100 磁盘一分钟读的速率：irate(node_disk_reads_completed_total{instance=~\"$node\"}[1m]) 可以结合grafana丰富的dashboard，编辑图表查看PromQL更好的学习PromQL语法。 2、常用函数1、rate函数rate会取指定时间范围内所有数据点，算出一组速率，然后取平均值作为结果。 单个counter类型的指标是无意义的，因为其只增不减，且重置就清零了。 rate（）函数用于计算在指定时间范围内计数器每秒增加量的平均值。 进行 rate 计算的时候是选择指定时间范围下的第一和最后一个样本进行计算，下图是表示瞬时计算的计算方式： 往往我们需要的是绘制一个图形，那么就需要进行区间查询，指定一个时间范围内进行多次计算，将结果串联起来形成一个图形： 2、irate函数irate取的是在指定时间范围内的最近两个数据点来算速率。 irate 同样用于计算区间向量的计算率，但是其反应出的是瞬时增长率。irate 函数是通过区间向量中最后两个样本数据来计算区间向量的增长速率。这种方式可以避免在时间窗口范围内的长尾问题，并且体现出更好的灵敏度，通过 irate 函数绘制的图标能够更好的反应样本数据的瞬时变化状态。 3、其他函数increase() rate()、irate() 和 increase() 函数只能输出非负值的结果，对于跟踪一个可以上升或下降的值的指标（如温度、内存或磁盘空间），可以使用 delta() 和 deriv() 函数来代替。 还有另外一个 predict_linear() 函数可以预测一个 Gauge 类型的指标在未来指定一段时间内的值，例如我们可以根据过去 15 分钟的变化情况，来预测一个小时后的磁盘使用量是多少，可以用如下所示的表达式来查询： predict_linear(demo_disk_usage_bytes{job=\"demo\"}[15m], 3600) 这个函数可以用于报警，告诉我们磁盘是否会在几个小时候内用完。 ","date":"2022-01-05","objectID":"/prometheus/:1:4","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#2irate函数"},{"categories":[],"content":"四、PromQL基本使用1、PromQL基本使用PromQL(Prometheus Query Language)是prometheus自己开发的数据查询DSL语言，语言表现力非常丰富，内置函数很多，在日常数据可视化以及rule告警中都会使用到它。我们把每个查询对象的名字叫做metrics，类似于mysql中的表名。 查询结果 瞬时数据：包含一组时序，每个时序只有一个点，例如：prometheus_http_request_total 区间数据：包含一组时序，每个时序有多个点，例如：prometheus_http_request_total [5m] 纯量数据：纯量只有一个数字，没有时序，例如：count(prometheus_http_request_total) 可以指定label的name查询，还支持算术运算。例如：+，-，*，/，比较运算：==，!=，,=，逻辑运算and,or，聚合运算：sum,min,max,avg,count，内置函数：rate、irate、abs 常用的查询举例 五分钟的CPU平均使用率：100 - (avg(irate(node_cpu_seconds_total{mode= “idle”}[5m])) * 100) 可用内存百分比：(node_memory_MemAvailable_bytes / (node_memory_MemTotal_bytes)) * 100 磁盘一分钟读的速率：irate(node_disk_reads_completed_total{instance=~\"$node\"}[1m]) 可以结合grafana丰富的dashboard，编辑图表查看PromQL更好的学习PromQL语法。 2、常用函数1、rate函数rate会取指定时间范围内所有数据点，算出一组速率，然后取平均值作为结果。 单个counter类型的指标是无意义的，因为其只增不减，且重置就清零了。 rate（）函数用于计算在指定时间范围内计数器每秒增加量的平均值。 进行 rate 计算的时候是选择指定时间范围下的第一和最后一个样本进行计算，下图是表示瞬时计算的计算方式： 往往我们需要的是绘制一个图形，那么就需要进行区间查询，指定一个时间范围内进行多次计算，将结果串联起来形成一个图形： 2、irate函数irate取的是在指定时间范围内的最近两个数据点来算速率。 irate 同样用于计算区间向量的计算率，但是其反应出的是瞬时增长率。irate 函数是通过区间向量中最后两个样本数据来计算区间向量的增长速率。这种方式可以避免在时间窗口范围内的长尾问题，并且体现出更好的灵敏度，通过 irate 函数绘制的图标能够更好的反应样本数据的瞬时变化状态。 3、其他函数increase() rate()、irate() 和 increase() 函数只能输出非负值的结果，对于跟踪一个可以上升或下降的值的指标（如温度、内存或磁盘空间），可以使用 delta() 和 deriv() 函数来代替。 还有另外一个 predict_linear() 函数可以预测一个 Gauge 类型的指标在未来指定一段时间内的值，例如我们可以根据过去 15 分钟的变化情况，来预测一个小时后的磁盘使用量是多少，可以用如下所示的表达式来查询： predict_linear(demo_disk_usage_bytes{job=\"demo\"}[15m], 3600) 这个函数可以用于报警，告诉我们磁盘是否会在几个小时候内用完。 ","date":"2022-01-05","objectID":"/prometheus/:1:4","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#3其他函数"},{"categories":[],"content":"五、高可用方案1、server高可用 部署多个相同配置的server A和B（甚至可以再加），保持相同的配置，收集相同的数据： 优点：服务能够提供基本的可靠性；配置非常简单，只要保证配置文件一致即可。 缺点：无法扩展；数据不一致；本质是单点，数据量大的时候，会有性能瓶颈。 适用场景：小规模集群；短期存储的需求。 remote storage（远程存储） 如果ServerA出现故障，启动ServerB： 优点：保证数据一致；数据可长期存储；server 可以灵活迁移。 缺点：server同样是单点，数据量大的时候存在性能瓶颈 适用场景：小规模集群；数据长期存储。 联邦集群 Prometheus原生支持联邦架构，能够实现从别的prometheus来抓取符合特定条件的数据： scrape_configs:- job_name:'federate'scrape_interval:15shonor_labels:truemetrics_path:'/federate'params:'match[]':- '{job=~\"kubernetes.*\"}'# 抓取了目标prometheus中job为kubernetes开头的所有监控项static_configs:- targets:- 'source-prometheus-1:9090'- 'source-prometheus-2:9090'- 'source-prometheus-3:9090' 优点：资料能够被持久化保持在第三方存储系统中；能够依旧不同任务进行层级划分；server可以灵活迁移；serverA和serverB可以用前面提到的方法进行高可用扩展。 缺点：单一资料中心带来的单点（ServerC压力较大）；分层带来的配置复杂，维护成本较高；监控成本较大。 适用场景：能够满足较大规模的监控需求；有很好地扩展；单资料中心下的较为完善的架构。 多资料中心高可用架构 多套k8s集群系统监控/cpu、内存、磁盘、网络等数据量不大 业务监控（nginx/grpc等）/和线上访问成正比，数据量巨大 各自特点： 系统监控要保存较长时间（要做长久的资源分析） 业务监控主要做实时探测，一般需求不会超过一星期（主要做实时业务成功率报警，历史数据分析从日志进行操作 多资料中心而且有不同存储需求 2、alert高可用","date":"2022-01-05","objectID":"/prometheus/:1:5","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#五高可用方案"},{"categories":[],"content":"五、高可用方案1、server高可用 部署多个相同配置的server A和B（甚至可以再加），保持相同的配置，收集相同的数据： 优点：服务能够提供基本的可靠性；配置非常简单，只要保证配置文件一致即可。 缺点：无法扩展；数据不一致；本质是单点，数据量大的时候，会有性能瓶颈。 适用场景：小规模集群；短期存储的需求。 remote storage（远程存储） 如果ServerA出现故障，启动ServerB： 优点：保证数据一致；数据可长期存储；server 可以灵活迁移。 缺点：server同样是单点，数据量大的时候存在性能瓶颈 适用场景：小规模集群；数据长期存储。 联邦集群 Prometheus原生支持联邦架构，能够实现从别的prometheus来抓取符合特定条件的数据： scrape_configs:- job_name:'federate'scrape_interval:15shonor_labels:truemetrics_path:'/federate'params:'match[]':- '{job=~\"kubernetes.*\"}'# 抓取了目标prometheus中job为kubernetes开头的所有监控项static_configs:- targets:- 'source-prometheus-1:9090'- 'source-prometheus-2:9090'- 'source-prometheus-3:9090' 优点：资料能够被持久化保持在第三方存储系统中；能够依旧不同任务进行层级划分；server可以灵活迁移；serverA和serverB可以用前面提到的方法进行高可用扩展。 缺点：单一资料中心带来的单点（ServerC压力较大）；分层带来的配置复杂，维护成本较高；监控成本较大。 适用场景：能够满足较大规模的监控需求；有很好地扩展；单资料中心下的较为完善的架构。 多资料中心高可用架构 多套k8s集群系统监控/cpu、内存、磁盘、网络等数据量不大 业务监控（nginx/grpc等）/和线上访问成正比，数据量巨大 各自特点： 系统监控要保存较长时间（要做长久的资源分析） 业务监控主要做实时探测，一般需求不会超过一星期（主要做实时业务成功率报警，历史数据分析从日志进行操作 多资料中心而且有不同存储需求 2、alert高可用","date":"2022-01-05","objectID":"/prometheus/:1:5","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#1server高可用"},{"categories":[],"content":"五、高可用方案1、server高可用 部署多个相同配置的server A和B（甚至可以再加），保持相同的配置，收集相同的数据： 优点：服务能够提供基本的可靠性；配置非常简单，只要保证配置文件一致即可。 缺点：无法扩展；数据不一致；本质是单点，数据量大的时候，会有性能瓶颈。 适用场景：小规模集群；短期存储的需求。 remote storage（远程存储） 如果ServerA出现故障，启动ServerB： 优点：保证数据一致；数据可长期存储；server 可以灵活迁移。 缺点：server同样是单点，数据量大的时候存在性能瓶颈 适用场景：小规模集群；数据长期存储。 联邦集群 Prometheus原生支持联邦架构，能够实现从别的prometheus来抓取符合特定条件的数据： scrape_configs:- job_name:'federate'scrape_interval:15shonor_labels:truemetrics_path:'/federate'params:'match[]':- '{job=~\"kubernetes.*\"}'# 抓取了目标prometheus中job为kubernetes开头的所有监控项static_configs:- targets:- 'source-prometheus-1:9090'- 'source-prometheus-2:9090'- 'source-prometheus-3:9090' 优点：资料能够被持久化保持在第三方存储系统中；能够依旧不同任务进行层级划分；server可以灵活迁移；serverA和serverB可以用前面提到的方法进行高可用扩展。 缺点：单一资料中心带来的单点（ServerC压力较大）；分层带来的配置复杂，维护成本较高；监控成本较大。 适用场景：能够满足较大规模的监控需求；有很好地扩展；单资料中心下的较为完善的架构。 多资料中心高可用架构 多套k8s集群系统监控/cpu、内存、磁盘、网络等数据量不大 业务监控（nginx/grpc等）/和线上访问成正比，数据量巨大 各自特点： 系统监控要保存较长时间（要做长久的资源分析） 业务监控主要做实时探测，一般需求不会超过一星期（主要做实时业务成功率报警，历史数据分析从日志进行操作 多资料中心而且有不同存储需求 2、alert高可用","date":"2022-01-05","objectID":"/prometheus/:1:5","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#2alert高可用"},{"categories":[],"content":"六、扩展1、prometheus数据类型 数据模型 metrics name \u0026 label 指标名称和标签（key=value)的形式组成。如prometheus_http_requests_total{code=\"200\",handler=\"/api/v1/label/:name/values\",instance=\"localhost:9090\",job=\"prometheus\"} 一般由字母和下划线构成，prometheus_http_requests_total(应用名称_监测对象 _ 数值类型 _单位) label（标签）就是对一条时间序列不同维度的识别，每个k-v对都是一个label。 counter（计数器类型） counter类型的指标的工作方式和计数器一样，只增不减（除非系统发生了重置）。Counter一般用于累计值，例如记录请求次数、任务完成数，错误发生数。 通常来讲，许多指标counter本身并没有什么意义，有意义的是counter随时间的变化率。 Gauge（仪表盘类型） Gauge是可增可减的指标类，可以用于反应当前应用的状态，比如机器内存、磁盘可用空间大小等。node_memory_MemAvailable_bytes/node_file Histogram（直方图类型） Histogram由\u003cbasename\u003e_bucket，\u003cbasename\u003e_sum,\u003cbasename\u003e_counter组成。主要用于表示一段时间范围内对数据进行采样（通常是请求持续时间或响应大小），并能够对其指定区间以及总数进行统计，通常它采集的数据展示为直方图。 事件发生的总次数：basename_count。 所有事件产生值的大小的总和：basename_sum. 事件产生的值分布在bucket中的次数。 Summary（摘要类型） Summary类型和Histogram类型相似，由\u003cbasename\u003e{quantile= \"\u003c\u003e\"},\u003cbasename\u003e_sum,\u003cbasename\u003e_count，主要用于表示一段时间内数据采样结果（通常是请求持续时间或响应大小），它直接存储了分位数据，而不是根据统计区间计算出来的。 二者区别 Histogram指标直接反应了在不同区间内样本的个数，区间通过标签le进行定义，同时对于Histogram的指标，我们还可以通过histogram_quantile()函数计算出其值的分位数。 而Summary的分位数则是直接在客户端计算完成。 因此对于分位数的计算而言，Summary在通过PromQL进行查询时有更好的性能表现，而Histogram是在prometheus server上计算的，会消耗更多的资源，反之对于客户端而言Histogram消耗的资源更少。在选择这两种方式时用户应该按照自己的实际场景进行选择。 2、label的使用label（标签）使用 label能够让我们知道监控项目的来源端口方法等，同时label也为prometheus提供了丰富的聚合和查询等功能。可以在targets中看到已有的label有哪些，在实际使用中需要对冗长的label进行格式处理，以更加清晰可读的方式展示出来。 label的操作： keep 只保留符合匹配的标签； Drop 丢弃符合匹配的标签； 还支持replace、labelmap、keep、drop等操作 # 在Prometheus采集数据之前，通过Target实例的Metadata信息，动态重新写入Label的值。# 如将原始的__meta_kubernetes_namespace直接写成namespace，简洁明了- job_name:kubernetes-nodesscrape_interval:1mscrape_timeout:10smetrics_path:/metricsscheme:httpskubernetes_sd_configs:- api_server:nullrole:nodenamespaces:names:[]bearer_token_file:/var/run/secrets/kubernetes.io/serviceaccount/tokentls_config:ca_file:/var/run/secrets/kubernetes.io/serviceaccount/ca.crtinsecure_skip_verify:truerelabel_configs:- separator:;regex:__meta_kubernetes_node_label_(.+)replacement:$1action:labelmap- separator:;regex:(.*)target_label:__address__replacement:kubernetes.default.svc:443action:replace- source_labels:[__meta_kubernetes_node_name]action:replaceseparator:;regex:(.+)replacement:/api/v1/nodes/${1}/proxy/metricstarget_label:__metrics_path__ ","date":"2022-01-05","objectID":"/prometheus/:1:6","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#六扩展"},{"categories":[],"content":"六、扩展1、prometheus数据类型 数据模型 metrics name \u0026 label 指标名称和标签（key=value)的形式组成。如prometheus_http_requests_total{code=\"200\",handler=\"/api/v1/label/:name/values\",instance=\"localhost:9090\",job=\"prometheus\"} 一般由字母和下划线构成，prometheus_http_requests_total(应用名称_监测对象 _ 数值类型 _单位) label（标签）就是对一条时间序列不同维度的识别，每个k-v对都是一个label。 counter（计数器类型） counter类型的指标的工作方式和计数器一样，只增不减（除非系统发生了重置）。Counter一般用于累计值，例如记录请求次数、任务完成数，错误发生数。 通常来讲，许多指标counter本身并没有什么意义，有意义的是counter随时间的变化率。 Gauge（仪表盘类型） Gauge是可增可减的指标类，可以用于反应当前应用的状态，比如机器内存、磁盘可用空间大小等。node_memory_MemAvailable_bytes/node_file Histogram（直方图类型） Histogram由_bucket，_sum,_counter组成。主要用于表示一段时间范围内对数据进行采样（通常是请求持续时间或响应大小），并能够对其指定区间以及总数进行统计，通常它采集的数据展示为直方图。 事件发生的总次数：basename_count。 所有事件产生值的大小的总和：basename_sum. 事件产生的值分布在bucket中的次数。 Summary（摘要类型） Summary类型和Histogram类型相似，由{quantile= \"\"},_sum,_count，主要用于表示一段时间内数据采样结果（通常是请求持续时间或响应大小），它直接存储了分位数据，而不是根据统计区间计算出来的。 二者区别 Histogram指标直接反应了在不同区间内样本的个数，区间通过标签le进行定义，同时对于Histogram的指标，我们还可以通过histogram_quantile()函数计算出其值的分位数。 而Summary的分位数则是直接在客户端计算完成。 因此对于分位数的计算而言，Summary在通过PromQL进行查询时有更好的性能表现，而Histogram是在prometheus server上计算的，会消耗更多的资源，反之对于客户端而言Histogram消耗的资源更少。在选择这两种方式时用户应该按照自己的实际场景进行选择。 2、label的使用label（标签）使用 label能够让我们知道监控项目的来源端口方法等，同时label也为prometheus提供了丰富的聚合和查询等功能。可以在targets中看到已有的label有哪些，在实际使用中需要对冗长的label进行格式处理，以更加清晰可读的方式展示出来。 label的操作： keep 只保留符合匹配的标签； Drop 丢弃符合匹配的标签； 还支持replace、labelmap、keep、drop等操作 # 在Prometheus采集数据之前，通过Target实例的Metadata信息，动态重新写入Label的值。# 如将原始的__meta_kubernetes_namespace直接写成namespace，简洁明了- job_name:kubernetes-nodesscrape_interval:1mscrape_timeout:10smetrics_path:/metricsscheme:httpskubernetes_sd_configs:- api_server:nullrole:nodenamespaces:names:[]bearer_token_file:/var/run/secrets/kubernetes.io/serviceaccount/tokentls_config:ca_file:/var/run/secrets/kubernetes.io/serviceaccount/ca.crtinsecure_skip_verify:truerelabel_configs:- separator:;regex:__meta_kubernetes_node_label_(.+)replacement:$1action:labelmap- separator:;regex:(.*)target_label:__address__replacement:kubernetes.default.svc:443action:replace- source_labels:[__meta_kubernetes_node_name]action:replaceseparator:;regex:(.+)replacement:/api/v1/nodes/${1}/proxy/metricstarget_label:__metrics_path__ ","date":"2022-01-05","objectID":"/prometheus/:1:6","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#1prometheus数据类型"},{"categories":[],"content":"六、扩展1、prometheus数据类型 数据模型 metrics name \u0026 label 指标名称和标签（key=value)的形式组成。如prometheus_http_requests_total{code=\"200\",handler=\"/api/v1/label/:name/values\",instance=\"localhost:9090\",job=\"prometheus\"} 一般由字母和下划线构成，prometheus_http_requests_total(应用名称_监测对象 _ 数值类型 _单位) label（标签）就是对一条时间序列不同维度的识别，每个k-v对都是一个label。 counter（计数器类型） counter类型的指标的工作方式和计数器一样，只增不减（除非系统发生了重置）。Counter一般用于累计值，例如记录请求次数、任务完成数，错误发生数。 通常来讲，许多指标counter本身并没有什么意义，有意义的是counter随时间的变化率。 Gauge（仪表盘类型） Gauge是可增可减的指标类，可以用于反应当前应用的状态，比如机器内存、磁盘可用空间大小等。node_memory_MemAvailable_bytes/node_file Histogram（直方图类型） Histogram由_bucket，_sum,_counter组成。主要用于表示一段时间范围内对数据进行采样（通常是请求持续时间或响应大小），并能够对其指定区间以及总数进行统计，通常它采集的数据展示为直方图。 事件发生的总次数：basename_count。 所有事件产生值的大小的总和：basename_sum. 事件产生的值分布在bucket中的次数。 Summary（摘要类型） Summary类型和Histogram类型相似，由{quantile= \"\"},_sum,_count，主要用于表示一段时间内数据采样结果（通常是请求持续时间或响应大小），它直接存储了分位数据，而不是根据统计区间计算出来的。 二者区别 Histogram指标直接反应了在不同区间内样本的个数，区间通过标签le进行定义，同时对于Histogram的指标，我们还可以通过histogram_quantile()函数计算出其值的分位数。 而Summary的分位数则是直接在客户端计算完成。 因此对于分位数的计算而言，Summary在通过PromQL进行查询时有更好的性能表现，而Histogram是在prometheus server上计算的，会消耗更多的资源，反之对于客户端而言Histogram消耗的资源更少。在选择这两种方式时用户应该按照自己的实际场景进行选择。 2、label的使用label（标签）使用 label能够让我们知道监控项目的来源端口方法等，同时label也为prometheus提供了丰富的聚合和查询等功能。可以在targets中看到已有的label有哪些，在实际使用中需要对冗长的label进行格式处理，以更加清晰可读的方式展示出来。 label的操作： keep 只保留符合匹配的标签； Drop 丢弃符合匹配的标签； 还支持replace、labelmap、keep、drop等操作 # 在Prometheus采集数据之前，通过Target实例的Metadata信息，动态重新写入Label的值。# 如将原始的__meta_kubernetes_namespace直接写成namespace，简洁明了- job_name:kubernetes-nodesscrape_interval:1mscrape_timeout:10smetrics_path:/metricsscheme:httpskubernetes_sd_configs:- api_server:nullrole:nodenamespaces:names:[]bearer_token_file:/var/run/secrets/kubernetes.io/serviceaccount/tokentls_config:ca_file:/var/run/secrets/kubernetes.io/serviceaccount/ca.crtinsecure_skip_verify:truerelabel_configs:- separator:;regex:__meta_kubernetes_node_label_(.+)replacement:$1action:labelmap- separator:;regex:(.*)target_label:__address__replacement:kubernetes.default.svc:443action:replace- source_labels:[__meta_kubernetes_node_name]action:replaceseparator:;regex:(.+)replacement:/api/v1/nodes/${1}/proxy/metricstarget_label:__metrics_path__ ","date":"2022-01-05","objectID":"/prometheus/:1:6","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#2label的使用"},{"categories":[],"content":"Paxos的理解困境曾经有个很牛逼的大佬说，这个世界上只有一种一致性算法，那就是Paxos，其它的算法都是残次 品。 基于Paxos的算法变种有ZAB、Raft。 ","date":"2021-09-14","objectID":"/paxos-algo/:1:0","series":null,"tags":[],"title":"Paxos--分布式一致性算法学习","uri":"/paxos-algo/#paxos的理解困境"},{"categories":[],"content":"Paxos究竟在解决什么问题？Paxos用来确定一个不可变变量的取值 取值可以是任意的二进制数据。 一旦确定将不再更改，并且可以被获取到（不可变性、可读取性）。 系统有多个存储的节点，这些节点之间的数据要保持一致。 系统有多个写入的节点，这些写入的节点会存在并发，如何确定由哪个节点写入？ 多个写入节点可能会出现故障. 多个存储节点也可能出现故障，但是要保证半数以上的存储节点是可用并且值是一致 的。 写入的节点称为proposer，决定写入数据的节点称为acceptor。 ","date":"2021-09-14","objectID":"/paxos-algo/:1:1","series":null,"tags":[],"title":"Paxos--分布式一致性算法学习","uri":"/paxos-algo/#paxos究竟在解决什么问题"},{"categories":[],"content":"Paxos如何在分布式存储系统中应用？ 数据本身可变，采用多副本的方式进行存储 多个副本的更新操作序列[Op1,Op2,Op3,…,Opn]是相同的、不变的。 用Paxos依次来确定不可变变量Opi的取值（即第i个操作是什么）。 每确定完Opi之后，让各个数据副本执行Opi，依次类推。 Google的Chubby [‘tʃʌbi] 等都采用了Paxos来对数据副本的更新序列达成一致。 ","date":"2021-09-14","objectID":"/paxos-algo/:1:2","series":null,"tags":[],"title":"Paxos--分布式一致性算法学习","uri":"/paxos-algo/#paxos如何在分布式存储系统中应用"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=\u003e\u003cok,f\u003eor\u003cerror\u003e ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回\u003cok,f\u003e。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值\u003caccepted_epoch,accepted_value\u003e 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值\u003caccepted_epoch,accepted_value\u003e= \u003cprepared_epoch,V\u003e 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回\u003cok,V\u003e 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回\u003cok,accepted_value\u003e。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos--分布式一致性算法学习","uri":"/paxos-algo/#paxos算法的核心思想是什么"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=or ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值= 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos--分布式一致性算法学习","uri":"/paxos-algo/#设计一个系统来存储名称为var的变量"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=or ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值= 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos--分布式一致性算法学习","uri":"/paxos-algo/#系统需要保证var的取值满足一致性"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=or ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值= 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos--分布式一致性算法学习","uri":"/paxos-algo/#系统需要满足容错特性"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=or ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值= 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos--分布式一致性算法学习","uri":"/paxos-algo/#为了讲解简单暂不考虑"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=or ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值= 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos--分布式一致性算法学习","uri":"/paxos-algo/#确定一个不可变变量难点"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=or ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值= 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos--分布式一致性算法学习","uri":"/paxos-algo/#确定一个不可变变量的取值方案1"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=or ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值= 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos--分布式一致性算法学习","uri":"/paxos-algo/#方案1基于互斥访问权的acceptor的实现"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=or ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值= 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos--分布式一致性算法学习","uri":"/paxos-algo/#方案1proposevarv的两阶段实现"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=or ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值= 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos--分布式一致性算法学习","uri":"/paxos-algo/#方案1总结"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=or ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值= 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos--分布式一致性算法学习","uri":"/paxos-algo/#方案2引入抢占式访问权"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=or ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值= 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos--分布式一致性算法学习","uri":"/paxos-algo/#方案2基于抢占式访问权的acceptor的实现"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=or ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值= 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos--分布式一致性算法学习","uri":"/paxos-algo/#方案2proposevarv的两阶段实现"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=or ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值= 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos--分布式一致性算法学习","uri":"/paxos-algo/#方案2总结"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=or ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值= 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos--分布式一致性算法学习","uri":"/paxos-algo/#思考关于方案1和2"},{"categories":[],"content":"Paxos Paxos在方案2的基础上引入多acceptor。 acceptor的实现保持不变，仍然采用“喜新厌旧”的原则运行。 Paxos采用了少数acceptor服从多数的思路（少数服从多数）。 在方案2中，一旦某个epoch的取值f被系统里仅有的acceptor接受，那么我们就认为var的取值被确定了。那么在Paxos中，我们定义，一旦某epoch的取值f被半数以上acceptor接受，则认为此取值被确定为f，不再更改。 Acceptor的实现不变Propose的两阶段实现propose(var,V)第一阶段：选定epoch，获取epoch访问权和对应var的取值。 获取半数以上acceptor的访问权和对应的一组var取值。 因为半数以上和半数以上必然存在交集，那么就可以保证，一个epoch最多只会有一个proposer拿到访问权，进入第二阶段运行。 propose(var,V)第二阶段：采用后者认同前者的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值， 不会破坏。 如果proposer在第一阶段获取到的var取值都为空，则旧epoch无法形成确定性取值。此时努力使\u003cepoch,V\u003e成为确定性取值。 向所有的epoch对应的所有acceptor提交取值\u003cepoch,V\u003e。 如果收到半数以上成功，则返回\u003cok,V\u003e。 否则，则返回error（被新的epoch抢占或者accepor故障）。 如果说var的取值存在，那么就要认同最大accepted_epoch对应的取值f，努力使\u003cepoch,f\u003e成为确定性取值。 如果f已经出现了半数以上，则说明f已经是确定性取值，直接返回\u003cok,f\u003e 如果说f只是出现了半数以下，那此时f可能是确定性取值，也可能不是，不管怎样，此时的epoch都会认同这个f，向所有的acceptor提交这个取值\u003cepoch,f\u003e ​ 我们想象一下，当proposer1提交的\u003cepoch1,f\u003e被acceptor接受，epoch1形成了确定性取值，紧接着下一个就是proposer2的提交的epoch2，proposer2肯定是可以获取到至少一个确定性取值\u003cepoch1,f\u003e，并且在epoch2获取到的所有取值里面，epoch1是一个最大的epoch，所以epoch2会认可epoch1提交的取值f，以此类推，后面的epoch也都会认可epoch1提交的取值f，不会进行更改。 ​ 画图讲解下第一阶段 ​ proposer1向所有的acceptor发出prepare请求，并且返回var的当前取值，全部为空。 ​ proposer1发现所有的取值为空，这个时候proposer1就可以选定自己的取值V1为确定性取值向所有的acceptor发送accept请求。proposer1进入第二阶段，向第一个acceptor发出请求。 ​ 在这个时候，P2进入第一阶段，向acceptor发出prepare请求。使用epoch2企图抢占访问权。P2向前两个acceptor发出了prepare请求。 ​ epoch1的访问权直接失效，epoch2获取到了访问权，acceptor向P2返回了节点当前保存的结果。P2进入了第二阶段，在P2发起accept请求之前，P1继续向另外的两个节点发送accept请求。 ​ 在这个情况中，第二个acceptor会拒绝P1的请求，因为epoch1访问权失效，第三个acceptor接受了V1这个取值并且返回成功。这个时候，epoch1已经形成了确定性取值V1，也是P1的取值V1。 ​ 这个时候，P2开始在第二阶段向acceptor发起accept请求。它选定取值里面最大的epoch的取值，也就是epoch1提交的V1，然后开始让acceptor接受V1。 ​ 所以在这种情况下，我们可以看到P2也形成了确定性取值V1，因为它是直接选择epoch1提交的取值V1，所以即使epoch1和epoch2都形成了确定性取值，这两个取值不会发生冲突。 ​ 我们可以假设，P1的后两个accept请求没有成功发出去，那么epoch1无法形成确定性取值，epoch2也会照样选择V1来形成确定性取值，也不会形成冲突。 Paxos——总结Paxos算法的核心思想 在抢占式访问权的基础上引入多个acceptor 保证一个epoch，只有proposer运行，proposer按照epoch递增的顺序依次运行。 新epoch的proposer采用“后者认同前者”的思路运行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取 值，不会破坏。 Paxos算法可以满足容错性要求 半数以下acceptor出现故障时，存活的acceptor仍然了可以生成var的确定性取值。 一旦var取值被确定，即使出现了半数以下acceptor故障，该取值也可以被获取，并且不再更改。 Paxos算法的livelock问题 新轮次的抢占会让旧轮次停止运行，如果每一轮次在第二阶段成功之前都被新一轮次抢占，则 导致活锁，怎么解决呢？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:4","series":null,"tags":[],"title":"Paxos--分布式一致性算法学习","uri":"/paxos-algo/#paxos"},{"categories":[],"content":"Paxos Paxos在方案2的基础上引入多acceptor。 acceptor的实现保持不变，仍然采用“喜新厌旧”的原则运行。 Paxos采用了少数acceptor服从多数的思路（少数服从多数）。 在方案2中，一旦某个epoch的取值f被系统里仅有的acceptor接受，那么我们就认为var的取值被确定了。那么在Paxos中，我们定义，一旦某epoch的取值f被半数以上acceptor接受，则认为此取值被确定为f，不再更改。 Acceptor的实现不变Propose的两阶段实现propose(var,V)第一阶段：选定epoch，获取epoch访问权和对应var的取值。 获取半数以上acceptor的访问权和对应的一组var取值。 因为半数以上和半数以上必然存在交集，那么就可以保证，一个epoch最多只会有一个proposer拿到访问权，进入第二阶段运行。 propose(var,V)第二阶段：采用后者认同前者的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值， 不会破坏。 如果proposer在第一阶段获取到的var取值都为空，则旧epoch无法形成确定性取值。此时努力使成为确定性取值。 向所有的epoch对应的所有acceptor提交取值。 如果收到半数以上成功，则返回。 否则，则返回error（被新的epoch抢占或者accepor故障）。 如果说var的取值存在，那么就要认同最大accepted_epoch对应的取值f，努力使成为确定性取值。 如果f已经出现了半数以上，则说明f已经是确定性取值，直接返回 如果说f只是出现了半数以下，那此时f可能是确定性取值，也可能不是，不管怎样，此时的epoch都会认同这个f，向所有的acceptor提交这个取值 ​ 我们想象一下，当proposer1提交的被acceptor接受，epoch1形成了确定性取值，紧接着下一个就是proposer2的提交的epoch2，proposer2肯定是可以获取到至少一个确定性取值，并且在epoch2获取到的所有取值里面，epoch1是一个最大的epoch，所以epoch2会认可epoch1提交的取值f，以此类推，后面的epoch也都会认可epoch1提交的取值f，不会进行更改。 ​ 画图讲解下第一阶段 ​ proposer1向所有的acceptor发出prepare请求，并且返回var的当前取值，全部为空。 ​ proposer1发现所有的取值为空，这个时候proposer1就可以选定自己的取值V1为确定性取值向所有的acceptor发送accept请求。proposer1进入第二阶段，向第一个acceptor发出请求。 ​ 在这个时候，P2进入第一阶段，向acceptor发出prepare请求。使用epoch2企图抢占访问权。P2向前两个acceptor发出了prepare请求。 ​ epoch1的访问权直接失效，epoch2获取到了访问权，acceptor向P2返回了节点当前保存的结果。P2进入了第二阶段，在P2发起accept请求之前，P1继续向另外的两个节点发送accept请求。 ​ 在这个情况中，第二个acceptor会拒绝P1的请求，因为epoch1访问权失效，第三个acceptor接受了V1这个取值并且返回成功。这个时候，epoch1已经形成了确定性取值V1，也是P1的取值V1。 ​ 这个时候，P2开始在第二阶段向acceptor发起accept请求。它选定取值里面最大的epoch的取值，也就是epoch1提交的V1，然后开始让acceptor接受V1。 ​ 所以在这种情况下，我们可以看到P2也形成了确定性取值V1，因为它是直接选择epoch1提交的取值V1，所以即使epoch1和epoch2都形成了确定性取值，这两个取值不会发生冲突。 ​ 我们可以假设，P1的后两个accept请求没有成功发出去，那么epoch1无法形成确定性取值，epoch2也会照样选择V1来形成确定性取值，也不会形成冲突。 Paxos——总结Paxos算法的核心思想 在抢占式访问权的基础上引入多个acceptor 保证一个epoch，只有proposer运行，proposer按照epoch递增的顺序依次运行。 新epoch的proposer采用“后者认同前者”的思路运行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取 值，不会破坏。 Paxos算法可以满足容错性要求 半数以下acceptor出现故障时，存活的acceptor仍然了可以生成var的确定性取值。 一旦var取值被确定，即使出现了半数以下acceptor故障，该取值也可以被获取，并且不再更改。 Paxos算法的livelock问题 新轮次的抢占会让旧轮次停止运行，如果每一轮次在第二阶段成功之前都被新一轮次抢占，则 导致活锁，怎么解决呢？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:4","series":null,"tags":[],"title":"Paxos--分布式一致性算法学习","uri":"/paxos-algo/#acceptor的实现不变"},{"categories":[],"content":"Paxos Paxos在方案2的基础上引入多acceptor。 acceptor的实现保持不变，仍然采用“喜新厌旧”的原则运行。 Paxos采用了少数acceptor服从多数的思路（少数服从多数）。 在方案2中，一旦某个epoch的取值f被系统里仅有的acceptor接受，那么我们就认为var的取值被确定了。那么在Paxos中，我们定义，一旦某epoch的取值f被半数以上acceptor接受，则认为此取值被确定为f，不再更改。 Acceptor的实现不变Propose的两阶段实现propose(var,V)第一阶段：选定epoch，获取epoch访问权和对应var的取值。 获取半数以上acceptor的访问权和对应的一组var取值。 因为半数以上和半数以上必然存在交集，那么就可以保证，一个epoch最多只会有一个proposer拿到访问权，进入第二阶段运行。 propose(var,V)第二阶段：采用后者认同前者的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值， 不会破坏。 如果proposer在第一阶段获取到的var取值都为空，则旧epoch无法形成确定性取值。此时努力使成为确定性取值。 向所有的epoch对应的所有acceptor提交取值。 如果收到半数以上成功，则返回。 否则，则返回error（被新的epoch抢占或者accepor故障）。 如果说var的取值存在，那么就要认同最大accepted_epoch对应的取值f，努力使成为确定性取值。 如果f已经出现了半数以上，则说明f已经是确定性取值，直接返回 如果说f只是出现了半数以下，那此时f可能是确定性取值，也可能不是，不管怎样，此时的epoch都会认同这个f，向所有的acceptor提交这个取值 ​ 我们想象一下，当proposer1提交的被acceptor接受，epoch1形成了确定性取值，紧接着下一个就是proposer2的提交的epoch2，proposer2肯定是可以获取到至少一个确定性取值，并且在epoch2获取到的所有取值里面，epoch1是一个最大的epoch，所以epoch2会认可epoch1提交的取值f，以此类推，后面的epoch也都会认可epoch1提交的取值f，不会进行更改。 ​ 画图讲解下第一阶段 ​ proposer1向所有的acceptor发出prepare请求，并且返回var的当前取值，全部为空。 ​ proposer1发现所有的取值为空，这个时候proposer1就可以选定自己的取值V1为确定性取值向所有的acceptor发送accept请求。proposer1进入第二阶段，向第一个acceptor发出请求。 ​ 在这个时候，P2进入第一阶段，向acceptor发出prepare请求。使用epoch2企图抢占访问权。P2向前两个acceptor发出了prepare请求。 ​ epoch1的访问权直接失效，epoch2获取到了访问权，acceptor向P2返回了节点当前保存的结果。P2进入了第二阶段，在P2发起accept请求之前，P1继续向另外的两个节点发送accept请求。 ​ 在这个情况中，第二个acceptor会拒绝P1的请求，因为epoch1访问权失效，第三个acceptor接受了V1这个取值并且返回成功。这个时候，epoch1已经形成了确定性取值V1，也是P1的取值V1。 ​ 这个时候，P2开始在第二阶段向acceptor发起accept请求。它选定取值里面最大的epoch的取值，也就是epoch1提交的V1，然后开始让acceptor接受V1。 ​ 所以在这种情况下，我们可以看到P2也形成了确定性取值V1，因为它是直接选择epoch1提交的取值V1，所以即使epoch1和epoch2都形成了确定性取值，这两个取值不会发生冲突。 ​ 我们可以假设，P1的后两个accept请求没有成功发出去，那么epoch1无法形成确定性取值，epoch2也会照样选择V1来形成确定性取值，也不会形成冲突。 Paxos——总结Paxos算法的核心思想 在抢占式访问权的基础上引入多个acceptor 保证一个epoch，只有proposer运行，proposer按照epoch递增的顺序依次运行。 新epoch的proposer采用“后者认同前者”的思路运行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取 值，不会破坏。 Paxos算法可以满足容错性要求 半数以下acceptor出现故障时，存活的acceptor仍然了可以生成var的确定性取值。 一旦var取值被确定，即使出现了半数以下acceptor故障，该取值也可以被获取，并且不再更改。 Paxos算法的livelock问题 新轮次的抢占会让旧轮次停止运行，如果每一轮次在第二阶段成功之前都被新一轮次抢占，则 导致活锁，怎么解决呢？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:4","series":null,"tags":[],"title":"Paxos--分布式一致性算法学习","uri":"/paxos-algo/#propose的两阶段实现"},{"categories":[],"content":"Paxos Paxos在方案2的基础上引入多acceptor。 acceptor的实现保持不变，仍然采用“喜新厌旧”的原则运行。 Paxos采用了少数acceptor服从多数的思路（少数服从多数）。 在方案2中，一旦某个epoch的取值f被系统里仅有的acceptor接受，那么我们就认为var的取值被确定了。那么在Paxos中，我们定义，一旦某epoch的取值f被半数以上acceptor接受，则认为此取值被确定为f，不再更改。 Acceptor的实现不变Propose的两阶段实现propose(var,V)第一阶段：选定epoch，获取epoch访问权和对应var的取值。 获取半数以上acceptor的访问权和对应的一组var取值。 因为半数以上和半数以上必然存在交集，那么就可以保证，一个epoch最多只会有一个proposer拿到访问权，进入第二阶段运行。 propose(var,V)第二阶段：采用后者认同前者的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值， 不会破坏。 如果proposer在第一阶段获取到的var取值都为空，则旧epoch无法形成确定性取值。此时努力使成为确定性取值。 向所有的epoch对应的所有acceptor提交取值。 如果收到半数以上成功，则返回。 否则，则返回error（被新的epoch抢占或者accepor故障）。 如果说var的取值存在，那么就要认同最大accepted_epoch对应的取值f，努力使成为确定性取值。 如果f已经出现了半数以上，则说明f已经是确定性取值，直接返回 如果说f只是出现了半数以下，那此时f可能是确定性取值，也可能不是，不管怎样，此时的epoch都会认同这个f，向所有的acceptor提交这个取值 ​ 我们想象一下，当proposer1提交的被acceptor接受，epoch1形成了确定性取值，紧接着下一个就是proposer2的提交的epoch2，proposer2肯定是可以获取到至少一个确定性取值，并且在epoch2获取到的所有取值里面，epoch1是一个最大的epoch，所以epoch2会认可epoch1提交的取值f，以此类推，后面的epoch也都会认可epoch1提交的取值f，不会进行更改。 ​ 画图讲解下第一阶段 ​ proposer1向所有的acceptor发出prepare请求，并且返回var的当前取值，全部为空。 ​ proposer1发现所有的取值为空，这个时候proposer1就可以选定自己的取值V1为确定性取值向所有的acceptor发送accept请求。proposer1进入第二阶段，向第一个acceptor发出请求。 ​ 在这个时候，P2进入第一阶段，向acceptor发出prepare请求。使用epoch2企图抢占访问权。P2向前两个acceptor发出了prepare请求。 ​ epoch1的访问权直接失效，epoch2获取到了访问权，acceptor向P2返回了节点当前保存的结果。P2进入了第二阶段，在P2发起accept请求之前，P1继续向另外的两个节点发送accept请求。 ​ 在这个情况中，第二个acceptor会拒绝P1的请求，因为epoch1访问权失效，第三个acceptor接受了V1这个取值并且返回成功。这个时候，epoch1已经形成了确定性取值V1，也是P1的取值V1。 ​ 这个时候，P2开始在第二阶段向acceptor发起accept请求。它选定取值里面最大的epoch的取值，也就是epoch1提交的V1，然后开始让acceptor接受V1。 ​ 所以在这种情况下，我们可以看到P2也形成了确定性取值V1，因为它是直接选择epoch1提交的取值V1，所以即使epoch1和epoch2都形成了确定性取值，这两个取值不会发生冲突。 ​ 我们可以假设，P1的后两个accept请求没有成功发出去，那么epoch1无法形成确定性取值，epoch2也会照样选择V1来形成确定性取值，也不会形成冲突。 Paxos——总结Paxos算法的核心思想 在抢占式访问权的基础上引入多个acceptor 保证一个epoch，只有proposer运行，proposer按照epoch递增的顺序依次运行。 新epoch的proposer采用“后者认同前者”的思路运行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取 值，不会破坏。 Paxos算法可以满足容错性要求 半数以下acceptor出现故障时，存活的acceptor仍然了可以生成var的确定性取值。 一旦var取值被确定，即使出现了半数以下acceptor故障，该取值也可以被获取，并且不再更改。 Paxos算法的livelock问题 新轮次的抢占会让旧轮次停止运行，如果每一轮次在第二阶段成功之前都被新一轮次抢占，则 导致活锁，怎么解决呢？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:4","series":null,"tags":[],"title":"Paxos--分布式一致性算法学习","uri":"/paxos-algo/#paxos总结"},{"categories":[],"content":"Paxos Paxos在方案2的基础上引入多acceptor。 acceptor的实现保持不变，仍然采用“喜新厌旧”的原则运行。 Paxos采用了少数acceptor服从多数的思路（少数服从多数）。 在方案2中，一旦某个epoch的取值f被系统里仅有的acceptor接受，那么我们就认为var的取值被确定了。那么在Paxos中，我们定义，一旦某epoch的取值f被半数以上acceptor接受，则认为此取值被确定为f，不再更改。 Acceptor的实现不变Propose的两阶段实现propose(var,V)第一阶段：选定epoch，获取epoch访问权和对应var的取值。 获取半数以上acceptor的访问权和对应的一组var取值。 因为半数以上和半数以上必然存在交集，那么就可以保证，一个epoch最多只会有一个proposer拿到访问权，进入第二阶段运行。 propose(var,V)第二阶段：采用后者认同前者的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值， 不会破坏。 如果proposer在第一阶段获取到的var取值都为空，则旧epoch无法形成确定性取值。此时努力使成为确定性取值。 向所有的epoch对应的所有acceptor提交取值。 如果收到半数以上成功，则返回。 否则，则返回error（被新的epoch抢占或者accepor故障）。 如果说var的取值存在，那么就要认同最大accepted_epoch对应的取值f，努力使成为确定性取值。 如果f已经出现了半数以上，则说明f已经是确定性取值，直接返回 如果说f只是出现了半数以下，那此时f可能是确定性取值，也可能不是，不管怎样，此时的epoch都会认同这个f，向所有的acceptor提交这个取值 ​ 我们想象一下，当proposer1提交的被acceptor接受，epoch1形成了确定性取值，紧接着下一个就是proposer2的提交的epoch2，proposer2肯定是可以获取到至少一个确定性取值，并且在epoch2获取到的所有取值里面，epoch1是一个最大的epoch，所以epoch2会认可epoch1提交的取值f，以此类推，后面的epoch也都会认可epoch1提交的取值f，不会进行更改。 ​ 画图讲解下第一阶段 ​ proposer1向所有的acceptor发出prepare请求，并且返回var的当前取值，全部为空。 ​ proposer1发现所有的取值为空，这个时候proposer1就可以选定自己的取值V1为确定性取值向所有的acceptor发送accept请求。proposer1进入第二阶段，向第一个acceptor发出请求。 ​ 在这个时候，P2进入第一阶段，向acceptor发出prepare请求。使用epoch2企图抢占访问权。P2向前两个acceptor发出了prepare请求。 ​ epoch1的访问权直接失效，epoch2获取到了访问权，acceptor向P2返回了节点当前保存的结果。P2进入了第二阶段，在P2发起accept请求之前，P1继续向另外的两个节点发送accept请求。 ​ 在这个情况中，第二个acceptor会拒绝P1的请求，因为epoch1访问权失效，第三个acceptor接受了V1这个取值并且返回成功。这个时候，epoch1已经形成了确定性取值V1，也是P1的取值V1。 ​ 这个时候，P2开始在第二阶段向acceptor发起accept请求。它选定取值里面最大的epoch的取值，也就是epoch1提交的V1，然后开始让acceptor接受V1。 ​ 所以在这种情况下，我们可以看到P2也形成了确定性取值V1，因为它是直接选择epoch1提交的取值V1，所以即使epoch1和epoch2都形成了确定性取值，这两个取值不会发生冲突。 ​ 我们可以假设，P1的后两个accept请求没有成功发出去，那么epoch1无法形成确定性取值，epoch2也会照样选择V1来形成确定性取值，也不会形成冲突。 Paxos——总结Paxos算法的核心思想 在抢占式访问权的基础上引入多个acceptor 保证一个epoch，只有proposer运行，proposer按照epoch递增的顺序依次运行。 新epoch的proposer采用“后者认同前者”的思路运行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取 值，不会破坏。 Paxos算法可以满足容错性要求 半数以下acceptor出现故障时，存活的acceptor仍然了可以生成var的确定性取值。 一旦var取值被确定，即使出现了半数以下acceptor故障，该取值也可以被获取，并且不再更改。 Paxos算法的livelock问题 新轮次的抢占会让旧轮次停止运行，如果每一轮次在第二阶段成功之前都被新一轮次抢占，则 导致活锁，怎么解决呢？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:4","series":null,"tags":[],"title":"Paxos--分布式一致性算法学习","uri":"/paxos-algo/#paxos算法的核心思想"},{"categories":[],"content":"Paxos Paxos在方案2的基础上引入多acceptor。 acceptor的实现保持不变，仍然采用“喜新厌旧”的原则运行。 Paxos采用了少数acceptor服从多数的思路（少数服从多数）。 在方案2中，一旦某个epoch的取值f被系统里仅有的acceptor接受，那么我们就认为var的取值被确定了。那么在Paxos中，我们定义，一旦某epoch的取值f被半数以上acceptor接受，则认为此取值被确定为f，不再更改。 Acceptor的实现不变Propose的两阶段实现propose(var,V)第一阶段：选定epoch，获取epoch访问权和对应var的取值。 获取半数以上acceptor的访问权和对应的一组var取值。 因为半数以上和半数以上必然存在交集，那么就可以保证，一个epoch最多只会有一个proposer拿到访问权，进入第二阶段运行。 propose(var,V)第二阶段：采用后者认同前者的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值， 不会破坏。 如果proposer在第一阶段获取到的var取值都为空，则旧epoch无法形成确定性取值。此时努力使成为确定性取值。 向所有的epoch对应的所有acceptor提交取值。 如果收到半数以上成功，则返回。 否则，则返回error（被新的epoch抢占或者accepor故障）。 如果说var的取值存在，那么就要认同最大accepted_epoch对应的取值f，努力使成为确定性取值。 如果f已经出现了半数以上，则说明f已经是确定性取值，直接返回 如果说f只是出现了半数以下，那此时f可能是确定性取值，也可能不是，不管怎样，此时的epoch都会认同这个f，向所有的acceptor提交这个取值 ​ 我们想象一下，当proposer1提交的被acceptor接受，epoch1形成了确定性取值，紧接着下一个就是proposer2的提交的epoch2，proposer2肯定是可以获取到至少一个确定性取值，并且在epoch2获取到的所有取值里面，epoch1是一个最大的epoch，所以epoch2会认可epoch1提交的取值f，以此类推，后面的epoch也都会认可epoch1提交的取值f，不会进行更改。 ​ 画图讲解下第一阶段 ​ proposer1向所有的acceptor发出prepare请求，并且返回var的当前取值，全部为空。 ​ proposer1发现所有的取值为空，这个时候proposer1就可以选定自己的取值V1为确定性取值向所有的acceptor发送accept请求。proposer1进入第二阶段，向第一个acceptor发出请求。 ​ 在这个时候，P2进入第一阶段，向acceptor发出prepare请求。使用epoch2企图抢占访问权。P2向前两个acceptor发出了prepare请求。 ​ epoch1的访问权直接失效，epoch2获取到了访问权，acceptor向P2返回了节点当前保存的结果。P2进入了第二阶段，在P2发起accept请求之前，P1继续向另外的两个节点发送accept请求。 ​ 在这个情况中，第二个acceptor会拒绝P1的请求，因为epoch1访问权失效，第三个acceptor接受了V1这个取值并且返回成功。这个时候，epoch1已经形成了确定性取值V1，也是P1的取值V1。 ​ 这个时候，P2开始在第二阶段向acceptor发起accept请求。它选定取值里面最大的epoch的取值，也就是epoch1提交的V1，然后开始让acceptor接受V1。 ​ 所以在这种情况下，我们可以看到P2也形成了确定性取值V1，因为它是直接选择epoch1提交的取值V1，所以即使epoch1和epoch2都形成了确定性取值，这两个取值不会发生冲突。 ​ 我们可以假设，P1的后两个accept请求没有成功发出去，那么epoch1无法形成确定性取值，epoch2也会照样选择V1来形成确定性取值，也不会形成冲突。 Paxos——总结Paxos算法的核心思想 在抢占式访问权的基础上引入多个acceptor 保证一个epoch，只有proposer运行，proposer按照epoch递增的顺序依次运行。 新epoch的proposer采用“后者认同前者”的思路运行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取 值，不会破坏。 Paxos算法可以满足容错性要求 半数以下acceptor出现故障时，存活的acceptor仍然了可以生成var的确定性取值。 一旦var取值被确定，即使出现了半数以下acceptor故障，该取值也可以被获取，并且不再更改。 Paxos算法的livelock问题 新轮次的抢占会让旧轮次停止运行，如果每一轮次在第二阶段成功之前都被新一轮次抢占，则 导致活锁，怎么解决呢？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:4","series":null,"tags":[],"title":"Paxos--分布式一致性算法学习","uri":"/paxos-algo/#paxos算法可以满足容错性要求"},{"categories":[],"content":"Paxos Paxos在方案2的基础上引入多acceptor。 acceptor的实现保持不变，仍然采用“喜新厌旧”的原则运行。 Paxos采用了少数acceptor服从多数的思路（少数服从多数）。 在方案2中，一旦某个epoch的取值f被系统里仅有的acceptor接受，那么我们就认为var的取值被确定了。那么在Paxos中，我们定义，一旦某epoch的取值f被半数以上acceptor接受，则认为此取值被确定为f，不再更改。 Acceptor的实现不变Propose的两阶段实现propose(var,V)第一阶段：选定epoch，获取epoch访问权和对应var的取值。 获取半数以上acceptor的访问权和对应的一组var取值。 因为半数以上和半数以上必然存在交集，那么就可以保证，一个epoch最多只会有一个proposer拿到访问权，进入第二阶段运行。 propose(var,V)第二阶段：采用后者认同前者的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值， 不会破坏。 如果proposer在第一阶段获取到的var取值都为空，则旧epoch无法形成确定性取值。此时努力使成为确定性取值。 向所有的epoch对应的所有acceptor提交取值。 如果收到半数以上成功，则返回。 否则，则返回error（被新的epoch抢占或者accepor故障）。 如果说var的取值存在，那么就要认同最大accepted_epoch对应的取值f，努力使成为确定性取值。 如果f已经出现了半数以上，则说明f已经是确定性取值，直接返回 如果说f只是出现了半数以下，那此时f可能是确定性取值，也可能不是，不管怎样，此时的epoch都会认同这个f，向所有的acceptor提交这个取值 ​ 我们想象一下，当proposer1提交的被acceptor接受，epoch1形成了确定性取值，紧接着下一个就是proposer2的提交的epoch2，proposer2肯定是可以获取到至少一个确定性取值，并且在epoch2获取到的所有取值里面，epoch1是一个最大的epoch，所以epoch2会认可epoch1提交的取值f，以此类推，后面的epoch也都会认可epoch1提交的取值f，不会进行更改。 ​ 画图讲解下第一阶段 ​ proposer1向所有的acceptor发出prepare请求，并且返回var的当前取值，全部为空。 ​ proposer1发现所有的取值为空，这个时候proposer1就可以选定自己的取值V1为确定性取值向所有的acceptor发送accept请求。proposer1进入第二阶段，向第一个acceptor发出请求。 ​ 在这个时候，P2进入第一阶段，向acceptor发出prepare请求。使用epoch2企图抢占访问权。P2向前两个acceptor发出了prepare请求。 ​ epoch1的访问权直接失效，epoch2获取到了访问权，acceptor向P2返回了节点当前保存的结果。P2进入了第二阶段，在P2发起accept请求之前，P1继续向另外的两个节点发送accept请求。 ​ 在这个情况中，第二个acceptor会拒绝P1的请求，因为epoch1访问权失效，第三个acceptor接受了V1这个取值并且返回成功。这个时候，epoch1已经形成了确定性取值V1，也是P1的取值V1。 ​ 这个时候，P2开始在第二阶段向acceptor发起accept请求。它选定取值里面最大的epoch的取值，也就是epoch1提交的V1，然后开始让acceptor接受V1。 ​ 所以在这种情况下，我们可以看到P2也形成了确定性取值V1，因为它是直接选择epoch1提交的取值V1，所以即使epoch1和epoch2都形成了确定性取值，这两个取值不会发生冲突。 ​ 我们可以假设，P1的后两个accept请求没有成功发出去，那么epoch1无法形成确定性取值，epoch2也会照样选择V1来形成确定性取值，也不会形成冲突。 Paxos——总结Paxos算法的核心思想 在抢占式访问权的基础上引入多个acceptor 保证一个epoch，只有proposer运行，proposer按照epoch递增的顺序依次运行。 新epoch的proposer采用“后者认同前者”的思路运行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取 值，不会破坏。 Paxos算法可以满足容错性要求 半数以下acceptor出现故障时，存活的acceptor仍然了可以生成var的确定性取值。 一旦var取值被确定，即使出现了半数以下acceptor故障，该取值也可以被获取，并且不再更改。 Paxos算法的livelock问题 新轮次的抢占会让旧轮次停止运行，如果每一轮次在第二阶段成功之前都被新一轮次抢占，则 导致活锁，怎么解决呢？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:4","series":null,"tags":[],"title":"Paxos--分布式一致性算法学习","uri":"/paxos-algo/#paxos算法的livelock问题"},{"categories":[],"content":"思考题 在什么情况可以认为var的取值被确定，不再更改？ Paxos的两个阶段分别在做什么？ 一个epoch是否会有多个proposer进入第二阶段？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值呢？ 在第二阶段，如果获取的var取值都为空，为什么可以保证旧epoch无法形成确定性取值？ 新epoch抢占成功之后，旧epoch的proposer将如何运行？ 如何保证新的epoch不会破坏已经达成的确定性取值？ 为什么在第二阶段存在var取值时，只需要考虑accepted_epoch最大的取值f？ 在形成确定性取值之后，出现了任意半数以下acceptor故障，为何确定性取值不会被更改？ 如果proposer在运行过程中，任意半数以下的acceptor出现故障，此时将如何运行？ 正在运行的proposer和任意半数以下acceptor都出现故障时，var的取值可能是什么情况？为 何之后新的proposer可以形成确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:5","series":null,"tags":[],"title":"Paxos--分布式一致性算法学习","uri":"/paxos-algo/#思考题"},{"categories":[],"content":"参考资料分布式系列文章——Paxos算法原理与推导 ","date":"2021-09-14","objectID":"/paxos-algo/:1:6","series":null,"tags":[],"title":"Paxos--分布式一致性算法学习","uri":"/paxos-algo/#参考资料"},{"categories":[],"content":"最近新入手了一部IPad Air 4，想着为了不让其成为爱奇艺播放器，发挥生产力功效，于是搜罗资料，查找能否在iPad上实现写代码的方案。最终找到两种方法： 利用SSH连接软件，在远程服务器上利用Vim、NEOVim等编辑器软件进行编码。 首先找到的是一款名为termius的软件，下载免费，使用需内购，可是我在下载下来之后进入软件始终都无法创建账号，也就无法进行内购使用了，放弃。网上看使用过的大佬说，并不推荐这种方式，因为编码的效率太低，而且有时切出软件一小段时间后，SSH连接会断开，体验非常差。 利用code-server部署一个网页版的VScode，即“云IDE”，这样工作区在不同的设备上都能同步，而且切出后不会掉线。将网页作为WebApp添加到主屏幕上后的体验也接近于原生App(前提是服务器的带宽不能太低)。 ","date":"2021-09-10","objectID":"/code-server/:0:0","series":null,"tags":[],"title":"云IDE：code-server安装使用","uri":"/code-server/#"},{"categories":[],"content":"环境准备云服务器，规格 2C4G： $ cat /etc/redhat-release CentOS Linux release 7.6.1810 (Core) ","date":"2021-09-10","objectID":"/code-server/:0:1","series":null,"tags":[],"title":"云IDE：code-server安装使用","uri":"/code-server/#环境准备"},{"categories":[],"content":"下载资源下载code-server在github上的安装包： $ wget https://github.com/cdr/code-server/releases/download/v3.11.0/code-server-3.11.0-linux-amd64.tar.gz # 解压安装包 $ tar -zxf code-server-3.11.0-linux-amd64.tar.gz \u0026\u0026 cd code-server-3.11.0-linux-amd64 # ","date":"2021-09-10","objectID":"/code-server/:0:2","series":null,"tags":[],"title":"云IDE：code-server安装使用","uri":"/code-server/#下载资源"},{"categories":[],"content":"启动设置登录web服务的密码，code-server要求以环境变量$PASSWORD为登录密码： $ export PASSWORD=\"123456\" 运行code-server $ ./code-server --port 8080 --host 0.0.0.0 --auth password 8080是端口,可以自己修改,注意不要与其他应用冲突。0.0.0.0是代表可以被所有ip访问. $ ./code-server --port 8080 --host 0.0.0.0 --auth password ***** Please use the script in bin/code-server instead! ***** This script will soon be removed! ***** See the release notes at https://github.com/cdr/code-server/releases/tag/v3.4.0 [2021-09-10T07:39:08.191Z] info code-server 3.11.0 4e8cd09ef0412dfc7b148b7639a692e20e4fd6dd [2021-09-10T07:39:08.192Z] info Using user-data-dir ~/.local/share/code-server [2021-09-10T07:39:08.206Z] info Using config file ~/.config/code-server/config.yaml [2021-09-10T07:39:08.206Z] info HTTP server listening on http://0.0.0.0:8080 [2021-09-10T07:39:08.206Z] info - Authentication is enabled [2021-09-10T07:39:08.206Z] info - Using password from ~/.config/code-server/config.yaml [2021-09-10T07:39:08.206Z] info - Not serving HTTPS 如图所示就是已经完成配置了。 ","date":"2021-09-10","objectID":"/code-server/:0:3","series":null,"tags":[],"title":"云IDE：code-server安装使用","uri":"/code-server/#启动"},{"categories":[],"content":"访问在浏览器中输入服务器ip+端口号：127.0.0.1:8080，出现登录页面，输入刚才所设置的密码123456登录，即可进入Web IDE ,愉快的进行coding吧~ ","date":"2021-09-10","objectID":"/code-server/:0:4","series":null,"tags":[],"title":"云IDE：code-server安装使用","uri":"/code-server/#访问"},{"categories":[],"content":"添加插件 LeetCode（力扣） 在vs-code中扩展力扣，可以实现在vs-code中答题了，方便快捷。 Thief-Book（一款摸鱼插件） 可以在vs-code底部状态栏浏览TXT文本，懂得都懂~ Markdown All in one(预览Markdown) asciiflow.cn可视化纯文本流程图绘制工具 在写Markdown流程图时，在也不用担心图片存哪的问题了，纯文本格式的流程图，可以直接插入Markdown的代码块中展示。 Go Python 在github上还有非常多好玩有用的优秀插件，可以自行去探索，最好能做出一款自己写的插件。 ","date":"2021-09-10","objectID":"/code-server/:0:5","series":null,"tags":[],"title":"云IDE：code-server安装使用","uri":"/code-server/#添加插件"},{"categories":[],"content":"2021-12-01更新","date":"2021-09-10","objectID":"/code-server/:0:6","series":null,"tags":[],"title":"云IDE：code-server安装使用","uri":"/code-server/#2021-12-01更新"},{"categories":[],"content":"踩坑坑点1登录密码如果使用环境变量，记得一定要使用大写的PASSWORD！！ 原因：因启动参数中的password是小写，导致我一直错误的认为环境变量应该跟它保持一致，也是小写。 ./code-server --port 8080 --host 0.0.0.0 --auth password 而当我使用命令export password=123456添加了小写的password的环境变量去登录界面登录时又提示密码错误，且登录界面提示密码在~/.config/code-server/config.yaml中，于是我按照提示复制yaml文件中的密码成功登录了。 此时我还没意识到环境变量password其实是没有生效的，然后又去改了yaml中的密码为$password环境变量的值，导致我一直以为环境变量是被使用的。 $ cat ~/.config/code-server/config.yaml bind-addr: 0.0.0.0:8080 auth: password password: 123456 cert: false 坑点2后面想到是否可以用域名+nginx反向代理的方式访问会更加便捷呢？步骤如下： 1、在服务器上安装nginx。 注意：需要安装ssl模块./configure --prefix=/usr/local/nginx --with-http_ssl_module --with-http_v2_module 2、在阿里云申请免费证书并下载nginx版本的证书到本地。 3、上传证书到服务器上，并解压到到/usr/local/nginx/conf/cert/下。 4、在nginx.conf的配置如下： server { listen 443; server_name code.xxx.com; access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; ssl on; ssl_certificate cert/xxx.pem; ssl_certificate_key cert/xxx.com.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; #表示使用的加密套件的类型。 ssl_protocols TLSv1.1 TLSv1.2 TLSv1.3; #表示使用的TLS协议的类型。 ssl_prefer_server_ciphers on; proxy_set_header Host $host; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection upgrade; proxy_set_header Accept-Encoding gzip; location / { proxy_pass http://localhost:8080; } } server { listen 80; server_name localhost; rewrite ^(.*)$ https://$host$1 permanent; # http重写到https } 踩坑点：最开始由于server模块中没有配置proxy_set_header请求头，导致到了登录界面输入密码，却无法跳转进入vs-code界面。后面查看coder官方文档发现，code-server要求请求需使用websocket协议才能进行通信。官网原文:https://coder.com/docs/code-server/latest/guide#using-lets-encrypt-with-nginx To work properly, your environment should have WebSockets enabled, which code-server uses to communicate between the browser and server.(为了正常工作，您的环境应该启用 WebSockets，代码服务器使用它在浏览器和服务器之间进行通信。) ","date":"2021-09-10","objectID":"/code-server/:0:7","series":null,"tags":[],"title":"云IDE：code-server安装使用","uri":"/code-server/#踩坑"},{"categories":[],"content":"踩坑坑点1登录密码如果使用环境变量，记得一定要使用大写的PASSWORD！！ 原因：因启动参数中的password是小写，导致我一直错误的认为环境变量应该跟它保持一致，也是小写。 ./code-server --port 8080 --host 0.0.0.0 --auth password 而当我使用命令export password=123456添加了小写的password的环境变量去登录界面登录时又提示密码错误，且登录界面提示密码在~/.config/code-server/config.yaml中，于是我按照提示复制yaml文件中的密码成功登录了。 此时我还没意识到环境变量password其实是没有生效的，然后又去改了yaml中的密码为$password环境变量的值，导致我一直以为环境变量是被使用的。 $ cat ~/.config/code-server/config.yaml bind-addr: 0.0.0.0:8080 auth: password password: 123456 cert: false 坑点2后面想到是否可以用域名+nginx反向代理的方式访问会更加便捷呢？步骤如下： 1、在服务器上安装nginx。 注意：需要安装ssl模块./configure --prefix=/usr/local/nginx --with-http_ssl_module --with-http_v2_module 2、在阿里云申请免费证书并下载nginx版本的证书到本地。 3、上传证书到服务器上，并解压到到/usr/local/nginx/conf/cert/下。 4、在nginx.conf的配置如下： server { listen 443; server_name code.xxx.com; access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; ssl on; ssl_certificate cert/xxx.pem; ssl_certificate_key cert/xxx.com.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; #表示使用的加密套件的类型。 ssl_protocols TLSv1.1 TLSv1.2 TLSv1.3; #表示使用的TLS协议的类型。 ssl_prefer_server_ciphers on; proxy_set_header Host $host; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection upgrade; proxy_set_header Accept-Encoding gzip; location / { proxy_pass http://localhost:8080; } } server { listen 80; server_name localhost; rewrite ^(.*)$ https://$host$1 permanent; # http重写到https } 踩坑点：最开始由于server模块中没有配置proxy_set_header请求头，导致到了登录界面输入密码，却无法跳转进入vs-code界面。后面查看coder官方文档发现，code-server要求请求需使用websocket协议才能进行通信。官网原文:https://coder.com/docs/code-server/latest/guide#using-lets-encrypt-with-nginx To work properly, your environment should have WebSockets enabled, which code-server uses to communicate between the browser and server.(为了正常工作，您的环境应该启用 WebSockets，代码服务器使用它在浏览器和服务器之间进行通信。) ","date":"2021-09-10","objectID":"/code-server/:0:7","series":null,"tags":[],"title":"云IDE：code-server安装使用","uri":"/code-server/#坑点1"},{"categories":[],"content":"踩坑坑点1登录密码如果使用环境变量，记得一定要使用大写的PASSWORD！！ 原因：因启动参数中的password是小写，导致我一直错误的认为环境变量应该跟它保持一致，也是小写。 ./code-server --port 8080 --host 0.0.0.0 --auth password 而当我使用命令export password=123456添加了小写的password的环境变量去登录界面登录时又提示密码错误，且登录界面提示密码在~/.config/code-server/config.yaml中，于是我按照提示复制yaml文件中的密码成功登录了。 此时我还没意识到环境变量password其实是没有生效的，然后又去改了yaml中的密码为$password环境变量的值，导致我一直以为环境变量是被使用的。 $ cat ~/.config/code-server/config.yaml bind-addr: 0.0.0.0:8080 auth: password password: 123456 cert: false 坑点2后面想到是否可以用域名+nginx反向代理的方式访问会更加便捷呢？步骤如下： 1、在服务器上安装nginx。 注意：需要安装ssl模块./configure --prefix=/usr/local/nginx --with-http_ssl_module --with-http_v2_module 2、在阿里云申请免费证书并下载nginx版本的证书到本地。 3、上传证书到服务器上，并解压到到/usr/local/nginx/conf/cert/下。 4、在nginx.conf的配置如下： server { listen 443; server_name code.xxx.com; access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; ssl on; ssl_certificate cert/xxx.pem; ssl_certificate_key cert/xxx.com.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; #表示使用的加密套件的类型。 ssl_protocols TLSv1.1 TLSv1.2 TLSv1.3; #表示使用的TLS协议的类型。 ssl_prefer_server_ciphers on; proxy_set_header Host $host; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection upgrade; proxy_set_header Accept-Encoding gzip; location / { proxy_pass http://localhost:8080; } } server { listen 80; server_name localhost; rewrite ^(.*)$ https://$host$1 permanent; # http重写到https } 踩坑点：最开始由于server模块中没有配置proxy_set_header请求头，导致到了登录界面输入密码，却无法跳转进入vs-code界面。后面查看coder官方文档发现，code-server要求请求需使用websocket协议才能进行通信。官网原文:https://coder.com/docs/code-server/latest/guide#using-lets-encrypt-with-nginx To work properly, your environment should have WebSockets enabled, which code-server uses to communicate between the browser and server.(为了正常工作，您的环境应该启用 WebSockets，代码服务器使用它在浏览器和服务器之间进行通信。) ","date":"2021-09-10","objectID":"/code-server/:0:7","series":null,"tags":[],"title":"云IDE：code-server安装使用","uri":"/code-server/#坑点2"},{"categories":["随笔"],"content":" 《娱乐至死》是美国批评家尼尔·波兹曼在1985年写成出版的，这本书主要阐述了在二十世纪后半叶美国文化中的重大变化也就是电视业的蓬勃发展和传统印刷业的没落所带来的诸多问题的批判和思考。 在传统印刷业，也就是所谓的“阐释时代”，信息的组织是具有逻辑和语境的，人们从中获得了思考和智慧。而随着电视的普及，进入电视时代的人们更愿意接受娱乐化的信息，而渐渐排斥原本具有严肃性的东西。一开始，很多严肃的新闻或者具有教育意义的节目，也都是通过电视来呈现给大众的，但久而久之，由于各种各样的原因，这些原本具有严肃性的东西等也都纷纷向娱乐靠拢。 似乎一切的内容都以娱乐的形式呈现，大量的信息充斥在人们的生活中，信息变得碎片化。虽然看似我们从电视中获取了很多新闻资讯、很多知识，但是这些信息是没有语境和逻辑的，我们并没有主动去思考或者说已经没有机会去思考这里面的真假，很多观点都是别人整理好后塞给我们的。 我们通过电视媒体，给自己制造了获取很多知识的假象，我们已经很少去真正思考信息的来源以及信息的真假，只是被动地接受，最后，看似收获了很多知识，实则一无所获。 进入互联网时代也是一样，我们心甘情愿的沦为娱乐的附庸，无脑的享受着各种各样的新闻、娱乐资讯，刷微博，刷抖音，刷b站，越来越偏向于不动大脑的开怀大笑，最后成为一个娱乐至死的物种。 读完这本书，我才后知后觉，过去做过的很多事情，譬如看了很多电影、书、纪录片，实际上我真正深入思考的有多少？就算是我爱看的历史纪录片，事实上更多时候我也是听听故事，并没有多少时刻去认真思考整个历史事件的起因、经过和结局对于历史的推进作用。 当然，如果生活中只存在严肃性的东西，禁止一切娱乐，那也太矫枉过正了，显得生活太枯燥。我们不应该禁止娱乐，更正确的方式，我想应该是减少娱乐的时间，只在碎片化的时间段内浏览一些娱乐资讯，更多大块的时间用来读书和思考，真正提高个人整体素质和境界。 ","date":"2021-06-17","objectID":"/amusing-to-death/:0:0","series":null,"tags":[],"title":"娱乐至死","uri":"/amusing-to-death/#"},{"categories":[],"content":"添加评论系统启用评论系统utterances 在hugo的配置文件（config.toml）中启用utterances，打开config.toml，添加如下： # Utterances comment 评论系统设置 (https://utteranc.es/) [params.page.comment.utterances] enable = true # owner/repo repo = \"YourUsername/YourUsername.github.io\" ##自己的github仓库地址 issueTerm = \"pathname\" label = \"\" lightTheme = \"github-light\" darkTheme = \"github-dark\" repo的格式为：github用户名/创建的仓库名 github上安装 utterances 首先必须在 github 上进行安装 utterances，访问 utterances应用程序 然后点击 Install 按钮进行安装。 在这里可以选择可以关联的存储库，可以选择我们所拥有的库(也包括未来建立的库)或者某一个仓库，这里只选择某一个需要进行评论的库，这样比较好。 安装完成即可，随后访问 utterances应用程序 就不再是安装而是是执行配置项目。 此时服务端配置已经完成，接着访问博客测试下评论。 ","date":"2021-06-04","objectID":"/theme-seo/:0:1","series":null,"tags":[],"title":"主题优化-添加评论系统和内置搜索","uri":"/theme-seo/#添加评论系统"},{"categories":[],"content":"添加评论系统启用评论系统utterances 在hugo的配置文件（config.toml）中启用utterances，打开config.toml，添加如下： # Utterances comment 评论系统设置 (https://utteranc.es/) [params.page.comment.utterances] enable = true # owner/repo repo = \"YourUsername/YourUsername.github.io\" ##自己的github仓库地址 issueTerm = \"pathname\" label = \"\" lightTheme = \"github-light\" darkTheme = \"github-dark\" repo的格式为：github用户名/创建的仓库名 github上安装 utterances 首先必须在 github 上进行安装 utterances，访问 utterances应用程序 然后点击 Install 按钮进行安装。 在这里可以选择可以关联的存储库，可以选择我们所拥有的库(也包括未来建立的库)或者某一个仓库，这里只选择某一个需要进行评论的库，这样比较好。 安装完成即可，随后访问 utterances应用程序 就不再是安装而是是执行配置项目。 此时服务端配置已经完成，接着访问博客测试下评论。 ","date":"2021-06-04","objectID":"/theme-seo/:0:1","series":null,"tags":[],"title":"主题优化-添加评论系统和内置搜索","uri":"/theme-seo/#启用评论系统utterances"},{"categories":[],"content":"添加评论系统启用评论系统utterances 在hugo的配置文件（config.toml）中启用utterances，打开config.toml，添加如下： # Utterances comment 评论系统设置 (https://utteranc.es/) [params.page.comment.utterances] enable = true # owner/repo repo = \"YourUsername/YourUsername.github.io\" ##自己的github仓库地址 issueTerm = \"pathname\" label = \"\" lightTheme = \"github-light\" darkTheme = \"github-dark\" repo的格式为：github用户名/创建的仓库名 github上安装 utterances 首先必须在 github 上进行安装 utterances，访问 utterances应用程序 然后点击 Install 按钮进行安装。 在这里可以选择可以关联的存储库，可以选择我们所拥有的库(也包括未来建立的库)或者某一个仓库，这里只选择某一个需要进行评论的库，这样比较好。 安装完成即可，随后访问 utterances应用程序 就不再是安装而是是执行配置项目。 此时服务端配置已经完成，接着访问博客测试下评论。 ","date":"2021-06-04","objectID":"/theme-seo/:0:1","series":null,"tags":[],"title":"主题优化-添加评论系统和内置搜索","uri":"/theme-seo/#github上安装-utterances"},{"categories":[],"content":"内置搜索系统 原理：在执行push操作触发Actions编译站点代码到./public目录后，再执行生成索引文件操作，生成index.json到./public目录，并自动上传文章索引至algolia上，以实现站内搜索功能。 algolia实现内置搜索 前往官方网站https://www.algolia.com/ 使用 GitHub 或 Google 帐号登录。登录完成后根据提示信息填写一些基本的信息即可，注册完成后前往 Dashboard，我们可以发现 Algolia 会默认给我们生成一个 app。 选择 Indices，添加一个新的索引，index-name索引名自定义填写，并记录下来，后面网站配置要用到。再选择API keys，记录“Search-Only API Key”、“Admin API Key”两个秘钥。 由于我这里使用的主题是LoveIt，主题配置文件config.toml内置支持algolia插件，所以只需要在站点目录下的config.toml中，配置刚刚生成的索引和Search-Only API Key即可： [root@web-blog web]# vim config.toml [languages.zh-cn.params.search] enable = true # 搜索引擎的类型 (\"lunr\", \"algolia\") type = \"algolia\" # 文章内容最长索引长度 contentLength = 4000 # 搜索框的占位提示语 placeholder = \"\" # 最大结果数目 maxResultLength = 10 # 结果内容片段长度 snippetLength = 50 # 搜索结果中高亮部分的 HTML 标签 highlightTag = \"em\" # 是否在搜索索引中使用基于 baseURL 的绝对路径 absoluteURL = false [languages.zh-cn.params.search.algolia] index = \"yuepu-blog\" #索引名称 appID = \"SSC09FNCJM\" #应用ID searchKey = \"b42948e51daaa93df92381c8e2ac0f93\" #Search-Only API Key 利用GitHub Action配置自动上传索引文件编辑GitHub Action的CI/CD 配置文件gh-pages.yml，安装algoliasearch，并且使用Node.js配置秘钥文件： [root@web-blog web]# vim .github/workflows/gh-pages.yml ... - name: Use Node.js uses: actions/setup-node@v1 with: node-version: '15.x' - name: Push Argolia Index run: | npm install algoliasearch #安装algoliasearch插件 node push_argolia_index.js #使用我们配置的js文件 env: ALGOLIA_ADMIN_KEY: ${{ secrets.ALGOLIA_ADMIN_KEY }} 然后在站点根目录新建push_argolia_index.js文件，内容如下： /* 上传 algolia 索引文件 参考：https://www.algolia.com/doc/guides/getting-started/quick-start/tutorials/quick-start-with-the-api-client/javascript/?client=javascript */ // For the default version const algoliasearch = require('algoliasearch'); const appID = \"747LJ10EI7\" const indexName = \"ryan-space\" const adminKey = process.env.ALGOLIA_ADMIN_KEY const indexFile = \"./public/index.json\" const client = algoliasearch(appID, adminKey); const index = client.initIndex(indexName); const indexJson = require(indexFile); index.saveObjects(indexJson, { autoGenerateObjectIDIfNotExist: true }).then(({ objectIDs }) =\u003e { console.log(objectIDs); }); 这里我们一直没有用到的Admin API Key，需要在Setting -\u003e Secrets，新建仓库秘钥，名字取为ALGOLIA_ADMIN_KEY，以便Action 和 js中调用。 至此，配置就完成了。 ","date":"2021-06-04","objectID":"/theme-seo/:0:2","series":null,"tags":[],"title":"主题优化-添加评论系统和内置搜索","uri":"/theme-seo/#内置搜索系统"},{"categories":[],"content":"内置搜索系统 原理：在执行push操作触发Actions编译站点代码到./public目录后，再执行生成索引文件操作，生成index.json到./public目录，并自动上传文章索引至algolia上，以实现站内搜索功能。 algolia实现内置搜索 前往官方网站https://www.algolia.com/ 使用 GitHub 或 Google 帐号登录。登录完成后根据提示信息填写一些基本的信息即可，注册完成后前往 Dashboard，我们可以发现 Algolia 会默认给我们生成一个 app。 选择 Indices，添加一个新的索引，index-name索引名自定义填写，并记录下来，后面网站配置要用到。再选择API keys，记录“Search-Only API Key”、“Admin API Key”两个秘钥。 由于我这里使用的主题是LoveIt，主题配置文件config.toml内置支持algolia插件，所以只需要在站点目录下的config.toml中，配置刚刚生成的索引和Search-Only API Key即可： [root@web-blog web]# vim config.toml [languages.zh-cn.params.search] enable = true # 搜索引擎的类型 (\"lunr\", \"algolia\") type = \"algolia\" # 文章内容最长索引长度 contentLength = 4000 # 搜索框的占位提示语 placeholder = \"\" # 最大结果数目 maxResultLength = 10 # 结果内容片段长度 snippetLength = 50 # 搜索结果中高亮部分的 HTML 标签 highlightTag = \"em\" # 是否在搜索索引中使用基于 baseURL 的绝对路径 absoluteURL = false [languages.zh-cn.params.search.algolia] index = \"yuepu-blog\" #索引名称 appID = \"SSC09FNCJM\" #应用ID searchKey = \"b42948e51daaa93df92381c8e2ac0f93\" #Search-Only API Key 利用GitHub Action配置自动上传索引文件编辑GitHub Action的CI/CD 配置文件gh-pages.yml，安装algoliasearch，并且使用Node.js配置秘钥文件： [root@web-blog web]# vim .github/workflows/gh-pages.yml ... - name: Use Node.js uses: actions/setup-node@v1 with: node-version: '15.x' - name: Push Argolia Index run: | npm install algoliasearch #安装algoliasearch插件 node push_argolia_index.js #使用我们配置的js文件 env: ALGOLIA_ADMIN_KEY: ${{ secrets.ALGOLIA_ADMIN_KEY }} 然后在站点根目录新建push_argolia_index.js文件，内容如下： /* 上传 algolia 索引文件 参考：https://www.algolia.com/doc/guides/getting-started/quick-start/tutorials/quick-start-with-the-api-client/javascript/?client=javascript */ // For the default version const algoliasearch = require('algoliasearch'); const appID = \"747LJ10EI7\" const indexName = \"ryan-space\" const adminKey = process.env.ALGOLIA_ADMIN_KEY const indexFile = \"./public/index.json\" const client = algoliasearch(appID, adminKey); const index = client.initIndex(indexName); const indexJson = require(indexFile); index.saveObjects(indexJson, { autoGenerateObjectIDIfNotExist: true }).then(({ objectIDs }) = { console.log(objectIDs); }); 这里我们一直没有用到的Admin API Key，需要在Setting - Secrets，新建仓库秘钥，名字取为ALGOLIA_ADMIN_KEY，以便Action 和 js中调用。 至此，配置就完成了。 ","date":"2021-06-04","objectID":"/theme-seo/:0:2","series":null,"tags":[],"title":"主题优化-添加评论系统和内置搜索","uri":"/theme-seo/#algolia实现内置搜索"},{"categories":[],"content":"内置搜索系统 原理：在执行push操作触发Actions编译站点代码到./public目录后，再执行生成索引文件操作，生成index.json到./public目录，并自动上传文章索引至algolia上，以实现站内搜索功能。 algolia实现内置搜索 前往官方网站https://www.algolia.com/ 使用 GitHub 或 Google 帐号登录。登录完成后根据提示信息填写一些基本的信息即可，注册完成后前往 Dashboard，我们可以发现 Algolia 会默认给我们生成一个 app。 选择 Indices，添加一个新的索引，index-name索引名自定义填写，并记录下来，后面网站配置要用到。再选择API keys，记录“Search-Only API Key”、“Admin API Key”两个秘钥。 由于我这里使用的主题是LoveIt，主题配置文件config.toml内置支持algolia插件，所以只需要在站点目录下的config.toml中，配置刚刚生成的索引和Search-Only API Key即可： [root@web-blog web]# vim config.toml [languages.zh-cn.params.search] enable = true # 搜索引擎的类型 (\"lunr\", \"algolia\") type = \"algolia\" # 文章内容最长索引长度 contentLength = 4000 # 搜索框的占位提示语 placeholder = \"\" # 最大结果数目 maxResultLength = 10 # 结果内容片段长度 snippetLength = 50 # 搜索结果中高亮部分的 HTML 标签 highlightTag = \"em\" # 是否在搜索索引中使用基于 baseURL 的绝对路径 absoluteURL = false [languages.zh-cn.params.search.algolia] index = \"yuepu-blog\" #索引名称 appID = \"SSC09FNCJM\" #应用ID searchKey = \"b42948e51daaa93df92381c8e2ac0f93\" #Search-Only API Key 利用GitHub Action配置自动上传索引文件编辑GitHub Action的CI/CD 配置文件gh-pages.yml，安装algoliasearch，并且使用Node.js配置秘钥文件： [root@web-blog web]# vim .github/workflows/gh-pages.yml ... - name: Use Node.js uses: actions/setup-node@v1 with: node-version: '15.x' - name: Push Argolia Index run: | npm install algoliasearch #安装algoliasearch插件 node push_argolia_index.js #使用我们配置的js文件 env: ALGOLIA_ADMIN_KEY: ${{ secrets.ALGOLIA_ADMIN_KEY }} 然后在站点根目录新建push_argolia_index.js文件，内容如下： /* 上传 algolia 索引文件 参考：https://www.algolia.com/doc/guides/getting-started/quick-start/tutorials/quick-start-with-the-api-client/javascript/?client=javascript */ // For the default version const algoliasearch = require('algoliasearch'); const appID = \"747LJ10EI7\" const indexName = \"ryan-space\" const adminKey = process.env.ALGOLIA_ADMIN_KEY const indexFile = \"./public/index.json\" const client = algoliasearch(appID, adminKey); const index = client.initIndex(indexName); const indexJson = require(indexFile); index.saveObjects(indexJson, { autoGenerateObjectIDIfNotExist: true }).then(({ objectIDs }) = { console.log(objectIDs); }); 这里我们一直没有用到的Admin API Key，需要在Setting - Secrets，新建仓库秘钥，名字取为ALGOLIA_ADMIN_KEY，以便Action 和 js中调用。 至此，配置就完成了。 ","date":"2021-06-04","objectID":"/theme-seo/:0:2","series":null,"tags":[],"title":"主题优化-添加评论系统和内置搜索","uri":"/theme-seo/#利用github-action配置自动上传索引文件"},{"categories":[],"content":"参考 Hugo 博客使用 utterances 作为评论系统 algolia官网 上传 algolia 索引文件 参考：https://www.algolia.com/doc/guides/getting-started/quick-start/tutorials/quick-start-with-the-api-client/javascript/?client=javascript ","date":"2021-06-04","objectID":"/theme-seo/:0:3","series":null,"tags":[],"title":"主题优化-添加评论系统和内置搜索","uri":"/theme-seo/#参考"},{"categories":[],"content":"Google-SRE教程 ","date":"2021-06-04","objectID":"/links/:0:0","series":null,"tags":[],"title":"学习资料","uri":"/links/#"},{"categories":[],"content":"wiki–运维文档 此社区目的有两点： 1.共同整理出标准文档，进行持续维护，方便大家查阅使用 2.一起研究出一些东西出来，推动国内的运维技术发展 ","date":"2021-06-04","objectID":"/links/:0:1","series":null,"tags":[],"title":"学习资料","uri":"/links/#wiki--运维文档httpswww52wikicn"},{"categories":[],"content":"K8s训练营 阳明的博客 GO example 中文版 鸟哥的Linux私房菜 ","date":"2021-06-04","objectID":"/links/:0:2","series":null,"tags":[],"title":"学习资料","uri":"/links/#k8s训练营httpswwwqikqiakcom"},{"categories":[],"content":" 感谢 @Ryan4Yin 提供的友链页面模板~ LoveIt主题菜单栏标签参考（https://zhaouncle.com） 在友链形成的网络中漫游，是一件很有意思的事情。 以前的人们通过信笺交流，而我们通过友链串联起一个「世界」。希望你我都能在这个「世界」中有所收获 注： 下方友链次序每次刷新页面随机排列。 ","date":"2021-05-31","objectID":"/friends/:0:0","series":null,"tags":[],"title":"友链","uri":"/friends/#"},{"categories":[],"content":"交换友链如果你觉得我的博客有些意思，而且也有自己的独立博客，欢迎与我交换友链~ 可通过 Issues 或者评论区提交友链申请，格式如下： 站点名称：Yuepu`s Blog 站点地址: https://hyoung.site/ 个人形象：https://hyoung.site/images/avatar.jpg 站点描述：不急，但是不停~ // 以下为样例内容，按照格式可以随意修改 var myFriends = [ [\"https://chee5e.space\", \"https://chee5e.space/images/avatar.jpg\", \"@芝士部落格\", \"有思想，也有忧伤和理想，芝士就是力量\"], [\"https://blog.k8s.li/\", \"/avatar.png\", \"@木子\", \"垃圾佬、搬砖社畜、运维工程师 0) { var rndNum = Math.floor(Math.random()*myFriends.length); var friendNode = document.createElement(\"li\"); var friend_link = document.createElement(\"a\"), friend_img = document.createElement(\"img\"), friend_name = document.createElement(\"h4\"), friend_about = document.createElement(\"p\") ; friend_link.target = \"_blank\"; friend_link.href = myFriends[rndNum][0]; friend_img.src=myFriends[rndNum][1]; friend_name.innerText = myFriends[rndNum][2]; friend_about.innerText = myFriends[rndNum][3]; friend_link.appendChild(friend_img); friend_link.appendChild(friend_name); friend_link.appendChild(friend_about); friendNode.appendChild(friend_link); targetList.appendChild(friendNode); myFriends.splice(rndNum, 1); } .linkpage ul { color: rgba(255,255,255,.15) } .linkpage ul:after { content: \" \"; clear: both; display: block } .linkpage li { float: left; width: 48%; position: relative; -webkit-transition: .3s ease-out; transition: .3s ease-out; border-radius: 5px; line-height: 1.3; height: 90px; display: block } .linkpage h3 { margin: 15px -25px; padding: 0 25px; border-left: 5px solid #51aded; background-color: #f7f7f7; font-size: 25px; line-height: 40px } .linkpage li:hover { background: rgba(230,244,250,.5); cursor: pointer } .linkpage li a { padding: 0 10px 0 90px } .linkpage li a img { width: 60px; height: 60px; border-radius: 50%; position: absolute; top: 15px; left: 15px; cursor: pointer; margin: auto; border: none } .linkpage li a h4 { color: #333; font-size: 18px; margin: 0 0 7px; padding-left: 90px } .linkpage li a h4:hover { color: #51aded } .linkpage li a h4, .linkpage li a p { cursor: pointer; white-space: nowrap; text-overflow: ellipsis; overflow: hidden; line-height: 1.4; margin: 0 !important; } .linkpage li a p { font-size: 12px; color: #999; padding-left: 90px } @media(max-width: 460px) { .linkpage li { width:97% } .linkpage ul { padding-left: 5px } } ","date":"2021-05-31","objectID":"/friends/:1:0","series":null,"tags":[],"title":"友链","uri":"/friends/#交换友链"},{"categories":null,"content":" 关于我 （ “曾以为走不出去的日子,现在都回不去了。”——村上春树 《且听风吟》） 保持独立思考，不急，但是不停。 昵称：乐谱 游戏：游戏热爱者，参与过MMORPG游戏《莽荒纪》（C++）的游戏模块开发和运维工作，也参与过H5游戏《九州幻境城》（lua）的服务端运维。 影视：看得最多的是动漫了，科幻、悬疑类型也很喜欢。 运动：跑步、游泳、登山。 编程语言： shell：工作语言。 Python：学习中。 曾经使用过但已经荒废的语言：Java|C++。 职业：运维工程师 目前主要以提升业务稳定性和服务响应为主的业务运维工作，目标是掌握python语言，成为运维开发工程师，并学习kubernetes，熟悉云原生技术圈，思考如何更好地利用这些技术优化基础设施，使基础设施能稳定高效地支撑业务不断成长。 理论基础：计算机网络和Linux 底层知识还很欠缺，数据结构和设计模式有时间可以看看，数据库、中间件等分布式原理知识知之甚少。还有太多需要补习的理论基础知识。 关于此博客 “对我来说，博客首先是一种知识管理工具，其次才是传播工具。我的技术文章，主要用来整理我还不懂的知识。我只写那些我还没有完全掌握的东西，那些我精通的东西，往往没有动力写。炫耀从来不是我的动机，好奇才是。\" ──阮一峰 目的是想让博客成为我在互联网世界的一张名片和一个入口。其实记录在哪里都能记录，现在移动端如此普及，但我更希望能创建一个统一的入口，能够对自己的所学所感进行思考和总结，使其以规范的方式展现出来。 注意事项博客中的内容说到底也只是我一家之言，我只能尽量去减少错漏，但不能保证内容的正确性！ 因此请带着批判的眼光看待本博客中的任何内容。 话外互联网浩如烟海，这个小站偏安一隅，如果它有幸被你发现，而且其中文字对你还有些帮助，那可真是太棒了！感谢有你~ ","date":"2021-05-27","objectID":"/about/:0:0","series":null,"tags":null,"title":"关于我","uri":"/about/#"},{"categories":null,"content":" 关于我 （ “曾以为走不出去的日子,现在都回不去了。”——村上春树 《且听风吟》） 保持独立思考，不急，但是不停。 昵称：乐谱 游戏：游戏热爱者，参与过MMORPG游戏《莽荒纪》（C++）的游戏模块开发和运维工作，也参与过H5游戏《九州幻境城》（lua）的服务端运维。 影视：看得最多的是动漫了，科幻、悬疑类型也很喜欢。 运动：跑步、游泳、登山。 编程语言： shell：工作语言。 Python：学习中。 曾经使用过但已经荒废的语言：Java|C++。 职业：运维工程师 目前主要以提升业务稳定性和服务响应为主的业务运维工作，目标是掌握python语言，成为运维开发工程师，并学习kubernetes，熟悉云原生技术圈，思考如何更好地利用这些技术优化基础设施，使基础设施能稳定高效地支撑业务不断成长。 理论基础：计算机网络和Linux 底层知识还很欠缺，数据结构和设计模式有时间可以看看，数据库、中间件等分布式原理知识知之甚少。还有太多需要补习的理论基础知识。 关于此博客 “对我来说，博客首先是一种知识管理工具，其次才是传播工具。我的技术文章，主要用来整理我还不懂的知识。我只写那些我还没有完全掌握的东西，那些我精通的东西，往往没有动力写。炫耀从来不是我的动机，好奇才是。\" ──阮一峰 目的是想让博客成为我在互联网世界的一张名片和一个入口。其实记录在哪里都能记录，现在移动端如此普及，但我更希望能创建一个统一的入口，能够对自己的所学所感进行思考和总结，使其以规范的方式展现出来。 注意事项博客中的内容说到底也只是我一家之言，我只能尽量去减少错漏，但不能保证内容的正确性！ 因此请带着批判的眼光看待本博客中的任何内容。 话外互联网浩如烟海，这个小站偏安一隅，如果它有幸被你发现，而且其中文字对你还有些帮助，那可真是太棒了！感谢有你~ ","date":"2021-05-27","objectID":"/about/:0:0","series":null,"tags":null,"title":"关于我","uri":"/about/#关于我"},{"categories":null,"content":" 关于我 （ “曾以为走不出去的日子,现在都回不去了。”——村上春树 《且听风吟》） 保持独立思考，不急，但是不停。 昵称：乐谱 游戏：游戏热爱者，参与过MMORPG游戏《莽荒纪》（C++）的游戏模块开发和运维工作，也参与过H5游戏《九州幻境城》（lua）的服务端运维。 影视：看得最多的是动漫了，科幻、悬疑类型也很喜欢。 运动：跑步、游泳、登山。 编程语言： shell：工作语言。 Python：学习中。 曾经使用过但已经荒废的语言：Java|C++。 职业：运维工程师 目前主要以提升业务稳定性和服务响应为主的业务运维工作，目标是掌握python语言，成为运维开发工程师，并学习kubernetes，熟悉云原生技术圈，思考如何更好地利用这些技术优化基础设施，使基础设施能稳定高效地支撑业务不断成长。 理论基础：计算机网络和Linux 底层知识还很欠缺，数据结构和设计模式有时间可以看看，数据库、中间件等分布式原理知识知之甚少。还有太多需要补习的理论基础知识。 关于此博客 “对我来说，博客首先是一种知识管理工具，其次才是传播工具。我的技术文章，主要用来整理我还不懂的知识。我只写那些我还没有完全掌握的东西，那些我精通的东西，往往没有动力写。炫耀从来不是我的动机，好奇才是。\" ──阮一峰 目的是想让博客成为我在互联网世界的一张名片和一个入口。其实记录在哪里都能记录，现在移动端如此普及，但我更希望能创建一个统一的入口，能够对自己的所学所感进行思考和总结，使其以规范的方式展现出来。 注意事项博客中的内容说到底也只是我一家之言，我只能尽量去减少错漏，但不能保证内容的正确性！ 因此请带着批判的眼光看待本博客中的任何内容。 话外互联网浩如烟海，这个小站偏安一隅，如果它有幸被你发现，而且其中文字对你还有些帮助，那可真是太棒了！感谢有你~ ","date":"2021-05-27","objectID":"/about/:0:0","series":null,"tags":null,"title":"关于我","uri":"/about/#关于此博客"},{"categories":null,"content":" 关于我 （ “曾以为走不出去的日子,现在都回不去了。”——村上春树 《且听风吟》） 保持独立思考，不急，但是不停。 昵称：乐谱 游戏：游戏热爱者，参与过MMORPG游戏《莽荒纪》（C++）的游戏模块开发和运维工作，也参与过H5游戏《九州幻境城》（lua）的服务端运维。 影视：看得最多的是动漫了，科幻、悬疑类型也很喜欢。 运动：跑步、游泳、登山。 编程语言： shell：工作语言。 Python：学习中。 曾经使用过但已经荒废的语言：Java|C++。 职业：运维工程师 目前主要以提升业务稳定性和服务响应为主的业务运维工作，目标是掌握python语言，成为运维开发工程师，并学习kubernetes，熟悉云原生技术圈，思考如何更好地利用这些技术优化基础设施，使基础设施能稳定高效地支撑业务不断成长。 理论基础：计算机网络和Linux 底层知识还很欠缺，数据结构和设计模式有时间可以看看，数据库、中间件等分布式原理知识知之甚少。还有太多需要补习的理论基础知识。 关于此博客 “对我来说，博客首先是一种知识管理工具，其次才是传播工具。我的技术文章，主要用来整理我还不懂的知识。我只写那些我还没有完全掌握的东西，那些我精通的东西，往往没有动力写。炫耀从来不是我的动机，好奇才是。\" ──阮一峰 目的是想让博客成为我在互联网世界的一张名片和一个入口。其实记录在哪里都能记录，现在移动端如此普及，但我更希望能创建一个统一的入口，能够对自己的所学所感进行思考和总结，使其以规范的方式展现出来。 注意事项博客中的内容说到底也只是我一家之言，我只能尽量去减少错漏，但不能保证内容的正确性！ 因此请带着批判的眼光看待本博客中的任何内容。 话外互联网浩如烟海，这个小站偏安一隅，如果它有幸被你发现，而且其中文字对你还有些帮助，那可真是太棒了！感谢有你~ ","date":"2021-05-27","objectID":"/about/:0:0","series":null,"tags":null,"title":"关于我","uri":"/about/#注意事项"},{"categories":null,"content":" 关于我 （ “曾以为走不出去的日子,现在都回不去了。”——村上春树 《且听风吟》） 保持独立思考，不急，但是不停。 昵称：乐谱 游戏：游戏热爱者，参与过MMORPG游戏《莽荒纪》（C++）的游戏模块开发和运维工作，也参与过H5游戏《九州幻境城》（lua）的服务端运维。 影视：看得最多的是动漫了，科幻、悬疑类型也很喜欢。 运动：跑步、游泳、登山。 编程语言： shell：工作语言。 Python：学习中。 曾经使用过但已经荒废的语言：Java|C++。 职业：运维工程师 目前主要以提升业务稳定性和服务响应为主的业务运维工作，目标是掌握python语言，成为运维开发工程师，并学习kubernetes，熟悉云原生技术圈，思考如何更好地利用这些技术优化基础设施，使基础设施能稳定高效地支撑业务不断成长。 理论基础：计算机网络和Linux 底层知识还很欠缺，数据结构和设计模式有时间可以看看，数据库、中间件等分布式原理知识知之甚少。还有太多需要补习的理论基础知识。 关于此博客 “对我来说，博客首先是一种知识管理工具，其次才是传播工具。我的技术文章，主要用来整理我还不懂的知识。我只写那些我还没有完全掌握的东西，那些我精通的东西，往往没有动力写。炫耀从来不是我的动机，好奇才是。\" ──阮一峰 目的是想让博客成为我在互联网世界的一张名片和一个入口。其实记录在哪里都能记录，现在移动端如此普及，但我更希望能创建一个统一的入口，能够对自己的所学所感进行思考和总结，使其以规范的方式展现出来。 注意事项博客中的内容说到底也只是我一家之言，我只能尽量去减少错漏，但不能保证内容的正确性！ 因此请带着批判的眼光看待本博客中的任何内容。 话外互联网浩如烟海，这个小站偏安一隅，如果它有幸被你发现，而且其中文字对你还有些帮助，那可真是太棒了！感谢有你~ ","date":"2021-05-27","objectID":"/about/:0:0","series":null,"tags":null,"title":"关于我","uri":"/about/#话外"},{"categories":[],"content":"现在市面上的博客很多，如CSDN，博客园，简书等平台，可以直接在上面发表，用户交互做的好，写的文章百度也能搜索的到。缺点是比较不自由，会受到平台的各种限制和恶心的广告。 而自己购买域名和服务器，搭建博客的成本实在是太高了，不光是说这些购买成本，单单是花力气去自己搭这么一个网站，还要定期的维护它，对于我们大多数人来说，实在是没有这样的精力和时间。 那么就有第三种选择，直接在github page平台上托管我们的博客。这样就可以安心的来写作，又不需要定期维护，而且Hugo作为一个快速简洁的博客框架，用它来搭建博客真的非常容易。 ","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:0","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#"},{"categories":[],"content":"前言Hugo 是一个基于Go语言开发的静态博客框架，号称世界上最快的构建网站工具。本文是我在网上看的其他人的博客和一些up主的视频，通过他们的分享成功搭建好了的案例，在这里我也进行一次总结，方便以后使用。 ","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:1","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#前言"},{"categories":[],"content":"目的通过把博客文章的源代码托管到GitHub仓库，利用GitHub Actions for Hugo功能持续集成部署，利用GitHub Pages实现网站的发布和访问，生成一个自己专属的个人博客网站。 ","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:2","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#目的"},{"categories":[],"content":"流程及原理 本地新建文章，push到 Github仓库的 main分支。main分支存放博客文章的源码。 push 操作自动触发预先配置的Actions。 GitHub Action自动执行yml文件中的\"action\"，构建打包，推送至gh-pages分支。 通过 Github Pages生成的 URL 访问即可。 ","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:3","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#流程及原理"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—\u003eNew repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-\u003eSettings-\u003eSSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \u003cTHEMENAME\u003e\" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new \u003cSECTIONNAME\u003e/\u003cFILENAME\u003e.\u003cFORMAT\u003e\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#详细步骤"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#安装git和关联github"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#安装hugo"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#下载hugo"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#生成博客"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#下载主题"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#启动博客"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#写一篇文章"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#编译博客"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#推送到github"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#使用github-pages实现访问"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#使用github-action自动化部署"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#配置github_token"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#配置github-action"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#推送博客源码"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#修改pages源分支"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#域名绑定"},{"categories":[],"content":"搭建遇到的问题hugo配置文件参数错误在本地使用hugo server命令进行本地编译预览时报错: WARN 2020/02/17 20:51:06 found no layout file for \"HTML\" for \"page\": You should create a template file which matches Hugo Layouts Lookup Rules for this combination. 意思为：“找不到用于“页面”的“ HTML”布局文件”。 原因是没有指定所使用的主题。由于hugo new site mysite新建出来的站点目录中，存放主题的目录名为“themes”，导致我以为hugo的站点配置文件config.toml里指定的主题键名为”themes“，而实际应该是“theme”才对，才能正常编译。 [root@web-blog myblog]# vim themes/even/exampleSite/config.toml baseURL = \"http://localhost:1313/\" languageCode = \"en\" defaultContentLanguage = \"en\" # en / zh-cn / ... (This field determines which i18n file to use) title = \"Even - A super concise theme for Hugo\" preserveTaxonomyNames = true enableRobotsTXT = true enableEmoji = true theme = \"even\" 编译成功访问页面没有文章显示使用hugo new post/index.md新建的文章，是以./archetypes/default.md为模板创建的，默认的draft的值为true，hugo在编译时会忽略所有draft为true的文章，导致编译成功访问站点时发现没有文章显示。 解决办法：文章中draft（草稿）的值需设置为false，或者去掉./archetypes/default.md文件中的draft参数 每次git push之后，刷新站点就显示404写完文章push到github上之后，再刷新站点会显示404，网页找不到。然后到github pages检查发现之前绑定的域名被清空了。 解决办法：需要在gh-pages.yaml文件中加上cname选项，值为自己的域名。 - name:Deployuses:peaceiris/actions-gh-pages@v3with:github_token:${{ secrets.ACCESS_TOKEN }}publish_dir:./publiccname:domain.com ","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:5","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#搭建遇到的问题"},{"categories":[],"content":"搭建遇到的问题hugo配置文件参数错误在本地使用hugo server命令进行本地编译预览时报错: WARN 2020/02/17 20:51:06 found no layout file for \"HTML\" for \"page\": You should create a template file which matches Hugo Layouts Lookup Rules for this combination. 意思为：“找不到用于“页面”的“ HTML”布局文件”。 原因是没有指定所使用的主题。由于hugo new site mysite新建出来的站点目录中，存放主题的目录名为“themes”，导致我以为hugo的站点配置文件config.toml里指定的主题键名为”themes“，而实际应该是“theme”才对，才能正常编译。 [root@web-blog myblog]# vim themes/even/exampleSite/config.toml baseURL = \"http://localhost:1313/\" languageCode = \"en\" defaultContentLanguage = \"en\" # en / zh-cn / ... (This field determines which i18n file to use) title = \"Even - A super concise theme for Hugo\" preserveTaxonomyNames = true enableRobotsTXT = true enableEmoji = true theme = \"even\" 编译成功访问页面没有文章显示使用hugo new post/index.md新建的文章，是以./archetypes/default.md为模板创建的，默认的draft的值为true，hugo在编译时会忽略所有draft为true的文章，导致编译成功访问站点时发现没有文章显示。 解决办法：文章中draft（草稿）的值需设置为false，或者去掉./archetypes/default.md文件中的draft参数 每次git push之后，刷新站点就显示404写完文章push到github上之后，再刷新站点会显示404，网页找不到。然后到github pages检查发现之前绑定的域名被清空了。 解决办法：需要在gh-pages.yaml文件中加上cname选项，值为自己的域名。 - name:Deployuses:peaceiris/actions-gh-pages@v3with:github_token:${{ secrets.ACCESS_TOKEN }}publish_dir:./publiccname:domain.com ","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:5","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#hugo配置文件参数错误"},{"categories":[],"content":"搭建遇到的问题hugo配置文件参数错误在本地使用hugo server命令进行本地编译预览时报错: WARN 2020/02/17 20:51:06 found no layout file for \"HTML\" for \"page\": You should create a template file which matches Hugo Layouts Lookup Rules for this combination. 意思为：“找不到用于“页面”的“ HTML”布局文件”。 原因是没有指定所使用的主题。由于hugo new site mysite新建出来的站点目录中，存放主题的目录名为“themes”，导致我以为hugo的站点配置文件config.toml里指定的主题键名为”themes“，而实际应该是“theme”才对，才能正常编译。 [root@web-blog myblog]# vim themes/even/exampleSite/config.toml baseURL = \"http://localhost:1313/\" languageCode = \"en\" defaultContentLanguage = \"en\" # en / zh-cn / ... (This field determines which i18n file to use) title = \"Even - A super concise theme for Hugo\" preserveTaxonomyNames = true enableRobotsTXT = true enableEmoji = true theme = \"even\" 编译成功访问页面没有文章显示使用hugo new post/index.md新建的文章，是以./archetypes/default.md为模板创建的，默认的draft的值为true，hugo在编译时会忽略所有draft为true的文章，导致编译成功访问站点时发现没有文章显示。 解决办法：文章中draft（草稿）的值需设置为false，或者去掉./archetypes/default.md文件中的draft参数 每次git push之后，刷新站点就显示404写完文章push到github上之后，再刷新站点会显示404，网页找不到。然后到github pages检查发现之前绑定的域名被清空了。 解决办法：需要在gh-pages.yaml文件中加上cname选项，值为自己的域名。 - name:Deployuses:peaceiris/actions-gh-pages@v3with:github_token:${{ secrets.ACCESS_TOKEN }}publish_dir:./publiccname:domain.com ","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:5","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#编译成功访问页面没有文章显示"},{"categories":[],"content":"搭建遇到的问题hugo配置文件参数错误在本地使用hugo server命令进行本地编译预览时报错: WARN 2020/02/17 20:51:06 found no layout file for \"HTML\" for \"page\": You should create a template file which matches Hugo Layouts Lookup Rules for this combination. 意思为：“找不到用于“页面”的“ HTML”布局文件”。 原因是没有指定所使用的主题。由于hugo new site mysite新建出来的站点目录中，存放主题的目录名为“themes”，导致我以为hugo的站点配置文件config.toml里指定的主题键名为”themes“，而实际应该是“theme”才对，才能正常编译。 [root@web-blog myblog]# vim themes/even/exampleSite/config.toml baseURL = \"http://localhost:1313/\" languageCode = \"en\" defaultContentLanguage = \"en\" # en / zh-cn / ... (This field determines which i18n file to use) title = \"Even - A super concise theme for Hugo\" preserveTaxonomyNames = true enableRobotsTXT = true enableEmoji = true theme = \"even\" 编译成功访问页面没有文章显示使用hugo new post/index.md新建的文章，是以./archetypes/default.md为模板创建的，默认的draft的值为true，hugo在编译时会忽略所有draft为true的文章，导致编译成功访问站点时发现没有文章显示。 解决办法：文章中draft（草稿）的值需设置为false，或者去掉./archetypes/default.md文件中的draft参数 每次git push之后，刷新站点就显示404写完文章push到github上之后，再刷新站点会显示404，网页找不到。然后到github pages检查发现之前绑定的域名被清空了。 解决办法：需要在gh-pages.yaml文件中加上cname选项，值为自己的域名。 - name:Deployuses:peaceiris/actions-gh-pages@v3with:github_token:${{ secrets.ACCESS_TOKEN }}publish_dir:./publiccname:domain.com ","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:5","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#每次git-push之后刷新站点就显示404"},{"categories":[],"content":"参考链接Hugo官网：https://gohugo.io/ Hugo中文网：https://www.gohugo.cn/hosting-and-deployment/hosting-on-github/ Hugo中文帮助手册：https://hugo.aiaide.com/ Github Action 官方文档 GitHub Actions 入门教程 ","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:6","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#参考链接"},{"categories":[],"content":"Git操作命令总结 git push git push 命用于从将本地的分支版本上传到远程并合并。命令格式如下： git push \u003c远程主机名\u003e \u003c本地分支名\u003e:\u003c远程分支名\u003e 如果本地分支名与远程分支名相同，则可以省略冒号： git push \u003c远程主机名\u003e \u003c本地分支名\u003e git push -f 覆盖远程GitHub仓库的代码，强制推送。主要是为了解决本地仓库内容和远程仓库不一致而导致的push失败报错的问题，（在正常的开发项目中一般不建议这样操作，因为会覆盖所有其他成员提交的代码，只保留你自己的，属于危险操作！）： git push -f origin master #强制推送到origin源 git push -u origin master #正常推送到origin源 git checkout -b main #创建main分支并切换到main分支 git remote -v #查看本地添加的源地址 添加主题：使用git添加子模块的方式添加主题源地址，信息保存在.gitmodule git submodule add https://github.com/halogenica/beautifulhugo.git themes/beautifulhugo ","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:7","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#git操作命令总结"},{"categories":[],"content":"2021.07.12更新因GitHub宣布从 2021 年 8 月 13 日开始，我们将在对 Git 操作进行身份验证时不再接受帐户密码，并将要求使用基于令牌的身份验证。所以本地使用Git操作时，原先使用的账号密码验证身份的方式将被弃用，改成 用户名+token 的方式。 解决方法：点击GitHub头像-\u003eSetting -\u003e Developer settings -\u003e Personal access tokens -\u003e Generate new token，生成一个新的令牌。注意：生成之后需要立马复制下来，因为秘钥只会出现一次。 回到Git，需要清除之前使用的账户名和密码： vim ~/.gitconfig # 或者 cat /etc/git/.gitconfig [credential] # helper = store 注释掉这一行 再使用git push操作，此时会弹出需要验证账户密码，账户填写GitHub账户名，密码填写刚刚生成的token令牌。push成功之后，使用git config --global credential.helper store保存账户和令牌，下次再push就不用再输入账户密码了。 ","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:8","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#20210712更新"},{"categories":[],"content":"2021.08.12更新：Github Actions自动部署Hugo到Gitee同时刷新Gitee Pages Gitee仓库填入公钥 将id_rsa.pub 填入gitee仓库-\u003e settings→Deploy keys→add personal public key中 Github仓库填入私钥 将id_rsa 填入github仓库-\u003e Settings→Secret→New repository secre 用于之后的程序环境配置访问，命名为GITEE_RSA_PRIVATE_KEY 增加Actions代码 在 .github/workflows/gh-pages.yml文件中新增以下代码： sync: #同步到gitee仓库 needs: deploy runs-on: ubuntu-latest steps: - name: Sync to Gitee uses: wearerequired/git-mirror-action@master env: SSH_PRIVATE_KEY: ${{ secrets.GITEE_RSA_PRIVATE_KEY }} with: # 来源仓库 source-repo: \"git@github.com:JohntunLiu/myblog.git\" # 目标仓库 destination-repo: \"git@gitee.com:JohntunLiu/JohntunLiu.git\" reload-pages: #加载gitee-pages needs: sync runs-on: ubuntu-latest steps: - name: Build Gitee Pages uses: yanglbme/gitee-pages-action@main with: # 注意替换为你的 Gitee 用户名 gitee-username: JohntunLiu # 注意在 Settings-\u003eSecrets 配置 GITEE_PASSWORD gitee-password: ${{ secrets.GITEE_PASSWORD }} # 注意替换为你的 Gitee 仓库，仓库名严格区分大小写，请准确填写，否则会出错 gitee-repo: JohntunLiu/JohntunLiu # 要部署的分支，默认是 master，若是其他分支，则需要指定（指定的分支必须存在） branch: gh-pages commit 提交之后即每次push都会同步代码至gitee仓库上。 ","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:9","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#20210812更新github-actions自动部署hugo到gitee同时刷新gitee-pages"}]