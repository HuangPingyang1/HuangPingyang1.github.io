[{"categories":[],"content":"This file exists solely to respond to /search URL with the related search layout template. No content shown here is rendered, all content is based in the template layouts/page/search.html Setting a very low sitemap priority will tell search engines this is not important content. This implementation uses Fusejs, jquery and mark.js ","date":"2022-01-06","objectID":"/search/:0:0","series":null,"tags":[],"title":"Search Results","uri":"/search/#"},{"categories":[],"content":"Initial setupSearch depends on additional output content type of JSON in config.toml [outputs] home = [\"HTML\", \"JSON\"] ","date":"2022-01-06","objectID":"/search/:1:0","series":null,"tags":[],"title":"Search Results","uri":"/search/#initial-setup"},{"categories":[],"content":"Searching additional filedsTo search additional fields defined in front matter, you must add it in 2 places. ","date":"2022-01-06","objectID":"/search/:2:0","series":null,"tags":[],"title":"Search Results","uri":"/search/#searching-additional-fileds"},{"categories":[],"content":"Edit layouts/_default/index.JSONThis exposes the values in /index.json i.e. add category ... \"contents\":{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \"tags\":{{ .Params.tags | jsonify }}{{end}}, \"categories\" : {{ .Params.categories | jsonify }}, ... ","date":"2022-01-06","objectID":"/search/:2:1","series":null,"tags":[],"title":"Search Results","uri":"/search/#edit-layouts_defaultindexjson"},{"categories":[],"content":"Edit fuse.js options to Searchstatic/js/search.js keys: [ \"title\", \"contents\", \"tags\", \"categories\" ] ","date":"2022-01-06","objectID":"/search/:2:2","series":null,"tags":[],"title":"Search Results","uri":"/search/#edit-fusejs-options-to-search"},{"categories":[],"content":"Prometheus（普罗米修斯）监控系统","date":"2022-01-05","objectID":"/prometheus/:1:0","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#prometheus普罗米修斯监控系统"},{"categories":[],"content":"一、Prometheus概述1、什么是Prometheus？Prometheus [prəˈmi:θi:əs, -ˌθju:s] 是由SoundCloud使用Go语言开发的开源监控报警系统和时间序列数据库(TSDB)。Prometheus于 2016 年加入 云原生计算基金会（CNCF），作为继Kubernetes之后的第二个托管项目，因为kubernetes的流行带动了prometheus的发展。 2、时间序列数据什么是时间序列数据？ 时间序列数据(TimeSeries Data):按照时间顺序记录系统、设备状态变化的数据被称为时序数据。 应用的场景很多, 如： 无人驾驶车辆运行中要记录的经度，纬度，速度，方向，旁边物体的距离等等。每时每刻都要将数据记录下来做分析。 某一个地区的各车辆的行驶轨迹数据 传统证券行业实时交易数据 实时运维监控数据，CPU、内存等实时数据 时间序列数据特点： 性能好 关系型数据库对于大规模数据的处理性能糟糕。NOSQL可以比较好的处理大规模数据，让依然比不上时间序列数据库。 存储成本低 高效的压缩算法，节省存储空间，有效降低IO Prometheus有着非常高效的时间序列数据存储方法，每个采样数据仅仅占用3.5byte左右空间，上百万条时间序列，30秒间隔，保留60天，大概花了200多G（来自官方数据) 3、Prometheus的主要特征 多维度数据模型 灵活的查询语言 不依赖分布式存储，单个服务器节点是自主的 以HTTP方式，通过pull模型拉去时间序列数据 也可以通过中间网关支持push模型 通过服务发现或者静态配置，来发现目标服务对象 支持多种多样的图表和界面展示 4、Prometheus基本原理Prometheus [prəˈmi:θi:əs, -ˌθju:s] 的基本原理是使用 Pull （抓取）的方式，通过HTTP协议周期性抓取被监控组件的Metrics 数据（监控指标数据），然后，再把这些数据保存在一个 TSDB （时间序列数据库，比如 OpenTSDB、InfluxDB 等）当中，任意组件只要提供对应的HTTP接口就可以接入监控。不需要任何SDK或者其他的集成过程。这样做非常适合做虚拟化环境监控系统，比如VM、Docker、Kubernetes等。 5、架构图6、组件说明 Prometheus Server：主要用于抓取数据和存储时序数据，在该组件上配置监控数据的采集和告警规则. Push Gateway: 主要用于短期的 jobs。由于这类 jobs 存在时间较短, 可能在 Prometheus 来 pull 之前就消失了。为此, 这类jobs 可以直接向 Prometheus server 端推送它们的 metrics. 这种方式主要用于服务层面的 metrics, 对于机器层面的 metrics, 需要使用 node exporter. Exporter: 是 Prometheus的一类数据采集组件的总称，用于暴露已有的第三方服务的 metrics 给Prometheus。 它负责从目标处搜集数据, 并将其转化为Prometheus支持的格式. 与传统的数据采集组件不同的是, 它并不向中央服务器发送数据, 而是等待中央服务器主动前来抓取. AlertManager: 用于接收promethues发出的告警做进一步处理，对告警进行聚合、下发、抑制等。常见的告警方式有：邮件，钉钉，webhook 等一些其他的工具。 Grafana: 第三方数据图表展示工具 Service Discovery: 动态发现待监控的Target，从而完成监控配置的重要组件，在容器化环境中尤为有用；该组件目前由Prometheus Server 内建支持。 每个组件都是独立工作的，不依赖其他组件。不同模块组件之间通过配置文件关联到一起，实现整个监控的功能。每个独立的模块都可以扩展，做高可用方案。 ","date":"2022-01-05","objectID":"/prometheus/:1:1","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#一prometheus概述"},{"categories":[],"content":"一、Prometheus概述1、什么是Prometheus？Prometheus [prəˈmi:θi:əs, -ˌθju:s] 是由SoundCloud使用Go语言开发的开源监控报警系统和时间序列数据库(TSDB)。Prometheus于 2016 年加入 云原生计算基金会（CNCF），作为继Kubernetes之后的第二个托管项目，因为kubernetes的流行带动了prometheus的发展。 2、时间序列数据什么是时间序列数据？ 时间序列数据(TimeSeries Data):按照时间顺序记录系统、设备状态变化的数据被称为时序数据。 应用的场景很多, 如： 无人驾驶车辆运行中要记录的经度，纬度，速度，方向，旁边物体的距离等等。每时每刻都要将数据记录下来做分析。 某一个地区的各车辆的行驶轨迹数据 传统证券行业实时交易数据 实时运维监控数据，CPU、内存等实时数据 时间序列数据特点： 性能好 关系型数据库对于大规模数据的处理性能糟糕。NOSQL可以比较好的处理大规模数据，让依然比不上时间序列数据库。 存储成本低 高效的压缩算法，节省存储空间，有效降低IO Prometheus有着非常高效的时间序列数据存储方法，每个采样数据仅仅占用3.5byte左右空间，上百万条时间序列，30秒间隔，保留60天，大概花了200多G（来自官方数据) 3、Prometheus的主要特征 多维度数据模型 灵活的查询语言 不依赖分布式存储，单个服务器节点是自主的 以HTTP方式，通过pull模型拉去时间序列数据 也可以通过中间网关支持push模型 通过服务发现或者静态配置，来发现目标服务对象 支持多种多样的图表和界面展示 4、Prometheus基本原理Prometheus [prəˈmi:θi:əs, -ˌθju:s] 的基本原理是使用 Pull （抓取）的方式，通过HTTP协议周期性抓取被监控组件的Metrics 数据（监控指标数据），然后，再把这些数据保存在一个 TSDB （时间序列数据库，比如 OpenTSDB、InfluxDB 等）当中，任意组件只要提供对应的HTTP接口就可以接入监控。不需要任何SDK或者其他的集成过程。这样做非常适合做虚拟化环境监控系统，比如VM、Docker、Kubernetes等。 5、架构图6、组件说明 Prometheus Server：主要用于抓取数据和存储时序数据，在该组件上配置监控数据的采集和告警规则. Push Gateway: 主要用于短期的 jobs。由于这类 jobs 存在时间较短, 可能在 Prometheus 来 pull 之前就消失了。为此, 这类jobs 可以直接向 Prometheus server 端推送它们的 metrics. 这种方式主要用于服务层面的 metrics, 对于机器层面的 metrics, 需要使用 node exporter. Exporter: 是 Prometheus的一类数据采集组件的总称，用于暴露已有的第三方服务的 metrics 给Prometheus。 它负责从目标处搜集数据, 并将其转化为Prometheus支持的格式. 与传统的数据采集组件不同的是, 它并不向中央服务器发送数据, 而是等待中央服务器主动前来抓取. AlertManager: 用于接收promethues发出的告警做进一步处理，对告警进行聚合、下发、抑制等。常见的告警方式有：邮件，钉钉，webhook 等一些其他的工具。 Grafana: 第三方数据图表展示工具 Service Discovery: 动态发现待监控的Target，从而完成监控配置的重要组件，在容器化环境中尤为有用；该组件目前由Prometheus Server 内建支持。 每个组件都是独立工作的，不依赖其他组件。不同模块组件之间通过配置文件关联到一起，实现整个监控的功能。每个独立的模块都可以扩展，做高可用方案。 ","date":"2022-01-05","objectID":"/prometheus/:1:1","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#1什么是prometheus"},{"categories":[],"content":"一、Prometheus概述1、什么是Prometheus？Prometheus [prəˈmi:θi:əs, -ˌθju:s] 是由SoundCloud使用Go语言开发的开源监控报警系统和时间序列数据库(TSDB)。Prometheus于 2016 年加入 云原生计算基金会（CNCF），作为继Kubernetes之后的第二个托管项目，因为kubernetes的流行带动了prometheus的发展。 2、时间序列数据什么是时间序列数据？ 时间序列数据(TimeSeries Data):按照时间顺序记录系统、设备状态变化的数据被称为时序数据。 应用的场景很多, 如： 无人驾驶车辆运行中要记录的经度，纬度，速度，方向，旁边物体的距离等等。每时每刻都要将数据记录下来做分析。 某一个地区的各车辆的行驶轨迹数据 传统证券行业实时交易数据 实时运维监控数据，CPU、内存等实时数据 时间序列数据特点： 性能好 关系型数据库对于大规模数据的处理性能糟糕。NOSQL可以比较好的处理大规模数据，让依然比不上时间序列数据库。 存储成本低 高效的压缩算法，节省存储空间，有效降低IO Prometheus有着非常高效的时间序列数据存储方法，每个采样数据仅仅占用3.5byte左右空间，上百万条时间序列，30秒间隔，保留60天，大概花了200多G（来自官方数据) 3、Prometheus的主要特征 多维度数据模型 灵活的查询语言 不依赖分布式存储，单个服务器节点是自主的 以HTTP方式，通过pull模型拉去时间序列数据 也可以通过中间网关支持push模型 通过服务发现或者静态配置，来发现目标服务对象 支持多种多样的图表和界面展示 4、Prometheus基本原理Prometheus [prəˈmi:θi:əs, -ˌθju:s] 的基本原理是使用 Pull （抓取）的方式，通过HTTP协议周期性抓取被监控组件的Metrics 数据（监控指标数据），然后，再把这些数据保存在一个 TSDB （时间序列数据库，比如 OpenTSDB、InfluxDB 等）当中，任意组件只要提供对应的HTTP接口就可以接入监控。不需要任何SDK或者其他的集成过程。这样做非常适合做虚拟化环境监控系统，比如VM、Docker、Kubernetes等。 5、架构图6、组件说明 Prometheus Server：主要用于抓取数据和存储时序数据，在该组件上配置监控数据的采集和告警规则. Push Gateway: 主要用于短期的 jobs。由于这类 jobs 存在时间较短, 可能在 Prometheus 来 pull 之前就消失了。为此, 这类jobs 可以直接向 Prometheus server 端推送它们的 metrics. 这种方式主要用于服务层面的 metrics, 对于机器层面的 metrics, 需要使用 node exporter. Exporter: 是 Prometheus的一类数据采集组件的总称，用于暴露已有的第三方服务的 metrics 给Prometheus。 它负责从目标处搜集数据, 并将其转化为Prometheus支持的格式. 与传统的数据采集组件不同的是, 它并不向中央服务器发送数据, 而是等待中央服务器主动前来抓取. AlertManager: 用于接收promethues发出的告警做进一步处理，对告警进行聚合、下发、抑制等。常见的告警方式有：邮件，钉钉，webhook 等一些其他的工具。 Grafana: 第三方数据图表展示工具 Service Discovery: 动态发现待监控的Target，从而完成监控配置的重要组件，在容器化环境中尤为有用；该组件目前由Prometheus Server 内建支持。 每个组件都是独立工作的，不依赖其他组件。不同模块组件之间通过配置文件关联到一起，实现整个监控的功能。每个独立的模块都可以扩展，做高可用方案。 ","date":"2022-01-05","objectID":"/prometheus/:1:1","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#2时间序列数据"},{"categories":[],"content":"一、Prometheus概述1、什么是Prometheus？Prometheus [prəˈmi:θi:əs, -ˌθju:s] 是由SoundCloud使用Go语言开发的开源监控报警系统和时间序列数据库(TSDB)。Prometheus于 2016 年加入 云原生计算基金会（CNCF），作为继Kubernetes之后的第二个托管项目，因为kubernetes的流行带动了prometheus的发展。 2、时间序列数据什么是时间序列数据？ 时间序列数据(TimeSeries Data):按照时间顺序记录系统、设备状态变化的数据被称为时序数据。 应用的场景很多, 如： 无人驾驶车辆运行中要记录的经度，纬度，速度，方向，旁边物体的距离等等。每时每刻都要将数据记录下来做分析。 某一个地区的各车辆的行驶轨迹数据 传统证券行业实时交易数据 实时运维监控数据，CPU、内存等实时数据 时间序列数据特点： 性能好 关系型数据库对于大规模数据的处理性能糟糕。NOSQL可以比较好的处理大规模数据，让依然比不上时间序列数据库。 存储成本低 高效的压缩算法，节省存储空间，有效降低IO Prometheus有着非常高效的时间序列数据存储方法，每个采样数据仅仅占用3.5byte左右空间，上百万条时间序列，30秒间隔，保留60天，大概花了200多G（来自官方数据) 3、Prometheus的主要特征 多维度数据模型 灵活的查询语言 不依赖分布式存储，单个服务器节点是自主的 以HTTP方式，通过pull模型拉去时间序列数据 也可以通过中间网关支持push模型 通过服务发现或者静态配置，来发现目标服务对象 支持多种多样的图表和界面展示 4、Prometheus基本原理Prometheus [prəˈmi:θi:əs, -ˌθju:s] 的基本原理是使用 Pull （抓取）的方式，通过HTTP协议周期性抓取被监控组件的Metrics 数据（监控指标数据），然后，再把这些数据保存在一个 TSDB （时间序列数据库，比如 OpenTSDB、InfluxDB 等）当中，任意组件只要提供对应的HTTP接口就可以接入监控。不需要任何SDK或者其他的集成过程。这样做非常适合做虚拟化环境监控系统，比如VM、Docker、Kubernetes等。 5、架构图6、组件说明 Prometheus Server：主要用于抓取数据和存储时序数据，在该组件上配置监控数据的采集和告警规则. Push Gateway: 主要用于短期的 jobs。由于这类 jobs 存在时间较短, 可能在 Prometheus 来 pull 之前就消失了。为此, 这类jobs 可以直接向 Prometheus server 端推送它们的 metrics. 这种方式主要用于服务层面的 metrics, 对于机器层面的 metrics, 需要使用 node exporter. Exporter: 是 Prometheus的一类数据采集组件的总称，用于暴露已有的第三方服务的 metrics 给Prometheus。 它负责从目标处搜集数据, 并将其转化为Prometheus支持的格式. 与传统的数据采集组件不同的是, 它并不向中央服务器发送数据, 而是等待中央服务器主动前来抓取. AlertManager: 用于接收promethues发出的告警做进一步处理，对告警进行聚合、下发、抑制等。常见的告警方式有：邮件，钉钉，webhook 等一些其他的工具。 Grafana: 第三方数据图表展示工具 Service Discovery: 动态发现待监控的Target，从而完成监控配置的重要组件，在容器化环境中尤为有用；该组件目前由Prometheus Server 内建支持。 每个组件都是独立工作的，不依赖其他组件。不同模块组件之间通过配置文件关联到一起，实现整个监控的功能。每个独立的模块都可以扩展，做高可用方案。 ","date":"2022-01-05","objectID":"/prometheus/:1:1","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#3prometheus的主要特征"},{"categories":[],"content":"一、Prometheus概述1、什么是Prometheus？Prometheus [prəˈmi:θi:əs, -ˌθju:s] 是由SoundCloud使用Go语言开发的开源监控报警系统和时间序列数据库(TSDB)。Prometheus于 2016 年加入 云原生计算基金会（CNCF），作为继Kubernetes之后的第二个托管项目，因为kubernetes的流行带动了prometheus的发展。 2、时间序列数据什么是时间序列数据？ 时间序列数据(TimeSeries Data):按照时间顺序记录系统、设备状态变化的数据被称为时序数据。 应用的场景很多, 如： 无人驾驶车辆运行中要记录的经度，纬度，速度，方向，旁边物体的距离等等。每时每刻都要将数据记录下来做分析。 某一个地区的各车辆的行驶轨迹数据 传统证券行业实时交易数据 实时运维监控数据，CPU、内存等实时数据 时间序列数据特点： 性能好 关系型数据库对于大规模数据的处理性能糟糕。NOSQL可以比较好的处理大规模数据，让依然比不上时间序列数据库。 存储成本低 高效的压缩算法，节省存储空间，有效降低IO Prometheus有着非常高效的时间序列数据存储方法，每个采样数据仅仅占用3.5byte左右空间，上百万条时间序列，30秒间隔，保留60天，大概花了200多G（来自官方数据) 3、Prometheus的主要特征 多维度数据模型 灵活的查询语言 不依赖分布式存储，单个服务器节点是自主的 以HTTP方式，通过pull模型拉去时间序列数据 也可以通过中间网关支持push模型 通过服务发现或者静态配置，来发现目标服务对象 支持多种多样的图表和界面展示 4、Prometheus基本原理Prometheus [prəˈmi:θi:əs, -ˌθju:s] 的基本原理是使用 Pull （抓取）的方式，通过HTTP协议周期性抓取被监控组件的Metrics 数据（监控指标数据），然后，再把这些数据保存在一个 TSDB （时间序列数据库，比如 OpenTSDB、InfluxDB 等）当中，任意组件只要提供对应的HTTP接口就可以接入监控。不需要任何SDK或者其他的集成过程。这样做非常适合做虚拟化环境监控系统，比如VM、Docker、Kubernetes等。 5、架构图6、组件说明 Prometheus Server：主要用于抓取数据和存储时序数据，在该组件上配置监控数据的采集和告警规则. Push Gateway: 主要用于短期的 jobs。由于这类 jobs 存在时间较短, 可能在 Prometheus 来 pull 之前就消失了。为此, 这类jobs 可以直接向 Prometheus server 端推送它们的 metrics. 这种方式主要用于服务层面的 metrics, 对于机器层面的 metrics, 需要使用 node exporter. Exporter: 是 Prometheus的一类数据采集组件的总称，用于暴露已有的第三方服务的 metrics 给Prometheus。 它负责从目标处搜集数据, 并将其转化为Prometheus支持的格式. 与传统的数据采集组件不同的是, 它并不向中央服务器发送数据, 而是等待中央服务器主动前来抓取. AlertManager: 用于接收promethues发出的告警做进一步处理，对告警进行聚合、下发、抑制等。常见的告警方式有：邮件，钉钉，webhook 等一些其他的工具。 Grafana: 第三方数据图表展示工具 Service Discovery: 动态发现待监控的Target，从而完成监控配置的重要组件，在容器化环境中尤为有用；该组件目前由Prometheus Server 内建支持。 每个组件都是独立工作的，不依赖其他组件。不同模块组件之间通过配置文件关联到一起，实现整个监控的功能。每个独立的模块都可以扩展，做高可用方案。 ","date":"2022-01-05","objectID":"/prometheus/:1:1","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#4prometheus基本原理"},{"categories":[],"content":"一、Prometheus概述1、什么是Prometheus？Prometheus [prəˈmi:θi:əs, -ˌθju:s] 是由SoundCloud使用Go语言开发的开源监控报警系统和时间序列数据库(TSDB)。Prometheus于 2016 年加入 云原生计算基金会（CNCF），作为继Kubernetes之后的第二个托管项目，因为kubernetes的流行带动了prometheus的发展。 2、时间序列数据什么是时间序列数据？ 时间序列数据(TimeSeries Data):按照时间顺序记录系统、设备状态变化的数据被称为时序数据。 应用的场景很多, 如： 无人驾驶车辆运行中要记录的经度，纬度，速度，方向，旁边物体的距离等等。每时每刻都要将数据记录下来做分析。 某一个地区的各车辆的行驶轨迹数据 传统证券行业实时交易数据 实时运维监控数据，CPU、内存等实时数据 时间序列数据特点： 性能好 关系型数据库对于大规模数据的处理性能糟糕。NOSQL可以比较好的处理大规模数据，让依然比不上时间序列数据库。 存储成本低 高效的压缩算法，节省存储空间，有效降低IO Prometheus有着非常高效的时间序列数据存储方法，每个采样数据仅仅占用3.5byte左右空间，上百万条时间序列，30秒间隔，保留60天，大概花了200多G（来自官方数据) 3、Prometheus的主要特征 多维度数据模型 灵活的查询语言 不依赖分布式存储，单个服务器节点是自主的 以HTTP方式，通过pull模型拉去时间序列数据 也可以通过中间网关支持push模型 通过服务发现或者静态配置，来发现目标服务对象 支持多种多样的图表和界面展示 4、Prometheus基本原理Prometheus [prəˈmi:θi:əs, -ˌθju:s] 的基本原理是使用 Pull （抓取）的方式，通过HTTP协议周期性抓取被监控组件的Metrics 数据（监控指标数据），然后，再把这些数据保存在一个 TSDB （时间序列数据库，比如 OpenTSDB、InfluxDB 等）当中，任意组件只要提供对应的HTTP接口就可以接入监控。不需要任何SDK或者其他的集成过程。这样做非常适合做虚拟化环境监控系统，比如VM、Docker、Kubernetes等。 5、架构图6、组件说明 Prometheus Server：主要用于抓取数据和存储时序数据，在该组件上配置监控数据的采集和告警规则. Push Gateway: 主要用于短期的 jobs。由于这类 jobs 存在时间较短, 可能在 Prometheus 来 pull 之前就消失了。为此, 这类jobs 可以直接向 Prometheus server 端推送它们的 metrics. 这种方式主要用于服务层面的 metrics, 对于机器层面的 metrics, 需要使用 node exporter. Exporter: 是 Prometheus的一类数据采集组件的总称，用于暴露已有的第三方服务的 metrics 给Prometheus。 它负责从目标处搜集数据, 并将其转化为Prometheus支持的格式. 与传统的数据采集组件不同的是, 它并不向中央服务器发送数据, 而是等待中央服务器主动前来抓取. AlertManager: 用于接收promethues发出的告警做进一步处理，对告警进行聚合、下发、抑制等。常见的告警方式有：邮件，钉钉，webhook 等一些其他的工具。 Grafana: 第三方数据图表展示工具 Service Discovery: 动态发现待监控的Target，从而完成监控配置的重要组件，在容器化环境中尤为有用；该组件目前由Prometheus Server 内建支持。 每个组件都是独立工作的，不依赖其他组件。不同模块组件之间通过配置文件关联到一起，实现整个监控的功能。每个独立的模块都可以扩展，做高可用方案。 ","date":"2022-01-05","objectID":"/prometheus/:1:1","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#5架构图"},{"categories":[],"content":"一、Prometheus概述1、什么是Prometheus？Prometheus [prəˈmi:θi:əs, -ˌθju:s] 是由SoundCloud使用Go语言开发的开源监控报警系统和时间序列数据库(TSDB)。Prometheus于 2016 年加入 云原生计算基金会（CNCF），作为继Kubernetes之后的第二个托管项目，因为kubernetes的流行带动了prometheus的发展。 2、时间序列数据什么是时间序列数据？ 时间序列数据(TimeSeries Data):按照时间顺序记录系统、设备状态变化的数据被称为时序数据。 应用的场景很多, 如： 无人驾驶车辆运行中要记录的经度，纬度，速度，方向，旁边物体的距离等等。每时每刻都要将数据记录下来做分析。 某一个地区的各车辆的行驶轨迹数据 传统证券行业实时交易数据 实时运维监控数据，CPU、内存等实时数据 时间序列数据特点： 性能好 关系型数据库对于大规模数据的处理性能糟糕。NOSQL可以比较好的处理大规模数据，让依然比不上时间序列数据库。 存储成本低 高效的压缩算法，节省存储空间，有效降低IO Prometheus有着非常高效的时间序列数据存储方法，每个采样数据仅仅占用3.5byte左右空间，上百万条时间序列，30秒间隔，保留60天，大概花了200多G（来自官方数据) 3、Prometheus的主要特征 多维度数据模型 灵活的查询语言 不依赖分布式存储，单个服务器节点是自主的 以HTTP方式，通过pull模型拉去时间序列数据 也可以通过中间网关支持push模型 通过服务发现或者静态配置，来发现目标服务对象 支持多种多样的图表和界面展示 4、Prometheus基本原理Prometheus [prəˈmi:θi:əs, -ˌθju:s] 的基本原理是使用 Pull （抓取）的方式，通过HTTP协议周期性抓取被监控组件的Metrics 数据（监控指标数据），然后，再把这些数据保存在一个 TSDB （时间序列数据库，比如 OpenTSDB、InfluxDB 等）当中，任意组件只要提供对应的HTTP接口就可以接入监控。不需要任何SDK或者其他的集成过程。这样做非常适合做虚拟化环境监控系统，比如VM、Docker、Kubernetes等。 5、架构图6、组件说明 Prometheus Server：主要用于抓取数据和存储时序数据，在该组件上配置监控数据的采集和告警规则. Push Gateway: 主要用于短期的 jobs。由于这类 jobs 存在时间较短, 可能在 Prometheus 来 pull 之前就消失了。为此, 这类jobs 可以直接向 Prometheus server 端推送它们的 metrics. 这种方式主要用于服务层面的 metrics, 对于机器层面的 metrics, 需要使用 node exporter. Exporter: 是 Prometheus的一类数据采集组件的总称，用于暴露已有的第三方服务的 metrics 给Prometheus。 它负责从目标处搜集数据, 并将其转化为Prometheus支持的格式. 与传统的数据采集组件不同的是, 它并不向中央服务器发送数据, 而是等待中央服务器主动前来抓取. AlertManager: 用于接收promethues发出的告警做进一步处理，对告警进行聚合、下发、抑制等。常见的告警方式有：邮件，钉钉，webhook 等一些其他的工具。 Grafana: 第三方数据图表展示工具 Service Discovery: 动态发现待监控的Target，从而完成监控配置的重要组件，在容器化环境中尤为有用；该组件目前由Prometheus Server 内建支持。 每个组件都是独立工作的，不依赖其他组件。不同模块组件之间通过配置文件关联到一起，实现整个监控的功能。每个独立的模块都可以扩展，做高可用方案。 ","date":"2022-01-05","objectID":"/prometheus/:1:1","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#6组件说明"},{"categories":[],"content":"二、Prometheus 部署与配置1、安装prometheus从 https://prometheus.io/download/ 下载相应版本，安装到服务器上官网提供的是二进制版，解压就能用，不需要编译 $ tar xf prometheus-2.5.0.linuxamd64.tar.gz -C /usr/local/ $ mv /usr/local/prometheus-2.5.0.linuxamd64/ /usr/local/prometheus # 直接使用默认配置文件启动 $ /usr/local/prometheus/prometheus --config.file=\"/usr/local/prometheus/prometheus.yml\" --web.enable-lifecycle \u0026 # 启动时加上--web.enable-lifecycle启用远程热加载配置文件 # 调用指令是curl -X POST http://localhost:9090/-/reload # 确认端口(9090) $ lsof -i:9090 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME prometheu 85396 root 8u IPv6 2258519 0t0 TCP *:websm (LISTEN) 2、prometheus界面通过浏览器访问http://服务器IP:9090就可以访问到prometheus的主界面，点击Status –\u003e点Targets –\u003e可以看到只监控了prometheus server本机 访问http://10.101.1.51:9090/metrics可以查看到prometheus提供的自身 相关的metrics（指标）数据 # HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 3.6816e-05 go_gc_duration_seconds{quantile=\"0.25\"} 5.924e-05 go_gc_duration_seconds{quantile=\"0.5\"} 9.4932e-05 go_gc_duration_seconds{quantile=\"0.75\"} 0.000144405 go_gc_duration_seconds{quantile=\"1\"} 0.001375254 go_gc_duration_seconds_sum 0.036465283 go_gc_duration_seconds_count 270 # HELP go_goroutines Number of goroutines that currently exist. # TYPE go_goroutines gauge go_goroutines 31 ... ... 在主界面可以通过关键字查询监控项 3、 监控远程主机 在远程linux主机(被监控端agent1)上安装node_exporter组件，下载地址: https://prometheus.io/download/ $ tar xf node_exporter-0.16.0.linuxamd64.tar.gz -C /usr/local/ $ mv /usr/local/node_exporter-0.16.0.linuxamd64/ /usr/local/node_exporter # 里面就一个启动命令node_exporter,可以直接使用此命令启动 $ ls /usr/local/node_exporter/ LICENSE node_exporter NOTICE $ nohup /usr/local/node_exporter/node_exporter \u0026 # 确认端口(9100) $ lsof -i:9100 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME node_expo 83747 root 3u IPv6 2272614 0t0 TCP *:jetdirect (LISTEN) 通过浏览器访问http://被监控端ip:9100/metrics 就可以查看到node-exporter在被监控端收集到的信息 # HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 7.0401e-05 go_gc_duration_seconds{quantile=\"0.25\"} 7.0401e-05 go_gc_duration_seconds{quantile=\"0.5\"} 0.001011446 go_gc_duration_seconds{quantile=\"0.75\"} 0.001011446 go_gc_duration_seconds{quantile=\"1\"} 0.001011446 go_gc_duration_seconds_sum 0.001081847 go_gc_duration_seconds_count 2 # HELP go_goroutines Number of goroutines that currently exist. # TYPE go_goroutines gauge go_goroutines 8 # HELP go_info Information about the Go environment. # TYPE go_info gauge go_info{version=\"go1.16.7\"} 1 # HELP go_memstats_alloc_bytes Number of bytes allocated and still in use. # TYPE go_memstats_alloc_bytes gauge 回到prometheus服务器的配置文件里添加被监控机器的配置段 # 在yml文件的最后添加被监控器的配置段 $ vim /usr/local/prometheus.yml - job_name: \"node-exporter\" # 添加新的监控项 static_configs: - targets: [\"10.101.1.53:9100\"] # 修改完成后重新加载配置文件 $ curl -X POST http://localhost:9090/-/reload level=info ts=2021-10-15T08:41:40.889Z caller=main.go:1016 msg=\"Completed loading of configuration file\" filename=/usr/local/prometheus/prometheus.yml 回到web界面查看targets，可以看到多了一台监控目标 4、监控远程MySQL 在被管理机agent1上安装mysqld_exporter组件，下载地址: https://prometheus.io/download/。操作和监控远程主机类似 # 安装mysqld_exporter组件 [root@agent1 ~]# tar xf mysqld_exporter-0.11.0.linuxamd64. tar.gz -C /usr/local/ [root@agent1 ~]# mv /usr/local/mysqld_exporter-0.11.0.linux-amd64/ /usr/local/mysqld_exporter [root@agent1 ~]# ls /usr/local/mysqld_exporter/ LICENSE mysqld_exporter NOTICE # 安装mariadb数据库,并授权 [root@agent1 ~]# yum install mariadb\\* -y [root@agent1 ~]# systemctl restart mariadb [root@agent1 ~]# systemctl enable mariadb [root@agent1 ~]# mysql MariaDB [(none)]\u003e grant select,replication client,process ON *.* to 'mysql_monitor'@'localhost' identified by '123'; (注意:授权ip为localhost，因为不是prometheus服务器来直接找mariadb获取数据，而是prometheus服务器找mysql_exporter,mysql_exporter再找mariadb。所以这个localhost是指的mysql_exporter的IP) MariaDB [(none)]\u003e flush privileges; # 查询权限授予的表 MariaDB [(none)]\u003e select * fr","date":"2022-01-05","objectID":"/prometheus/:1:2","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#二prometheus-部署与配置"},{"categories":[],"content":"二、Prometheus 部署与配置1、安装prometheus从 https://prometheus.io/download/ 下载相应版本，安装到服务器上官网提供的是二进制版，解压就能用，不需要编译 $ tar xf prometheus-2.5.0.linuxamd64.tar.gz -C /usr/local/ $ mv /usr/local/prometheus-2.5.0.linuxamd64/ /usr/local/prometheus # 直接使用默认配置文件启动 $ /usr/local/prometheus/prometheus --config.file=\"/usr/local/prometheus/prometheus.yml\" --web.enable-lifecycle \u0026 # 启动时加上--web.enable-lifecycle启用远程热加载配置文件 # 调用指令是curl -X POST http://localhost:9090/-/reload # 确认端口(9090) $ lsof -i:9090 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME prometheu 85396 root 8u IPv6 2258519 0t0 TCP *:websm (LISTEN) 2、prometheus界面通过浏览器访问http://服务器IP:9090就可以访问到prometheus的主界面，点击Status –点Targets –可以看到只监控了prometheus server本机 访问http://10.101.1.51:9090/metrics可以查看到prometheus提供的自身 相关的metrics（指标）数据 # HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 3.6816e-05 go_gc_duration_seconds{quantile=\"0.25\"} 5.924e-05 go_gc_duration_seconds{quantile=\"0.5\"} 9.4932e-05 go_gc_duration_seconds{quantile=\"0.75\"} 0.000144405 go_gc_duration_seconds{quantile=\"1\"} 0.001375254 go_gc_duration_seconds_sum 0.036465283 go_gc_duration_seconds_count 270 # HELP go_goroutines Number of goroutines that currently exist. # TYPE go_goroutines gauge go_goroutines 31 ... ... 在主界面可以通过关键字查询监控项 3、 监控远程主机 在远程linux主机(被监控端agent1)上安装node_exporter组件，下载地址: https://prometheus.io/download/ $ tar xf node_exporter-0.16.0.linuxamd64.tar.gz -C /usr/local/ $ mv /usr/local/node_exporter-0.16.0.linuxamd64/ /usr/local/node_exporter # 里面就一个启动命令node_exporter,可以直接使用此命令启动 $ ls /usr/local/node_exporter/ LICENSE node_exporter NOTICE $ nohup /usr/local/node_exporter/node_exporter \u0026 # 确认端口(9100) $ lsof -i:9100 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME node_expo 83747 root 3u IPv6 2272614 0t0 TCP *:jetdirect (LISTEN) 通过浏览器访问http://被监控端ip:9100/metrics 就可以查看到node-exporter在被监控端收集到的信息 # HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 7.0401e-05 go_gc_duration_seconds{quantile=\"0.25\"} 7.0401e-05 go_gc_duration_seconds{quantile=\"0.5\"} 0.001011446 go_gc_duration_seconds{quantile=\"0.75\"} 0.001011446 go_gc_duration_seconds{quantile=\"1\"} 0.001011446 go_gc_duration_seconds_sum 0.001081847 go_gc_duration_seconds_count 2 # HELP go_goroutines Number of goroutines that currently exist. # TYPE go_goroutines gauge go_goroutines 8 # HELP go_info Information about the Go environment. # TYPE go_info gauge go_info{version=\"go1.16.7\"} 1 # HELP go_memstats_alloc_bytes Number of bytes allocated and still in use. # TYPE go_memstats_alloc_bytes gauge 回到prometheus服务器的配置文件里添加被监控机器的配置段 # 在yml文件的最后添加被监控器的配置段 $ vim /usr/local/prometheus.yml - job_name: \"node-exporter\" # 添加新的监控项 static_configs: - targets: [\"10.101.1.53:9100\"] # 修改完成后重新加载配置文件 $ curl -X POST http://localhost:9090/-/reload level=info ts=2021-10-15T08:41:40.889Z caller=main.go:1016 msg=\"Completed loading of configuration file\" filename=/usr/local/prometheus/prometheus.yml 回到web界面查看targets，可以看到多了一台监控目标 4、监控远程MySQL 在被管理机agent1上安装mysqld_exporter组件，下载地址: https://prometheus.io/download/。操作和监控远程主机类似 # 安装mysqld_exporter组件 [root@agent1 ~]# tar xf mysqld_exporter-0.11.0.linuxamd64. tar.gz -C /usr/local/ [root@agent1 ~]# mv /usr/local/mysqld_exporter-0.11.0.linux-amd64/ /usr/local/mysqld_exporter [root@agent1 ~]# ls /usr/local/mysqld_exporter/ LICENSE mysqld_exporter NOTICE # 安装mariadb数据库,并授权 [root@agent1 ~]# yum install mariadb\\* -y [root@agent1 ~]# systemctl restart mariadb [root@agent1 ~]# systemctl enable mariadb [root@agent1 ~]# mysql MariaDB [(none)] grant select,replication client,process ON *.* to 'mysql_monitor'@'localhost' identified by '123'; (注意:授权ip为localhost，因为不是prometheus服务器来直接找mariadb获取数据，而是prometheus服务器找mysql_exporter,mysql_exporter再找mariadb。所以这个localhost是指的mysql_exporter的IP) MariaDB [(none)] flush privileges; # 查询权限授予的表 MariaDB [(none)] select * fr","date":"2022-01-05","objectID":"/prometheus/:1:2","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#1安装prometheus"},{"categories":[],"content":"二、Prometheus 部署与配置1、安装prometheus从 https://prometheus.io/download/ 下载相应版本，安装到服务器上官网提供的是二进制版，解压就能用，不需要编译 $ tar xf prometheus-2.5.0.linuxamd64.tar.gz -C /usr/local/ $ mv /usr/local/prometheus-2.5.0.linuxamd64/ /usr/local/prometheus # 直接使用默认配置文件启动 $ /usr/local/prometheus/prometheus --config.file=\"/usr/local/prometheus/prometheus.yml\" --web.enable-lifecycle \u0026 # 启动时加上--web.enable-lifecycle启用远程热加载配置文件 # 调用指令是curl -X POST http://localhost:9090/-/reload # 确认端口(9090) $ lsof -i:9090 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME prometheu 85396 root 8u IPv6 2258519 0t0 TCP *:websm (LISTEN) 2、prometheus界面通过浏览器访问http://服务器IP:9090就可以访问到prometheus的主界面，点击Status –点Targets –可以看到只监控了prometheus server本机 访问http://10.101.1.51:9090/metrics可以查看到prometheus提供的自身 相关的metrics（指标）数据 # HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 3.6816e-05 go_gc_duration_seconds{quantile=\"0.25\"} 5.924e-05 go_gc_duration_seconds{quantile=\"0.5\"} 9.4932e-05 go_gc_duration_seconds{quantile=\"0.75\"} 0.000144405 go_gc_duration_seconds{quantile=\"1\"} 0.001375254 go_gc_duration_seconds_sum 0.036465283 go_gc_duration_seconds_count 270 # HELP go_goroutines Number of goroutines that currently exist. # TYPE go_goroutines gauge go_goroutines 31 ... ... 在主界面可以通过关键字查询监控项 3、 监控远程主机 在远程linux主机(被监控端agent1)上安装node_exporter组件，下载地址: https://prometheus.io/download/ $ tar xf node_exporter-0.16.0.linuxamd64.tar.gz -C /usr/local/ $ mv /usr/local/node_exporter-0.16.0.linuxamd64/ /usr/local/node_exporter # 里面就一个启动命令node_exporter,可以直接使用此命令启动 $ ls /usr/local/node_exporter/ LICENSE node_exporter NOTICE $ nohup /usr/local/node_exporter/node_exporter \u0026 # 确认端口(9100) $ lsof -i:9100 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME node_expo 83747 root 3u IPv6 2272614 0t0 TCP *:jetdirect (LISTEN) 通过浏览器访问http://被监控端ip:9100/metrics 就可以查看到node-exporter在被监控端收集到的信息 # HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 7.0401e-05 go_gc_duration_seconds{quantile=\"0.25\"} 7.0401e-05 go_gc_duration_seconds{quantile=\"0.5\"} 0.001011446 go_gc_duration_seconds{quantile=\"0.75\"} 0.001011446 go_gc_duration_seconds{quantile=\"1\"} 0.001011446 go_gc_duration_seconds_sum 0.001081847 go_gc_duration_seconds_count 2 # HELP go_goroutines Number of goroutines that currently exist. # TYPE go_goroutines gauge go_goroutines 8 # HELP go_info Information about the Go environment. # TYPE go_info gauge go_info{version=\"go1.16.7\"} 1 # HELP go_memstats_alloc_bytes Number of bytes allocated and still in use. # TYPE go_memstats_alloc_bytes gauge 回到prometheus服务器的配置文件里添加被监控机器的配置段 # 在yml文件的最后添加被监控器的配置段 $ vim /usr/local/prometheus.yml - job_name: \"node-exporter\" # 添加新的监控项 static_configs: - targets: [\"10.101.1.53:9100\"] # 修改完成后重新加载配置文件 $ curl -X POST http://localhost:9090/-/reload level=info ts=2021-10-15T08:41:40.889Z caller=main.go:1016 msg=\"Completed loading of configuration file\" filename=/usr/local/prometheus/prometheus.yml 回到web界面查看targets，可以看到多了一台监控目标 4、监控远程MySQL 在被管理机agent1上安装mysqld_exporter组件，下载地址: https://prometheus.io/download/。操作和监控远程主机类似 # 安装mysqld_exporter组件 [root@agent1 ~]# tar xf mysqld_exporter-0.11.0.linuxamd64. tar.gz -C /usr/local/ [root@agent1 ~]# mv /usr/local/mysqld_exporter-0.11.0.linux-amd64/ /usr/local/mysqld_exporter [root@agent1 ~]# ls /usr/local/mysqld_exporter/ LICENSE mysqld_exporter NOTICE # 安装mariadb数据库,并授权 [root@agent1 ~]# yum install mariadb\\* -y [root@agent1 ~]# systemctl restart mariadb [root@agent1 ~]# systemctl enable mariadb [root@agent1 ~]# mysql MariaDB [(none)] grant select,replication client,process ON *.* to 'mysql_monitor'@'localhost' identified by '123'; (注意:授权ip为localhost，因为不是prometheus服务器来直接找mariadb获取数据，而是prometheus服务器找mysql_exporter,mysql_exporter再找mariadb。所以这个localhost是指的mysql_exporter的IP) MariaDB [(none)] flush privileges; # 查询权限授予的表 MariaDB [(none)] select * fr","date":"2022-01-05","objectID":"/prometheus/:1:2","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#2prometheus界面"},{"categories":[],"content":"二、Prometheus 部署与配置1、安装prometheus从 https://prometheus.io/download/ 下载相应版本，安装到服务器上官网提供的是二进制版，解压就能用，不需要编译 $ tar xf prometheus-2.5.0.linuxamd64.tar.gz -C /usr/local/ $ mv /usr/local/prometheus-2.5.0.linuxamd64/ /usr/local/prometheus # 直接使用默认配置文件启动 $ /usr/local/prometheus/prometheus --config.file=\"/usr/local/prometheus/prometheus.yml\" --web.enable-lifecycle \u0026 # 启动时加上--web.enable-lifecycle启用远程热加载配置文件 # 调用指令是curl -X POST http://localhost:9090/-/reload # 确认端口(9090) $ lsof -i:9090 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME prometheu 85396 root 8u IPv6 2258519 0t0 TCP *:websm (LISTEN) 2、prometheus界面通过浏览器访问http://服务器IP:9090就可以访问到prometheus的主界面，点击Status –点Targets –可以看到只监控了prometheus server本机 访问http://10.101.1.51:9090/metrics可以查看到prometheus提供的自身 相关的metrics（指标）数据 # HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 3.6816e-05 go_gc_duration_seconds{quantile=\"0.25\"} 5.924e-05 go_gc_duration_seconds{quantile=\"0.5\"} 9.4932e-05 go_gc_duration_seconds{quantile=\"0.75\"} 0.000144405 go_gc_duration_seconds{quantile=\"1\"} 0.001375254 go_gc_duration_seconds_sum 0.036465283 go_gc_duration_seconds_count 270 # HELP go_goroutines Number of goroutines that currently exist. # TYPE go_goroutines gauge go_goroutines 31 ... ... 在主界面可以通过关键字查询监控项 3、 监控远程主机 在远程linux主机(被监控端agent1)上安装node_exporter组件，下载地址: https://prometheus.io/download/ $ tar xf node_exporter-0.16.0.linuxamd64.tar.gz -C /usr/local/ $ mv /usr/local/node_exporter-0.16.0.linuxamd64/ /usr/local/node_exporter # 里面就一个启动命令node_exporter,可以直接使用此命令启动 $ ls /usr/local/node_exporter/ LICENSE node_exporter NOTICE $ nohup /usr/local/node_exporter/node_exporter \u0026 # 确认端口(9100) $ lsof -i:9100 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME node_expo 83747 root 3u IPv6 2272614 0t0 TCP *:jetdirect (LISTEN) 通过浏览器访问http://被监控端ip:9100/metrics 就可以查看到node-exporter在被监控端收集到的信息 # HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 7.0401e-05 go_gc_duration_seconds{quantile=\"0.25\"} 7.0401e-05 go_gc_duration_seconds{quantile=\"0.5\"} 0.001011446 go_gc_duration_seconds{quantile=\"0.75\"} 0.001011446 go_gc_duration_seconds{quantile=\"1\"} 0.001011446 go_gc_duration_seconds_sum 0.001081847 go_gc_duration_seconds_count 2 # HELP go_goroutines Number of goroutines that currently exist. # TYPE go_goroutines gauge go_goroutines 8 # HELP go_info Information about the Go environment. # TYPE go_info gauge go_info{version=\"go1.16.7\"} 1 # HELP go_memstats_alloc_bytes Number of bytes allocated and still in use. # TYPE go_memstats_alloc_bytes gauge 回到prometheus服务器的配置文件里添加被监控机器的配置段 # 在yml文件的最后添加被监控器的配置段 $ vim /usr/local/prometheus.yml - job_name: \"node-exporter\" # 添加新的监控项 static_configs: - targets: [\"10.101.1.53:9100\"] # 修改完成后重新加载配置文件 $ curl -X POST http://localhost:9090/-/reload level=info ts=2021-10-15T08:41:40.889Z caller=main.go:1016 msg=\"Completed loading of configuration file\" filename=/usr/local/prometheus/prometheus.yml 回到web界面查看targets，可以看到多了一台监控目标 4、监控远程MySQL 在被管理机agent1上安装mysqld_exporter组件，下载地址: https://prometheus.io/download/。操作和监控远程主机类似 # 安装mysqld_exporter组件 [root@agent1 ~]# tar xf mysqld_exporter-0.11.0.linuxamd64. tar.gz -C /usr/local/ [root@agent1 ~]# mv /usr/local/mysqld_exporter-0.11.0.linux-amd64/ /usr/local/mysqld_exporter [root@agent1 ~]# ls /usr/local/mysqld_exporter/ LICENSE mysqld_exporter NOTICE # 安装mariadb数据库,并授权 [root@agent1 ~]# yum install mariadb\\* -y [root@agent1 ~]# systemctl restart mariadb [root@agent1 ~]# systemctl enable mariadb [root@agent1 ~]# mysql MariaDB [(none)] grant select,replication client,process ON *.* to 'mysql_monitor'@'localhost' identified by '123'; (注意:授权ip为localhost，因为不是prometheus服务器来直接找mariadb获取数据，而是prometheus服务器找mysql_exporter,mysql_exporter再找mariadb。所以这个localhost是指的mysql_exporter的IP) MariaDB [(none)] flush privileges; # 查询权限授予的表 MariaDB [(none)] select * fr","date":"2022-01-05","objectID":"/prometheus/:1:2","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#3-监控远程主机"},{"categories":[],"content":"二、Prometheus 部署与配置1、安装prometheus从 https://prometheus.io/download/ 下载相应版本，安装到服务器上官网提供的是二进制版，解压就能用，不需要编译 $ tar xf prometheus-2.5.0.linuxamd64.tar.gz -C /usr/local/ $ mv /usr/local/prometheus-2.5.0.linuxamd64/ /usr/local/prometheus # 直接使用默认配置文件启动 $ /usr/local/prometheus/prometheus --config.file=\"/usr/local/prometheus/prometheus.yml\" --web.enable-lifecycle \u0026 # 启动时加上--web.enable-lifecycle启用远程热加载配置文件 # 调用指令是curl -X POST http://localhost:9090/-/reload # 确认端口(9090) $ lsof -i:9090 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME prometheu 85396 root 8u IPv6 2258519 0t0 TCP *:websm (LISTEN) 2、prometheus界面通过浏览器访问http://服务器IP:9090就可以访问到prometheus的主界面，点击Status –点Targets –可以看到只监控了prometheus server本机 访问http://10.101.1.51:9090/metrics可以查看到prometheus提供的自身 相关的metrics（指标）数据 # HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 3.6816e-05 go_gc_duration_seconds{quantile=\"0.25\"} 5.924e-05 go_gc_duration_seconds{quantile=\"0.5\"} 9.4932e-05 go_gc_duration_seconds{quantile=\"0.75\"} 0.000144405 go_gc_duration_seconds{quantile=\"1\"} 0.001375254 go_gc_duration_seconds_sum 0.036465283 go_gc_duration_seconds_count 270 # HELP go_goroutines Number of goroutines that currently exist. # TYPE go_goroutines gauge go_goroutines 31 ... ... 在主界面可以通过关键字查询监控项 3、 监控远程主机 在远程linux主机(被监控端agent1)上安装node_exporter组件，下载地址: https://prometheus.io/download/ $ tar xf node_exporter-0.16.0.linuxamd64.tar.gz -C /usr/local/ $ mv /usr/local/node_exporter-0.16.0.linuxamd64/ /usr/local/node_exporter # 里面就一个启动命令node_exporter,可以直接使用此命令启动 $ ls /usr/local/node_exporter/ LICENSE node_exporter NOTICE $ nohup /usr/local/node_exporter/node_exporter \u0026 # 确认端口(9100) $ lsof -i:9100 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME node_expo 83747 root 3u IPv6 2272614 0t0 TCP *:jetdirect (LISTEN) 通过浏览器访问http://被监控端ip:9100/metrics 就可以查看到node-exporter在被监控端收集到的信息 # HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 7.0401e-05 go_gc_duration_seconds{quantile=\"0.25\"} 7.0401e-05 go_gc_duration_seconds{quantile=\"0.5\"} 0.001011446 go_gc_duration_seconds{quantile=\"0.75\"} 0.001011446 go_gc_duration_seconds{quantile=\"1\"} 0.001011446 go_gc_duration_seconds_sum 0.001081847 go_gc_duration_seconds_count 2 # HELP go_goroutines Number of goroutines that currently exist. # TYPE go_goroutines gauge go_goroutines 8 # HELP go_info Information about the Go environment. # TYPE go_info gauge go_info{version=\"go1.16.7\"} 1 # HELP go_memstats_alloc_bytes Number of bytes allocated and still in use. # TYPE go_memstats_alloc_bytes gauge 回到prometheus服务器的配置文件里添加被监控机器的配置段 # 在yml文件的最后添加被监控器的配置段 $ vim /usr/local/prometheus.yml - job_name: \"node-exporter\" # 添加新的监控项 static_configs: - targets: [\"10.101.1.53:9100\"] # 修改完成后重新加载配置文件 $ curl -X POST http://localhost:9090/-/reload level=info ts=2021-10-15T08:41:40.889Z caller=main.go:1016 msg=\"Completed loading of configuration file\" filename=/usr/local/prometheus/prometheus.yml 回到web界面查看targets，可以看到多了一台监控目标 4、监控远程MySQL 在被管理机agent1上安装mysqld_exporter组件，下载地址: https://prometheus.io/download/。操作和监控远程主机类似 # 安装mysqld_exporter组件 [root@agent1 ~]# tar xf mysqld_exporter-0.11.0.linuxamd64. tar.gz -C /usr/local/ [root@agent1 ~]# mv /usr/local/mysqld_exporter-0.11.0.linux-amd64/ /usr/local/mysqld_exporter [root@agent1 ~]# ls /usr/local/mysqld_exporter/ LICENSE mysqld_exporter NOTICE # 安装mariadb数据库,并授权 [root@agent1 ~]# yum install mariadb\\* -y [root@agent1 ~]# systemctl restart mariadb [root@agent1 ~]# systemctl enable mariadb [root@agent1 ~]# mysql MariaDB [(none)] grant select,replication client,process ON *.* to 'mysql_monitor'@'localhost' identified by '123'; (注意:授权ip为localhost，因为不是prometheus服务器来直接找mariadb获取数据，而是prometheus服务器找mysql_exporter,mysql_exporter再找mariadb。所以这个localhost是指的mysql_exporter的IP) MariaDB [(none)] flush privileges; # 查询权限授予的表 MariaDB [(none)] select * fr","date":"2022-01-05","objectID":"/prometheus/:1:2","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#4监控远程mysql"},{"categories":[],"content":"二、Prometheus 部署与配置1、安装prometheus从 https://prometheus.io/download/ 下载相应版本，安装到服务器上官网提供的是二进制版，解压就能用，不需要编译 $ tar xf prometheus-2.5.0.linuxamd64.tar.gz -C /usr/local/ $ mv /usr/local/prometheus-2.5.0.linuxamd64/ /usr/local/prometheus # 直接使用默认配置文件启动 $ /usr/local/prometheus/prometheus --config.file=\"/usr/local/prometheus/prometheus.yml\" --web.enable-lifecycle \u0026 # 启动时加上--web.enable-lifecycle启用远程热加载配置文件 # 调用指令是curl -X POST http://localhost:9090/-/reload # 确认端口(9090) $ lsof -i:9090 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME prometheu 85396 root 8u IPv6 2258519 0t0 TCP *:websm (LISTEN) 2、prometheus界面通过浏览器访问http://服务器IP:9090就可以访问到prometheus的主界面，点击Status –点Targets –可以看到只监控了prometheus server本机 访问http://10.101.1.51:9090/metrics可以查看到prometheus提供的自身 相关的metrics（指标）数据 # HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 3.6816e-05 go_gc_duration_seconds{quantile=\"0.25\"} 5.924e-05 go_gc_duration_seconds{quantile=\"0.5\"} 9.4932e-05 go_gc_duration_seconds{quantile=\"0.75\"} 0.000144405 go_gc_duration_seconds{quantile=\"1\"} 0.001375254 go_gc_duration_seconds_sum 0.036465283 go_gc_duration_seconds_count 270 # HELP go_goroutines Number of goroutines that currently exist. # TYPE go_goroutines gauge go_goroutines 31 ... ... 在主界面可以通过关键字查询监控项 3、 监控远程主机 在远程linux主机(被监控端agent1)上安装node_exporter组件，下载地址: https://prometheus.io/download/ $ tar xf node_exporter-0.16.0.linuxamd64.tar.gz -C /usr/local/ $ mv /usr/local/node_exporter-0.16.0.linuxamd64/ /usr/local/node_exporter # 里面就一个启动命令node_exporter,可以直接使用此命令启动 $ ls /usr/local/node_exporter/ LICENSE node_exporter NOTICE $ nohup /usr/local/node_exporter/node_exporter \u0026 # 确认端口(9100) $ lsof -i:9100 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME node_expo 83747 root 3u IPv6 2272614 0t0 TCP *:jetdirect (LISTEN) 通过浏览器访问http://被监控端ip:9100/metrics 就可以查看到node-exporter在被监控端收集到的信息 # HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile=\"0\"} 7.0401e-05 go_gc_duration_seconds{quantile=\"0.25\"} 7.0401e-05 go_gc_duration_seconds{quantile=\"0.5\"} 0.001011446 go_gc_duration_seconds{quantile=\"0.75\"} 0.001011446 go_gc_duration_seconds{quantile=\"1\"} 0.001011446 go_gc_duration_seconds_sum 0.001081847 go_gc_duration_seconds_count 2 # HELP go_goroutines Number of goroutines that currently exist. # TYPE go_goroutines gauge go_goroutines 8 # HELP go_info Information about the Go environment. # TYPE go_info gauge go_info{version=\"go1.16.7\"} 1 # HELP go_memstats_alloc_bytes Number of bytes allocated and still in use. # TYPE go_memstats_alloc_bytes gauge 回到prometheus服务器的配置文件里添加被监控机器的配置段 # 在yml文件的最后添加被监控器的配置段 $ vim /usr/local/prometheus.yml - job_name: \"node-exporter\" # 添加新的监控项 static_configs: - targets: [\"10.101.1.53:9100\"] # 修改完成后重新加载配置文件 $ curl -X POST http://localhost:9090/-/reload level=info ts=2021-10-15T08:41:40.889Z caller=main.go:1016 msg=\"Completed loading of configuration file\" filename=/usr/local/prometheus/prometheus.yml 回到web界面查看targets，可以看到多了一台监控目标 4、监控远程MySQL 在被管理机agent1上安装mysqld_exporter组件，下载地址: https://prometheus.io/download/。操作和监控远程主机类似 # 安装mysqld_exporter组件 [root@agent1 ~]# tar xf mysqld_exporter-0.11.0.linuxamd64. tar.gz -C /usr/local/ [root@agent1 ~]# mv /usr/local/mysqld_exporter-0.11.0.linux-amd64/ /usr/local/mysqld_exporter [root@agent1 ~]# ls /usr/local/mysqld_exporter/ LICENSE mysqld_exporter NOTICE # 安装mariadb数据库,并授权 [root@agent1 ~]# yum install mariadb\\* -y [root@agent1 ~]# systemctl restart mariadb [root@agent1 ~]# systemctl enable mariadb [root@agent1 ~]# mysql MariaDB [(none)] grant select,replication client,process ON *.* to 'mysql_monitor'@'localhost' identified by '123'; (注意:授权ip为localhost，因为不是prometheus服务器来直接找mariadb获取数据，而是prometheus服务器找mysql_exporter,mysql_exporter再找mariadb。所以这个localhost是指的mysql_exporter的IP) MariaDB [(none)] flush privileges; # 查询权限授予的表 MariaDB [(none)] select * fr","date":"2022-01-05","objectID":"/prometheus/:1:2","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#5prometheu配置文件"},{"categories":[],"content":"三、Grafana可视化图形展示工具Grafana是一个开源的度量分析和可视化工具，可以通过将采集的数据分析，查询，然后进行可视化的展示,并能实现报警 安装grafana # 我这里选择的rpm包，下载后直接rpm -ivh安装就OK $ wget https://dl.grafana.com/enterprise/release/grafana-enterprise-8.2.1-1.x86_64.rpm [root@grafana ~]# rpm -ivh /root/Desktop/grafana-5.3.4- 1.x86_64.rpm # 启动服务 [root@grafana ~]# systemctl start grafana-server [root@grafana ~]# systemctl enable grafana-server # 确认端口(3000) [root@grafana ~]# lsof -i:3000 访问：http://10.101.1.52:3000，在Configuration中添加DataSource为prometheus的地址 配置dashboard grafana官方图表库有很多优秀的数据图表，可以按需求下载使用。参考网址:https://grafana.com/grafana/dashboards/。 到官网直接搜索数据源为prometheus的dashboard，下载对应的json文件（这些json文件可以看作是开发人员开发的一个监控模板），导入到grafana即可展示。 ","date":"2022-01-05","objectID":"/prometheus/:1:3","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#三grafana可视化图形展示工具"},{"categories":[],"content":"四、PromQL基本使用1、PromQL基本使用PromQL(Prometheus Query Language)是prometheus自己开发的数据查询DSL语言，语言表现力非常丰富，内置函数很多，在日常数据可视化以及rule告警中都会使用到它。我们把每个查询对象的名字叫做metrics，类似于mysql中的表名。 查询结果 瞬时数据：包含一组时序，每个时序只有一个点，例如：prometheus_http_request_total 区间数据：包含一组时序，每个时序有多个点，例如：prometheus_http_request_total [5m] 纯量数据：纯量只有一个数字，没有时序，例如：count(prometheus_http_request_total) 可以指定label的name查询，还支持算术运算。例如：+，-，*，/，比较运算：==，!=，\u003e,\u003c,\u003c=,\u003e=，逻辑运算and,or，聚合运算：sum,min,max,avg,count，内置函数：rate、irate、abs 常用的查询举例 五分钟的CPU平均使用率：100 - (avg(irate(node_cpu_seconds_total{mode= “idle”}[5m])) * 100) 可用内存百分比：(node_memory_MemAvailable_bytes / (node_memory_MemTotal_bytes)) * 100 磁盘一分钟读的速率：irate(node_disk_reads_completed_total{instance=~\"$node\"}[1m]) 可以结合grafana丰富的dashboard，编辑图表查看PromQL更好的学习PromQL语法。 2、常用函数1、rate函数rate会取指定时间范围内所有数据点，算出一组速率，然后取平均值作为结果。 单个counter类型的指标是无意义的，因为其只增不减，且重置就清零了。 rate（）函数用于计算在指定时间范围内计数器每秒增加量的平均值。 进行 rate 计算的时候是选择指定时间范围下的第一和最后一个样本进行计算，下图是表示瞬时计算的计算方式： 往往我们需要的是绘制一个图形，那么就需要进行区间查询，指定一个时间范围内进行多次计算，将结果串联起来形成一个图形： 2、irate函数irate取的是在指定时间范围内的最近两个数据点来算速率。 irate 同样用于计算区间向量的计算率，但是其反应出的是瞬时增长率。irate 函数是通过区间向量中最后两个样本数据来计算区间向量的增长速率。这种方式可以避免在时间窗口范围内的长尾问题，并且体现出更好的灵敏度，通过 irate 函数绘制的图标能够更好的反应样本数据的瞬时变化状态。 3、其他函数increase() rate()、irate() 和 increase() 函数只能输出非负值的结果，对于跟踪一个可以上升或下降的值的指标（如温度、内存或磁盘空间），可以使用 delta() 和 deriv() 函数来代替。 还有另外一个 predict_linear() 函数可以预测一个 Gauge 类型的指标在未来指定一段时间内的值，例如我们可以根据过去 15 分钟的变化情况，来预测一个小时后的磁盘使用量是多少，可以用如下所示的表达式来查询： predict_linear(demo_disk_usage_bytes{job=\"demo\"}[15m], 3600) 这个函数可以用于报警，告诉我们磁盘是否会在几个小时候内用完。 ","date":"2022-01-05","objectID":"/prometheus/:1:4","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#四promql基本使用"},{"categories":[],"content":"四、PromQL基本使用1、PromQL基本使用PromQL(Prometheus Query Language)是prometheus自己开发的数据查询DSL语言，语言表现力非常丰富，内置函数很多，在日常数据可视化以及rule告警中都会使用到它。我们把每个查询对象的名字叫做metrics，类似于mysql中的表名。 查询结果 瞬时数据：包含一组时序，每个时序只有一个点，例如：prometheus_http_request_total 区间数据：包含一组时序，每个时序有多个点，例如：prometheus_http_request_total [5m] 纯量数据：纯量只有一个数字，没有时序，例如：count(prometheus_http_request_total) 可以指定label的name查询，还支持算术运算。例如：+，-，*，/，比较运算：==，!=，,=，逻辑运算and,or，聚合运算：sum,min,max,avg,count，内置函数：rate、irate、abs 常用的查询举例 五分钟的CPU平均使用率：100 - (avg(irate(node_cpu_seconds_total{mode= “idle”}[5m])) * 100) 可用内存百分比：(node_memory_MemAvailable_bytes / (node_memory_MemTotal_bytes)) * 100 磁盘一分钟读的速率：irate(node_disk_reads_completed_total{instance=~\"$node\"}[1m]) 可以结合grafana丰富的dashboard，编辑图表查看PromQL更好的学习PromQL语法。 2、常用函数1、rate函数rate会取指定时间范围内所有数据点，算出一组速率，然后取平均值作为结果。 单个counter类型的指标是无意义的，因为其只增不减，且重置就清零了。 rate（）函数用于计算在指定时间范围内计数器每秒增加量的平均值。 进行 rate 计算的时候是选择指定时间范围下的第一和最后一个样本进行计算，下图是表示瞬时计算的计算方式： 往往我们需要的是绘制一个图形，那么就需要进行区间查询，指定一个时间范围内进行多次计算，将结果串联起来形成一个图形： 2、irate函数irate取的是在指定时间范围内的最近两个数据点来算速率。 irate 同样用于计算区间向量的计算率，但是其反应出的是瞬时增长率。irate 函数是通过区间向量中最后两个样本数据来计算区间向量的增长速率。这种方式可以避免在时间窗口范围内的长尾问题，并且体现出更好的灵敏度，通过 irate 函数绘制的图标能够更好的反应样本数据的瞬时变化状态。 3、其他函数increase() rate()、irate() 和 increase() 函数只能输出非负值的结果，对于跟踪一个可以上升或下降的值的指标（如温度、内存或磁盘空间），可以使用 delta() 和 deriv() 函数来代替。 还有另外一个 predict_linear() 函数可以预测一个 Gauge 类型的指标在未来指定一段时间内的值，例如我们可以根据过去 15 分钟的变化情况，来预测一个小时后的磁盘使用量是多少，可以用如下所示的表达式来查询： predict_linear(demo_disk_usage_bytes{job=\"demo\"}[15m], 3600) 这个函数可以用于报警，告诉我们磁盘是否会在几个小时候内用完。 ","date":"2022-01-05","objectID":"/prometheus/:1:4","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#1promql基本使用"},{"categories":[],"content":"四、PromQL基本使用1、PromQL基本使用PromQL(Prometheus Query Language)是prometheus自己开发的数据查询DSL语言，语言表现力非常丰富，内置函数很多，在日常数据可视化以及rule告警中都会使用到它。我们把每个查询对象的名字叫做metrics，类似于mysql中的表名。 查询结果 瞬时数据：包含一组时序，每个时序只有一个点，例如：prometheus_http_request_total 区间数据：包含一组时序，每个时序有多个点，例如：prometheus_http_request_total [5m] 纯量数据：纯量只有一个数字，没有时序，例如：count(prometheus_http_request_total) 可以指定label的name查询，还支持算术运算。例如：+，-，*，/，比较运算：==，!=，,=，逻辑运算and,or，聚合运算：sum,min,max,avg,count，内置函数：rate、irate、abs 常用的查询举例 五分钟的CPU平均使用率：100 - (avg(irate(node_cpu_seconds_total{mode= “idle”}[5m])) * 100) 可用内存百分比：(node_memory_MemAvailable_bytes / (node_memory_MemTotal_bytes)) * 100 磁盘一分钟读的速率：irate(node_disk_reads_completed_total{instance=~\"$node\"}[1m]) 可以结合grafana丰富的dashboard，编辑图表查看PromQL更好的学习PromQL语法。 2、常用函数1、rate函数rate会取指定时间范围内所有数据点，算出一组速率，然后取平均值作为结果。 单个counter类型的指标是无意义的，因为其只增不减，且重置就清零了。 rate（）函数用于计算在指定时间范围内计数器每秒增加量的平均值。 进行 rate 计算的时候是选择指定时间范围下的第一和最后一个样本进行计算，下图是表示瞬时计算的计算方式： 往往我们需要的是绘制一个图形，那么就需要进行区间查询，指定一个时间范围内进行多次计算，将结果串联起来形成一个图形： 2、irate函数irate取的是在指定时间范围内的最近两个数据点来算速率。 irate 同样用于计算区间向量的计算率，但是其反应出的是瞬时增长率。irate 函数是通过区间向量中最后两个样本数据来计算区间向量的增长速率。这种方式可以避免在时间窗口范围内的长尾问题，并且体现出更好的灵敏度，通过 irate 函数绘制的图标能够更好的反应样本数据的瞬时变化状态。 3、其他函数increase() rate()、irate() 和 increase() 函数只能输出非负值的结果，对于跟踪一个可以上升或下降的值的指标（如温度、内存或磁盘空间），可以使用 delta() 和 deriv() 函数来代替。 还有另外一个 predict_linear() 函数可以预测一个 Gauge 类型的指标在未来指定一段时间内的值，例如我们可以根据过去 15 分钟的变化情况，来预测一个小时后的磁盘使用量是多少，可以用如下所示的表达式来查询： predict_linear(demo_disk_usage_bytes{job=\"demo\"}[15m], 3600) 这个函数可以用于报警，告诉我们磁盘是否会在几个小时候内用完。 ","date":"2022-01-05","objectID":"/prometheus/:1:4","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#2常用函数"},{"categories":[],"content":"四、PromQL基本使用1、PromQL基本使用PromQL(Prometheus Query Language)是prometheus自己开发的数据查询DSL语言，语言表现力非常丰富，内置函数很多，在日常数据可视化以及rule告警中都会使用到它。我们把每个查询对象的名字叫做metrics，类似于mysql中的表名。 查询结果 瞬时数据：包含一组时序，每个时序只有一个点，例如：prometheus_http_request_total 区间数据：包含一组时序，每个时序有多个点，例如：prometheus_http_request_total [5m] 纯量数据：纯量只有一个数字，没有时序，例如：count(prometheus_http_request_total) 可以指定label的name查询，还支持算术运算。例如：+，-，*，/，比较运算：==，!=，,=，逻辑运算and,or，聚合运算：sum,min,max,avg,count，内置函数：rate、irate、abs 常用的查询举例 五分钟的CPU平均使用率：100 - (avg(irate(node_cpu_seconds_total{mode= “idle”}[5m])) * 100) 可用内存百分比：(node_memory_MemAvailable_bytes / (node_memory_MemTotal_bytes)) * 100 磁盘一分钟读的速率：irate(node_disk_reads_completed_total{instance=~\"$node\"}[1m]) 可以结合grafana丰富的dashboard，编辑图表查看PromQL更好的学习PromQL语法。 2、常用函数1、rate函数rate会取指定时间范围内所有数据点，算出一组速率，然后取平均值作为结果。 单个counter类型的指标是无意义的，因为其只增不减，且重置就清零了。 rate（）函数用于计算在指定时间范围内计数器每秒增加量的平均值。 进行 rate 计算的时候是选择指定时间范围下的第一和最后一个样本进行计算，下图是表示瞬时计算的计算方式： 往往我们需要的是绘制一个图形，那么就需要进行区间查询，指定一个时间范围内进行多次计算，将结果串联起来形成一个图形： 2、irate函数irate取的是在指定时间范围内的最近两个数据点来算速率。 irate 同样用于计算区间向量的计算率，但是其反应出的是瞬时增长率。irate 函数是通过区间向量中最后两个样本数据来计算区间向量的增长速率。这种方式可以避免在时间窗口范围内的长尾问题，并且体现出更好的灵敏度，通过 irate 函数绘制的图标能够更好的反应样本数据的瞬时变化状态。 3、其他函数increase() rate()、irate() 和 increase() 函数只能输出非负值的结果，对于跟踪一个可以上升或下降的值的指标（如温度、内存或磁盘空间），可以使用 delta() 和 deriv() 函数来代替。 还有另外一个 predict_linear() 函数可以预测一个 Gauge 类型的指标在未来指定一段时间内的值，例如我们可以根据过去 15 分钟的变化情况，来预测一个小时后的磁盘使用量是多少，可以用如下所示的表达式来查询： predict_linear(demo_disk_usage_bytes{job=\"demo\"}[15m], 3600) 这个函数可以用于报警，告诉我们磁盘是否会在几个小时候内用完。 ","date":"2022-01-05","objectID":"/prometheus/:1:4","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#1rate函数"},{"categories":[],"content":"四、PromQL基本使用1、PromQL基本使用PromQL(Prometheus Query Language)是prometheus自己开发的数据查询DSL语言，语言表现力非常丰富，内置函数很多，在日常数据可视化以及rule告警中都会使用到它。我们把每个查询对象的名字叫做metrics，类似于mysql中的表名。 查询结果 瞬时数据：包含一组时序，每个时序只有一个点，例如：prometheus_http_request_total 区间数据：包含一组时序，每个时序有多个点，例如：prometheus_http_request_total [5m] 纯量数据：纯量只有一个数字，没有时序，例如：count(prometheus_http_request_total) 可以指定label的name查询，还支持算术运算。例如：+，-，*，/，比较运算：==，!=，,=，逻辑运算and,or，聚合运算：sum,min,max,avg,count，内置函数：rate、irate、abs 常用的查询举例 五分钟的CPU平均使用率：100 - (avg(irate(node_cpu_seconds_total{mode= “idle”}[5m])) * 100) 可用内存百分比：(node_memory_MemAvailable_bytes / (node_memory_MemTotal_bytes)) * 100 磁盘一分钟读的速率：irate(node_disk_reads_completed_total{instance=~\"$node\"}[1m]) 可以结合grafana丰富的dashboard，编辑图表查看PromQL更好的学习PromQL语法。 2、常用函数1、rate函数rate会取指定时间范围内所有数据点，算出一组速率，然后取平均值作为结果。 单个counter类型的指标是无意义的，因为其只增不减，且重置就清零了。 rate（）函数用于计算在指定时间范围内计数器每秒增加量的平均值。 进行 rate 计算的时候是选择指定时间范围下的第一和最后一个样本进行计算，下图是表示瞬时计算的计算方式： 往往我们需要的是绘制一个图形，那么就需要进行区间查询，指定一个时间范围内进行多次计算，将结果串联起来形成一个图形： 2、irate函数irate取的是在指定时间范围内的最近两个数据点来算速率。 irate 同样用于计算区间向量的计算率，但是其反应出的是瞬时增长率。irate 函数是通过区间向量中最后两个样本数据来计算区间向量的增长速率。这种方式可以避免在时间窗口范围内的长尾问题，并且体现出更好的灵敏度，通过 irate 函数绘制的图标能够更好的反应样本数据的瞬时变化状态。 3、其他函数increase() rate()、irate() 和 increase() 函数只能输出非负值的结果，对于跟踪一个可以上升或下降的值的指标（如温度、内存或磁盘空间），可以使用 delta() 和 deriv() 函数来代替。 还有另外一个 predict_linear() 函数可以预测一个 Gauge 类型的指标在未来指定一段时间内的值，例如我们可以根据过去 15 分钟的变化情况，来预测一个小时后的磁盘使用量是多少，可以用如下所示的表达式来查询： predict_linear(demo_disk_usage_bytes{job=\"demo\"}[15m], 3600) 这个函数可以用于报警，告诉我们磁盘是否会在几个小时候内用完。 ","date":"2022-01-05","objectID":"/prometheus/:1:4","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#2irate函数"},{"categories":[],"content":"四、PromQL基本使用1、PromQL基本使用PromQL(Prometheus Query Language)是prometheus自己开发的数据查询DSL语言，语言表现力非常丰富，内置函数很多，在日常数据可视化以及rule告警中都会使用到它。我们把每个查询对象的名字叫做metrics，类似于mysql中的表名。 查询结果 瞬时数据：包含一组时序，每个时序只有一个点，例如：prometheus_http_request_total 区间数据：包含一组时序，每个时序有多个点，例如：prometheus_http_request_total [5m] 纯量数据：纯量只有一个数字，没有时序，例如：count(prometheus_http_request_total) 可以指定label的name查询，还支持算术运算。例如：+，-，*，/，比较运算：==，!=，,=，逻辑运算and,or，聚合运算：sum,min,max,avg,count，内置函数：rate、irate、abs 常用的查询举例 五分钟的CPU平均使用率：100 - (avg(irate(node_cpu_seconds_total{mode= “idle”}[5m])) * 100) 可用内存百分比：(node_memory_MemAvailable_bytes / (node_memory_MemTotal_bytes)) * 100 磁盘一分钟读的速率：irate(node_disk_reads_completed_total{instance=~\"$node\"}[1m]) 可以结合grafana丰富的dashboard，编辑图表查看PromQL更好的学习PromQL语法。 2、常用函数1、rate函数rate会取指定时间范围内所有数据点，算出一组速率，然后取平均值作为结果。 单个counter类型的指标是无意义的，因为其只增不减，且重置就清零了。 rate（）函数用于计算在指定时间范围内计数器每秒增加量的平均值。 进行 rate 计算的时候是选择指定时间范围下的第一和最后一个样本进行计算，下图是表示瞬时计算的计算方式： 往往我们需要的是绘制一个图形，那么就需要进行区间查询，指定一个时间范围内进行多次计算，将结果串联起来形成一个图形： 2、irate函数irate取的是在指定时间范围内的最近两个数据点来算速率。 irate 同样用于计算区间向量的计算率，但是其反应出的是瞬时增长率。irate 函数是通过区间向量中最后两个样本数据来计算区间向量的增长速率。这种方式可以避免在时间窗口范围内的长尾问题，并且体现出更好的灵敏度，通过 irate 函数绘制的图标能够更好的反应样本数据的瞬时变化状态。 3、其他函数increase() rate()、irate() 和 increase() 函数只能输出非负值的结果，对于跟踪一个可以上升或下降的值的指标（如温度、内存或磁盘空间），可以使用 delta() 和 deriv() 函数来代替。 还有另外一个 predict_linear() 函数可以预测一个 Gauge 类型的指标在未来指定一段时间内的值，例如我们可以根据过去 15 分钟的变化情况，来预测一个小时后的磁盘使用量是多少，可以用如下所示的表达式来查询： predict_linear(demo_disk_usage_bytes{job=\"demo\"}[15m], 3600) 这个函数可以用于报警，告诉我们磁盘是否会在几个小时候内用完。 ","date":"2022-01-05","objectID":"/prometheus/:1:4","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#3其他函数"},{"categories":[],"content":"五、高可用方案1、server高可用 部署多个相同配置的server A和B（甚至可以再加），保持相同的配置，收集相同的数据： 优点：服务能够提供基本的可靠性；配置非常简单，只要保证配置文件一致即可。 缺点：无法扩展；数据不一致；本质是单点，数据量大的时候，会有性能瓶颈。 适用场景：小规模集群；短期存储的需求。 remote storage（远程存储） 如果ServerA出现故障，启动ServerB： 优点：保证数据一致；数据可长期存储；server 可以灵活迁移。 缺点：server同样是单点，数据量大的时候存在性能瓶颈 适用场景：小规模集群；数据长期存储。 联邦集群 Prometheus原生支持联邦架构，能够实现从别的prometheus来抓取符合特定条件的数据： scrape_configs:- job_name:'federate'scrape_interval:15shonor_labels:truemetrics_path:'/federate'params:'match[]':- '{job=~\"kubernetes.*\"}'# 抓取了目标prometheus中job为kubernetes开头的所有监控项static_configs:- targets:- 'source-prometheus-1:9090'- 'source-prometheus-2:9090'- 'source-prometheus-3:9090' 优点：资料能够被持久化保持在第三方存储系统中；能够依旧不同任务进行层级划分；server可以灵活迁移；serverA和serverB可以用前面提到的方法进行高可用扩展。 缺点：单一资料中心带来的单点（ServerC压力较大）；分层带来的配置复杂，维护成本较高；监控成本较大。 适用场景：能够满足较大规模的监控需求；有很好地扩展；单资料中心下的较为完善的架构。 多资料中心高可用架构 多套k8s集群系统监控/cpu、内存、磁盘、网络等数据量不大 业务监控（nginx/grpc等）/和线上访问成正比，数据量巨大 各自特点： 系统监控要保存较长时间（要做长久的资源分析） 业务监控主要做实时探测，一般需求不会超过一星期（主要做实时业务成功率报警，历史数据分析从日志进行操作 多资料中心而且有不同存储需求 2、alert高可用","date":"2022-01-05","objectID":"/prometheus/:1:5","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#五高可用方案"},{"categories":[],"content":"五、高可用方案1、server高可用 部署多个相同配置的server A和B（甚至可以再加），保持相同的配置，收集相同的数据： 优点：服务能够提供基本的可靠性；配置非常简单，只要保证配置文件一致即可。 缺点：无法扩展；数据不一致；本质是单点，数据量大的时候，会有性能瓶颈。 适用场景：小规模集群；短期存储的需求。 remote storage（远程存储） 如果ServerA出现故障，启动ServerB： 优点：保证数据一致；数据可长期存储；server 可以灵活迁移。 缺点：server同样是单点，数据量大的时候存在性能瓶颈 适用场景：小规模集群；数据长期存储。 联邦集群 Prometheus原生支持联邦架构，能够实现从别的prometheus来抓取符合特定条件的数据： scrape_configs:- job_name:'federate'scrape_interval:15shonor_labels:truemetrics_path:'/federate'params:'match[]':- '{job=~\"kubernetes.*\"}'# 抓取了目标prometheus中job为kubernetes开头的所有监控项static_configs:- targets:- 'source-prometheus-1:9090'- 'source-prometheus-2:9090'- 'source-prometheus-3:9090' 优点：资料能够被持久化保持在第三方存储系统中；能够依旧不同任务进行层级划分；server可以灵活迁移；serverA和serverB可以用前面提到的方法进行高可用扩展。 缺点：单一资料中心带来的单点（ServerC压力较大）；分层带来的配置复杂，维护成本较高；监控成本较大。 适用场景：能够满足较大规模的监控需求；有很好地扩展；单资料中心下的较为完善的架构。 多资料中心高可用架构 多套k8s集群系统监控/cpu、内存、磁盘、网络等数据量不大 业务监控（nginx/grpc等）/和线上访问成正比，数据量巨大 各自特点： 系统监控要保存较长时间（要做长久的资源分析） 业务监控主要做实时探测，一般需求不会超过一星期（主要做实时业务成功率报警，历史数据分析从日志进行操作 多资料中心而且有不同存储需求 2、alert高可用","date":"2022-01-05","objectID":"/prometheus/:1:5","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#1server高可用"},{"categories":[],"content":"五、高可用方案1、server高可用 部署多个相同配置的server A和B（甚至可以再加），保持相同的配置，收集相同的数据： 优点：服务能够提供基本的可靠性；配置非常简单，只要保证配置文件一致即可。 缺点：无法扩展；数据不一致；本质是单点，数据量大的时候，会有性能瓶颈。 适用场景：小规模集群；短期存储的需求。 remote storage（远程存储） 如果ServerA出现故障，启动ServerB： 优点：保证数据一致；数据可长期存储；server 可以灵活迁移。 缺点：server同样是单点，数据量大的时候存在性能瓶颈 适用场景：小规模集群；数据长期存储。 联邦集群 Prometheus原生支持联邦架构，能够实现从别的prometheus来抓取符合特定条件的数据： scrape_configs:- job_name:'federate'scrape_interval:15shonor_labels:truemetrics_path:'/federate'params:'match[]':- '{job=~\"kubernetes.*\"}'# 抓取了目标prometheus中job为kubernetes开头的所有监控项static_configs:- targets:- 'source-prometheus-1:9090'- 'source-prometheus-2:9090'- 'source-prometheus-3:9090' 优点：资料能够被持久化保持在第三方存储系统中；能够依旧不同任务进行层级划分；server可以灵活迁移；serverA和serverB可以用前面提到的方法进行高可用扩展。 缺点：单一资料中心带来的单点（ServerC压力较大）；分层带来的配置复杂，维护成本较高；监控成本较大。 适用场景：能够满足较大规模的监控需求；有很好地扩展；单资料中心下的较为完善的架构。 多资料中心高可用架构 多套k8s集群系统监控/cpu、内存、磁盘、网络等数据量不大 业务监控（nginx/grpc等）/和线上访问成正比，数据量巨大 各自特点： 系统监控要保存较长时间（要做长久的资源分析） 业务监控主要做实时探测，一般需求不会超过一星期（主要做实时业务成功率报警，历史数据分析从日志进行操作 多资料中心而且有不同存储需求 2、alert高可用","date":"2022-01-05","objectID":"/prometheus/:1:5","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#2alert高可用"},{"categories":[],"content":"六、扩展1、prometheus数据类型 数据模型 metrics name \u0026 label 指标名称和标签（key=value)的形式组成。如prometheus_http_requests_total{code=\"200\",handler=\"/api/v1/label/:name/values\",instance=\"localhost:9090\",job=\"prometheus\"} 一般由字母和下划线构成，prometheus_http_requests_total(应用名称_监测对象 _ 数值类型 _单位) label（标签）就是对一条时间序列不同维度的识别，每个k-v对都是一个label。 counter（计数器类型） counter类型的指标的工作方式和计数器一样，只增不减（除非系统发生了重置）。Counter一般用于累计值，例如记录请求次数、任务完成数，错误发生数。 通常来讲，许多指标counter本身并没有什么意义，有意义的是counter随时间的变化率。 Gauge（仪表盘类型） Gauge是可增可减的指标类，可以用于反应当前应用的状态，比如机器内存、磁盘可用空间大小等。node_memory_MemAvailable_bytes/node_file Histogram（直方图类型） Histogram由\u003cbasename\u003e_bucket，\u003cbasename\u003e_sum,\u003cbasename\u003e_counter组成。主要用于表示一段时间范围内对数据进行采样（通常是请求持续时间或响应大小），并能够对其指定区间以及总数进行统计，通常它采集的数据展示为直方图。 事件发生的总次数：basename_count。 所有事件产生值的大小的总和：basename_sum. 事件产生的值分布在bucket中的次数。 Summary（摘要类型） Summary类型和Histogram类型相似，由\u003cbasename\u003e{quantile= \"\u003c\u003e\"},\u003cbasename\u003e_sum,\u003cbasename\u003e_count，主要用于表示一段时间内数据采样结果（通常是请求持续时间或响应大小），它直接存储了分位数据，而不是根据统计区间计算出来的。 二者区别 Histogram指标直接反应了在不同区间内样本的个数，区间通过标签le进行定义，同时对于Histogram的指标，我们还可以通过histogram_quantile()函数计算出其值的分位数。 而Summary的分位数则是直接在客户端计算完成。 因此对于分位数的计算而言，Summary在通过PromQL进行查询时有更好的性能表现，而Histogram是在prometheus server上计算的，会消耗更多的资源，反之对于客户端而言Histogram消耗的资源更少。在选择这两种方式时用户应该按照自己的实际场景进行选择。 2、label的使用label（标签）使用 label能够让我们知道监控项目的来源端口方法等，同时label也为prometheus提供了丰富的聚合和查询等功能。可以在targets中看到已有的label有哪些，在实际使用中需要对冗长的label进行格式处理，以更加清晰可读的方式展示出来。 label的操作： keep 只保留符合匹配的标签； Drop 丢弃符合匹配的标签； 还支持replace、labelmap、keep、drop等操作 # 在Prometheus采集数据之前，通过Target实例的Metadata信息，动态重新写入Label的值。# 如将原始的__meta_kubernetes_namespace直接写成namespace，简洁明了- job_name:kubernetes-nodesscrape_interval:1mscrape_timeout:10smetrics_path:/metricsscheme:httpskubernetes_sd_configs:- api_server:nullrole:nodenamespaces:names:[]bearer_token_file:/var/run/secrets/kubernetes.io/serviceaccount/tokentls_config:ca_file:/var/run/secrets/kubernetes.io/serviceaccount/ca.crtinsecure_skip_verify:truerelabel_configs:- separator:;regex:__meta_kubernetes_node_label_(.+)replacement:$1action:labelmap- separator:;regex:(.*)target_label:__address__replacement:kubernetes.default.svc:443action:replace- source_labels:[__meta_kubernetes_node_name]action:replaceseparator:;regex:(.+)replacement:/api/v1/nodes/${1}/proxy/metricstarget_label:__metrics_path__ ","date":"2022-01-05","objectID":"/prometheus/:1:6","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#六扩展"},{"categories":[],"content":"六、扩展1、prometheus数据类型 数据模型 metrics name \u0026 label 指标名称和标签（key=value)的形式组成。如prometheus_http_requests_total{code=\"200\",handler=\"/api/v1/label/:name/values\",instance=\"localhost:9090\",job=\"prometheus\"} 一般由字母和下划线构成，prometheus_http_requests_total(应用名称_监测对象 _ 数值类型 _单位) label（标签）就是对一条时间序列不同维度的识别，每个k-v对都是一个label。 counter（计数器类型） counter类型的指标的工作方式和计数器一样，只增不减（除非系统发生了重置）。Counter一般用于累计值，例如记录请求次数、任务完成数，错误发生数。 通常来讲，许多指标counter本身并没有什么意义，有意义的是counter随时间的变化率。 Gauge（仪表盘类型） Gauge是可增可减的指标类，可以用于反应当前应用的状态，比如机器内存、磁盘可用空间大小等。node_memory_MemAvailable_bytes/node_file Histogram（直方图类型） Histogram由_bucket，_sum,_counter组成。主要用于表示一段时间范围内对数据进行采样（通常是请求持续时间或响应大小），并能够对其指定区间以及总数进行统计，通常它采集的数据展示为直方图。 事件发生的总次数：basename_count。 所有事件产生值的大小的总和：basename_sum. 事件产生的值分布在bucket中的次数。 Summary（摘要类型） Summary类型和Histogram类型相似，由{quantile= \"\"},_sum,_count，主要用于表示一段时间内数据采样结果（通常是请求持续时间或响应大小），它直接存储了分位数据，而不是根据统计区间计算出来的。 二者区别 Histogram指标直接反应了在不同区间内样本的个数，区间通过标签le进行定义，同时对于Histogram的指标，我们还可以通过histogram_quantile()函数计算出其值的分位数。 而Summary的分位数则是直接在客户端计算完成。 因此对于分位数的计算而言，Summary在通过PromQL进行查询时有更好的性能表现，而Histogram是在prometheus server上计算的，会消耗更多的资源，反之对于客户端而言Histogram消耗的资源更少。在选择这两种方式时用户应该按照自己的实际场景进行选择。 2、label的使用label（标签）使用 label能够让我们知道监控项目的来源端口方法等，同时label也为prometheus提供了丰富的聚合和查询等功能。可以在targets中看到已有的label有哪些，在实际使用中需要对冗长的label进行格式处理，以更加清晰可读的方式展示出来。 label的操作： keep 只保留符合匹配的标签； Drop 丢弃符合匹配的标签； 还支持replace、labelmap、keep、drop等操作 # 在Prometheus采集数据之前，通过Target实例的Metadata信息，动态重新写入Label的值。# 如将原始的__meta_kubernetes_namespace直接写成namespace，简洁明了- job_name:kubernetes-nodesscrape_interval:1mscrape_timeout:10smetrics_path:/metricsscheme:httpskubernetes_sd_configs:- api_server:nullrole:nodenamespaces:names:[]bearer_token_file:/var/run/secrets/kubernetes.io/serviceaccount/tokentls_config:ca_file:/var/run/secrets/kubernetes.io/serviceaccount/ca.crtinsecure_skip_verify:truerelabel_configs:- separator:;regex:__meta_kubernetes_node_label_(.+)replacement:$1action:labelmap- separator:;regex:(.*)target_label:__address__replacement:kubernetes.default.svc:443action:replace- source_labels:[__meta_kubernetes_node_name]action:replaceseparator:;regex:(.+)replacement:/api/v1/nodes/${1}/proxy/metricstarget_label:__metrics_path__ ","date":"2022-01-05","objectID":"/prometheus/:1:6","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#1prometheus数据类型"},{"categories":[],"content":"六、扩展1、prometheus数据类型 数据模型 metrics name \u0026 label 指标名称和标签（key=value)的形式组成。如prometheus_http_requests_total{code=\"200\",handler=\"/api/v1/label/:name/values\",instance=\"localhost:9090\",job=\"prometheus\"} 一般由字母和下划线构成，prometheus_http_requests_total(应用名称_监测对象 _ 数值类型 _单位) label（标签）就是对一条时间序列不同维度的识别，每个k-v对都是一个label。 counter（计数器类型） counter类型的指标的工作方式和计数器一样，只增不减（除非系统发生了重置）。Counter一般用于累计值，例如记录请求次数、任务完成数，错误发生数。 通常来讲，许多指标counter本身并没有什么意义，有意义的是counter随时间的变化率。 Gauge（仪表盘类型） Gauge是可增可减的指标类，可以用于反应当前应用的状态，比如机器内存、磁盘可用空间大小等。node_memory_MemAvailable_bytes/node_file Histogram（直方图类型） Histogram由_bucket，_sum,_counter组成。主要用于表示一段时间范围内对数据进行采样（通常是请求持续时间或响应大小），并能够对其指定区间以及总数进行统计，通常它采集的数据展示为直方图。 事件发生的总次数：basename_count。 所有事件产生值的大小的总和：basename_sum. 事件产生的值分布在bucket中的次数。 Summary（摘要类型） Summary类型和Histogram类型相似，由{quantile= \"\"},_sum,_count，主要用于表示一段时间内数据采样结果（通常是请求持续时间或响应大小），它直接存储了分位数据，而不是根据统计区间计算出来的。 二者区别 Histogram指标直接反应了在不同区间内样本的个数，区间通过标签le进行定义，同时对于Histogram的指标，我们还可以通过histogram_quantile()函数计算出其值的分位数。 而Summary的分位数则是直接在客户端计算完成。 因此对于分位数的计算而言，Summary在通过PromQL进行查询时有更好的性能表现，而Histogram是在prometheus server上计算的，会消耗更多的资源，反之对于客户端而言Histogram消耗的资源更少。在选择这两种方式时用户应该按照自己的实际场景进行选择。 2、label的使用label（标签）使用 label能够让我们知道监控项目的来源端口方法等，同时label也为prometheus提供了丰富的聚合和查询等功能。可以在targets中看到已有的label有哪些，在实际使用中需要对冗长的label进行格式处理，以更加清晰可读的方式展示出来。 label的操作： keep 只保留符合匹配的标签； Drop 丢弃符合匹配的标签； 还支持replace、labelmap、keep、drop等操作 # 在Prometheus采集数据之前，通过Target实例的Metadata信息，动态重新写入Label的值。# 如将原始的__meta_kubernetes_namespace直接写成namespace，简洁明了- job_name:kubernetes-nodesscrape_interval:1mscrape_timeout:10smetrics_path:/metricsscheme:httpskubernetes_sd_configs:- api_server:nullrole:nodenamespaces:names:[]bearer_token_file:/var/run/secrets/kubernetes.io/serviceaccount/tokentls_config:ca_file:/var/run/secrets/kubernetes.io/serviceaccount/ca.crtinsecure_skip_verify:truerelabel_configs:- separator:;regex:__meta_kubernetes_node_label_(.+)replacement:$1action:labelmap- separator:;regex:(.*)target_label:__address__replacement:kubernetes.default.svc:443action:replace- source_labels:[__meta_kubernetes_node_name]action:replaceseparator:;regex:(.+)replacement:/api/v1/nodes/${1}/proxy/metricstarget_label:__metrics_path__ ","date":"2022-01-05","objectID":"/prometheus/:1:6","series":null,"tags":[],"title":"Prometheus监控系统","uri":"/prometheus/#2label的使用"},{"categories":[],"content":"Paxos的理解困境曾经有个很牛逼的大佬说，这个世界上只有一种一致性算法，那就是Paxos，其它的算法都是残次 品。 基于Paxos的算法变种有ZAB、Raft。 ","date":"2021-09-14","objectID":"/paxos-algo/:1:0","series":null,"tags":[],"title":"Paxos算法学习","uri":"/paxos-algo/#paxos的理解困境"},{"categories":[],"content":"Paxos究竟在解决什么问题？Paxos用来确定一个不可变变量的取值 取值可以是任意的二进制数据。 一旦确定将不再更改，并且可以被获取到（不可变性、可读取性）。 系统有多个存储的节点，这些节点之间的数据要保持一致。 系统有多个写入的节点，这些写入的节点会存在并发，如何确定由哪个节点写入？ 多个写入节点可能会出现故障. 多个存储节点也可能出现故障，但是要保证半数以上的存储节点是可用并且值是一致 的。 写入的节点称为proposer，决定写入数据的节点称为acceptor。 ","date":"2021-09-14","objectID":"/paxos-algo/:1:1","series":null,"tags":[],"title":"Paxos算法学习","uri":"/paxos-algo/#paxos究竟在解决什么问题"},{"categories":[],"content":"Paxos如何在分布式存储系统中应用？ 数据本身可变，采用多副本的方式进行存储 多个副本的更新操作序列[Op1,Op2,Op3,…,Opn]是相同的、不变的。 用Paxos依次来确定不可变变量Opi的取值（即第i个操作是什么）。 每确定完Opi之后，让各个数据副本执行Opi，依次类推。 Google的Chubby [‘tʃʌbi] 等都采用了Paxos来对数据副本的更新序列达成一致。 ","date":"2021-09-14","objectID":"/paxos-algo/:1:2","series":null,"tags":[],"title":"Paxos算法学习","uri":"/paxos-algo/#paxos如何在分布式存储系统中应用"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=\u003e\u003cok,f\u003eor\u003cerror\u003e ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回\u003cok,f\u003e。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值\u003caccepted_epoch,accepted_value\u003e 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值\u003caccepted_epoch,accepted_value\u003e= \u003cprepared_epoch,V\u003e 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回\u003cok,V\u003e 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回\u003cok,accepted_value\u003e。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos算法学习","uri":"/paxos-algo/#paxos算法的核心思想是什么"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=or ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值= 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos算法学习","uri":"/paxos-algo/#设计一个系统来存储名称为var的变量"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=or ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值= 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos算法学习","uri":"/paxos-algo/#系统需要保证var的取值满足一致性"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=or ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值= 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos算法学习","uri":"/paxos-algo/#系统需要满足容错特性"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=or ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值= 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos算法学习","uri":"/paxos-algo/#为了讲解简单暂不考虑"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=or ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值= 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos算法学习","uri":"/paxos-algo/#确定一个不可变变量难点"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=or ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值= 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos算法学习","uri":"/paxos-algo/#确定一个不可变变量的取值方案1"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=or ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值= 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos算法学习","uri":"/paxos-algo/#方案1基于互斥访问权的acceptor的实现"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=or ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值= 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos算法学习","uri":"/paxos-algo/#方案1proposevarv的两阶段实现"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=or ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值= 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos算法学习","uri":"/paxos-algo/#方案1总结"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=or ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值= 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos算法学习","uri":"/paxos-algo/#方案2引入抢占式访问权"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=or ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值= 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos算法学习","uri":"/paxos-algo/#方案2基于抢占式访问权的acceptor的实现"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=or ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值= 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos算法学习","uri":"/paxos-algo/#方案2proposevarv的两阶段实现"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=or ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值= 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos算法学习","uri":"/paxos-algo/#方案2总结"},{"categories":[],"content":"Paxos算法的核心思想是什么？设计一个系统，来存储名称为var的变量 系统内部由多个Acceptor组成，负责存储和管理var变量。 外部有多个proposer机器任意并发调用API，向系统提交不同的var取值。 var的取值可以是任意的二进制数据 系统对外的API库接口为： propose(var,V)=or ，proposer机器向系统发出请求，希望把var设置成V，系统会返回ok和系统内部已经确定下来的取值，或者返回error，如果说系统内部将这个值设置成V，那么f就是V，否则f就是其他proposer设置成的结果。 这个时候我们对于这个系统的初步印象可以是这样的，不一定是对的。 PaxosPaxos \" Paxos 系统需要保证var的取值满足一致性那么就会要求 如果var的取值还没确定，则var的取值为null。 一旦var的取值被确定，则不可被更改，并且可以一直取到这个值。 系统需要满足容错特性 可以容忍任意proposer机器出现故障。 可以容忍少数Acceptor故障（少于半数）。 为了讲解简单，暂不考虑 网络分化。 Acceptor故障会丢失var的信息。 确定一个不可变变量——难点 管理多个Proposer的并发执行 保证var变量的不可变性 容忍任意Propose机器故障 容忍半数以下Acceptor机器故障 确定一个不可变变量的取值——方案1 先考虑系统由单个Acceptor组成。通过类似互斥锁机制，来管理并发的proposer运行。 Proposer首先向acceptor申请acceptor的互斥访问权，然后才能请求acceptor接受自己的取值。 acceptor给proposer发放互斥访问权，谁申请到互斥访问权，就接收谁提交的取值。 这样的话，就可以让proposer按照获取互斥访问权的顺序依次访问acceptor。 一旦acceptor接收了某个proposer的取值，则认为var的取值被确定，其他proposer不再更改。 方案1——基于互斥访问权的acceptor的实现 acceptor保存变量var和一个互斥锁lock acceptor::prepare(): 加互斥锁，给予var的互斥访问权，并且返回var当前的取值f。 acceptor::release(): 解互斥锁，收回var的互斥访问权。 acceptor::accept(var,V): 如果已经加锁，并且var没有确定值，则设置var为V。并且释放锁。 方案1——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 如果不能，返回error，代表锁已经被别人占用了。 第二阶段：根据当前var的取值f，执行选择。 如果f为null，则通过acceptor::accept(var,V)来提交数据V。 如果f不为空，则通过acceptor::release()释放访问权，返回。这代表当前proposer想要修改历史的var的取值，根据一致性原则，之前确定下来的值不改，返回已经确定的取值。 方案1——总结 通过acceptor互斥访问权让proposer序列运行，可以简单的实现var取值的一致性。 proposer在释放互斥访问权之前发生故障，会导致系统陷入死锁。 不能容忍任意的Proposer机器故障。 方案2——引入抢占式访问权方案1我们看起来就是因为死锁的问题导致不够完善，那么我们怎么解决死锁问题呢？ acceptor可以让某个proposer获取到的访问权失效，不再接收它的访问。 之后，可以将访问权发放给其他proposer，让其他proposer访问acceptor。 那么对于acceptor来说，它就只需要记录下最新发放的访问权就行了。新的有用，旧的不行。可是要怎么判断新旧呢？ Proposer向acceptor申请访问权时指定编号epoch /ˈiː.pɒk/ （越大的epoch越新），获取到访问权之后，才能向acceptor提交取值。 acceptor采用喜新厌旧的原则。 一旦收到更大的新epoch的申请，马上让旧epoch的访问权失效，不再接收他们提交的取值。 然后给新epoch发放访问权，只接收新epoch提交的取值。 新epoch可以抢占旧epoch，让旧epoch的访问权失效。旧epoch的proposer将无法运行，新epoch的proposer将开始运行。 为了保持一致性，不同的proposer之间采用“后者认同前者”的原则。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 方案2——基于抢占式访问权的acceptor的实现 acceptor保存的状态 当前var的取值 最新发放访问权的epoch(lastest_prepared_epoch) acceptor::prepare(epoch): 只接收比lastest_prepared_epoch更大的epoch，并且给予访问权， 记录lastest_prepared_epoch=epoch；然后返回当前var的取值 acceptor::accept(var,prepared_epoch,V): 验证是否prepared_epoch==lastest_prepared_epoch 假如验证通过，设置var的取值= 假如不通过，说明已经有了更大的epoch申请到了访问权，当前proposer获 取到的访问权失效。 方案2——propose(var,V)的两阶段实现 第一阶段：通过acceptor::prepare获取互斥访问权和当前var的取值。 我们可以简单地以当前时间戳为epoch，通过acceptor::prepare(epoch)，获取epoch轮次的访问权和当前var的取值。 如果不能获取，返回error。说明当前已经有个相同或者更大的epoch获取到了访问 权。 第二阶段：采用“后者认同前者”的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值，不会破坏。 如果var的取值为空，则肯定旧epoch无法生成确定性取值，则通过 acceptor::accept(var,prepared_epoch,V)提交数据V。成功后返回 如果accept失败，返回error。（被新的epoch抢占或者acceptor故障） 如果var的取值存在，则此取值肯定是确定性取值，此时认同它不再更改，直接返回。 画图来说明下，Proposer1向acceptor发送访问权申请 Proposer2向acceptor发送访问权申请 Proposer2拿到了访问权，向acceptor提交自己的数据。且之后Proposer1向acceptor提交自己的 数据。 再之后proposer3向acceptor发送访问权申请。 因为这个时候已经有确定性取值了，proposer3会认可这个值，不再进行修改。 方案2——总结 基于抢占式访问权的核心思想 让Proposer将按照epoch递增的顺序抢占式的依次运行，后者会认同前者。 可以避免proposer机器故障带来的死锁问题，并且仍可以保证var取值的一致性。 仍需要引入多acceptor 单机模块acceptor故障将会导致整系统宕机，无法提供服务。 思考——关于方案1和2 方案1 如何控制proposer的并发运行？ 为何可以保证一致性？ 为什么会有死锁问题？ 方案2 如何解决方案1的死锁问题？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值？ 如何保证新epoch不会破坏已经达成的确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:3","series":null,"tags":[],"title":"Paxos算法学习","uri":"/paxos-algo/#思考关于方案1和2"},{"categories":[],"content":"Paxos Paxos在方案2的基础上引入多acceptor。 acceptor的实现保持不变，仍然采用“喜新厌旧”的原则运行。 Paxos采用了少数acceptor服从多数的思路（少数服从多数）。 在方案2中，一旦某个epoch的取值f被系统里仅有的acceptor接受，那么我们就认为var的取值被确定了。那么在Paxos中，我们定义，一旦某epoch的取值f被半数以上acceptor接受，则认为此取值被确定为f，不再更改。 Acceptor的实现不变Propose的两阶段实现propose(var,V)第一阶段：选定epoch，获取epoch访问权和对应var的取值。 获取半数以上acceptor的访问权和对应的一组var取值。 因为半数以上和半数以上必然存在交集，那么就可以保证，一个epoch最多只会有一个proposer拿到访问权，进入第二阶段运行。 propose(var,V)第二阶段：采用后者认同前者的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值， 不会破坏。 如果proposer在第一阶段获取到的var取值都为空，则旧epoch无法形成确定性取值。此时努力使\u003cepoch,V\u003e成为确定性取值。 向所有的epoch对应的所有acceptor提交取值\u003cepoch,V\u003e。 如果收到半数以上成功，则返回\u003cok,V\u003e。 否则，则返回error（被新的epoch抢占或者accepor故障）。 如果说var的取值存在，那么就要认同最大accepted_epoch对应的取值f，努力使\u003cepoch,f\u003e成为确定性取值。 如果f已经出现了半数以上，则说明f已经是确定性取值，直接返回\u003cok,f\u003e 如果说f只是出现了半数以下，那此时f可能是确定性取值，也可能不是，不管怎样，此时的epoch都会认同这个f，向所有的acceptor提交这个取值\u003cepoch,f\u003e ​ 我们想象一下，当proposer1提交的\u003cepoch1,f\u003e被acceptor接受，epoch1形成了确定性取值，紧接着下一个就是proposer2的提交的epoch2，proposer2肯定是可以获取到至少一个确定性取值\u003cepoch1,f\u003e，并且在epoch2获取到的所有取值里面，epoch1是一个最大的epoch，所以epoch2会认可epoch1提交的取值f，以此类推，后面的epoch也都会认可epoch1提交的取值f，不会进行更改。 ​ 画图讲解下第一阶段 ​ proposer1向所有的acceptor发出prepare请求，并且返回var的当前取值，全部为空。 ​ proposer1发现所有的取值为空，这个时候proposer1就可以选定自己的取值V1为确定性取值向所有的acceptor发送accept请求。proposer1进入第二阶段，向第一个acceptor发出请求。 ​ 在这个时候，P2进入第一阶段，向acceptor发出prepare请求。使用epoch2企图抢占访问权。P2向前两个acceptor发出了prepare请求。 ​ epoch1的访问权直接失效，epoch2获取到了访问权，acceptor向P2返回了节点当前保存的结果。P2进入了第二阶段，在P2发起accept请求之前，P1继续向另外的两个节点发送accept请求。 ​ 在这个情况中，第二个acceptor会拒绝P1的请求，因为epoch1访问权失效，第三个acceptor接受了V1这个取值并且返回成功。这个时候，epoch1已经形成了确定性取值V1，也是P1的取值V1。 ​ 这个时候，P2开始在第二阶段向acceptor发起accept请求。它选定取值里面最大的epoch的取值，也就是epoch1提交的V1，然后开始让acceptor接受V1。 ​ 所以在这种情况下，我们可以看到P2也形成了确定性取值V1，因为它是直接选择epoch1提交的取值V1，所以即使epoch1和epoch2都形成了确定性取值，这两个取值不会发生冲突。 ​ 我们可以假设，P1的后两个accept请求没有成功发出去，那么epoch1无法形成确定性取值，epoch2也会照样选择V1来形成确定性取值，也不会形成冲突。 Paxos——总结Paxos算法的核心思想 在抢占式访问权的基础上引入多个acceptor 保证一个epoch，只有proposer运行，proposer按照epoch递增的顺序依次运行。 新epoch的proposer采用“后者认同前者”的思路运行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取 值，不会破坏。 Paxos算法可以满足容错性要求 半数以下acceptor出现故障时，存活的acceptor仍然了可以生成var的确定性取值。 一旦var取值被确定，即使出现了半数以下acceptor故障，该取值也可以被获取，并且不再更改。 Paxos算法的livelock问题 新轮次的抢占会让旧轮次停止运行，如果每一轮次在第二阶段成功之前都被新一轮次抢占，则 导致活锁，怎么解决呢？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:4","series":null,"tags":[],"title":"Paxos算法学习","uri":"/paxos-algo/#paxos"},{"categories":[],"content":"Paxos Paxos在方案2的基础上引入多acceptor。 acceptor的实现保持不变，仍然采用“喜新厌旧”的原则运行。 Paxos采用了少数acceptor服从多数的思路（少数服从多数）。 在方案2中，一旦某个epoch的取值f被系统里仅有的acceptor接受，那么我们就认为var的取值被确定了。那么在Paxos中，我们定义，一旦某epoch的取值f被半数以上acceptor接受，则认为此取值被确定为f，不再更改。 Acceptor的实现不变Propose的两阶段实现propose(var,V)第一阶段：选定epoch，获取epoch访问权和对应var的取值。 获取半数以上acceptor的访问权和对应的一组var取值。 因为半数以上和半数以上必然存在交集，那么就可以保证，一个epoch最多只会有一个proposer拿到访问权，进入第二阶段运行。 propose(var,V)第二阶段：采用后者认同前者的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值， 不会破坏。 如果proposer在第一阶段获取到的var取值都为空，则旧epoch无法形成确定性取值。此时努力使成为确定性取值。 向所有的epoch对应的所有acceptor提交取值。 如果收到半数以上成功，则返回。 否则，则返回error（被新的epoch抢占或者accepor故障）。 如果说var的取值存在，那么就要认同最大accepted_epoch对应的取值f，努力使成为确定性取值。 如果f已经出现了半数以上，则说明f已经是确定性取值，直接返回 如果说f只是出现了半数以下，那此时f可能是确定性取值，也可能不是，不管怎样，此时的epoch都会认同这个f，向所有的acceptor提交这个取值 ​ 我们想象一下，当proposer1提交的被acceptor接受，epoch1形成了确定性取值，紧接着下一个就是proposer2的提交的epoch2，proposer2肯定是可以获取到至少一个确定性取值，并且在epoch2获取到的所有取值里面，epoch1是一个最大的epoch，所以epoch2会认可epoch1提交的取值f，以此类推，后面的epoch也都会认可epoch1提交的取值f，不会进行更改。 ​ 画图讲解下第一阶段 ​ proposer1向所有的acceptor发出prepare请求，并且返回var的当前取值，全部为空。 ​ proposer1发现所有的取值为空，这个时候proposer1就可以选定自己的取值V1为确定性取值向所有的acceptor发送accept请求。proposer1进入第二阶段，向第一个acceptor发出请求。 ​ 在这个时候，P2进入第一阶段，向acceptor发出prepare请求。使用epoch2企图抢占访问权。P2向前两个acceptor发出了prepare请求。 ​ epoch1的访问权直接失效，epoch2获取到了访问权，acceptor向P2返回了节点当前保存的结果。P2进入了第二阶段，在P2发起accept请求之前，P1继续向另外的两个节点发送accept请求。 ​ 在这个情况中，第二个acceptor会拒绝P1的请求，因为epoch1访问权失效，第三个acceptor接受了V1这个取值并且返回成功。这个时候，epoch1已经形成了确定性取值V1，也是P1的取值V1。 ​ 这个时候，P2开始在第二阶段向acceptor发起accept请求。它选定取值里面最大的epoch的取值，也就是epoch1提交的V1，然后开始让acceptor接受V1。 ​ 所以在这种情况下，我们可以看到P2也形成了确定性取值V1，因为它是直接选择epoch1提交的取值V1，所以即使epoch1和epoch2都形成了确定性取值，这两个取值不会发生冲突。 ​ 我们可以假设，P1的后两个accept请求没有成功发出去，那么epoch1无法形成确定性取值，epoch2也会照样选择V1来形成确定性取值，也不会形成冲突。 Paxos——总结Paxos算法的核心思想 在抢占式访问权的基础上引入多个acceptor 保证一个epoch，只有proposer运行，proposer按照epoch递增的顺序依次运行。 新epoch的proposer采用“后者认同前者”的思路运行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取 值，不会破坏。 Paxos算法可以满足容错性要求 半数以下acceptor出现故障时，存活的acceptor仍然了可以生成var的确定性取值。 一旦var取值被确定，即使出现了半数以下acceptor故障，该取值也可以被获取，并且不再更改。 Paxos算法的livelock问题 新轮次的抢占会让旧轮次停止运行，如果每一轮次在第二阶段成功之前都被新一轮次抢占，则 导致活锁，怎么解决呢？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:4","series":null,"tags":[],"title":"Paxos算法学习","uri":"/paxos-algo/#acceptor的实现不变"},{"categories":[],"content":"Paxos Paxos在方案2的基础上引入多acceptor。 acceptor的实现保持不变，仍然采用“喜新厌旧”的原则运行。 Paxos采用了少数acceptor服从多数的思路（少数服从多数）。 在方案2中，一旦某个epoch的取值f被系统里仅有的acceptor接受，那么我们就认为var的取值被确定了。那么在Paxos中，我们定义，一旦某epoch的取值f被半数以上acceptor接受，则认为此取值被确定为f，不再更改。 Acceptor的实现不变Propose的两阶段实现propose(var,V)第一阶段：选定epoch，获取epoch访问权和对应var的取值。 获取半数以上acceptor的访问权和对应的一组var取值。 因为半数以上和半数以上必然存在交集，那么就可以保证，一个epoch最多只会有一个proposer拿到访问权，进入第二阶段运行。 propose(var,V)第二阶段：采用后者认同前者的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值， 不会破坏。 如果proposer在第一阶段获取到的var取值都为空，则旧epoch无法形成确定性取值。此时努力使成为确定性取值。 向所有的epoch对应的所有acceptor提交取值。 如果收到半数以上成功，则返回。 否则，则返回error（被新的epoch抢占或者accepor故障）。 如果说var的取值存在，那么就要认同最大accepted_epoch对应的取值f，努力使成为确定性取值。 如果f已经出现了半数以上，则说明f已经是确定性取值，直接返回 如果说f只是出现了半数以下，那此时f可能是确定性取值，也可能不是，不管怎样，此时的epoch都会认同这个f，向所有的acceptor提交这个取值 ​ 我们想象一下，当proposer1提交的被acceptor接受，epoch1形成了确定性取值，紧接着下一个就是proposer2的提交的epoch2，proposer2肯定是可以获取到至少一个确定性取值，并且在epoch2获取到的所有取值里面，epoch1是一个最大的epoch，所以epoch2会认可epoch1提交的取值f，以此类推，后面的epoch也都会认可epoch1提交的取值f，不会进行更改。 ​ 画图讲解下第一阶段 ​ proposer1向所有的acceptor发出prepare请求，并且返回var的当前取值，全部为空。 ​ proposer1发现所有的取值为空，这个时候proposer1就可以选定自己的取值V1为确定性取值向所有的acceptor发送accept请求。proposer1进入第二阶段，向第一个acceptor发出请求。 ​ 在这个时候，P2进入第一阶段，向acceptor发出prepare请求。使用epoch2企图抢占访问权。P2向前两个acceptor发出了prepare请求。 ​ epoch1的访问权直接失效，epoch2获取到了访问权，acceptor向P2返回了节点当前保存的结果。P2进入了第二阶段，在P2发起accept请求之前，P1继续向另外的两个节点发送accept请求。 ​ 在这个情况中，第二个acceptor会拒绝P1的请求，因为epoch1访问权失效，第三个acceptor接受了V1这个取值并且返回成功。这个时候，epoch1已经形成了确定性取值V1，也是P1的取值V1。 ​ 这个时候，P2开始在第二阶段向acceptor发起accept请求。它选定取值里面最大的epoch的取值，也就是epoch1提交的V1，然后开始让acceptor接受V1。 ​ 所以在这种情况下，我们可以看到P2也形成了确定性取值V1，因为它是直接选择epoch1提交的取值V1，所以即使epoch1和epoch2都形成了确定性取值，这两个取值不会发生冲突。 ​ 我们可以假设，P1的后两个accept请求没有成功发出去，那么epoch1无法形成确定性取值，epoch2也会照样选择V1来形成确定性取值，也不会形成冲突。 Paxos——总结Paxos算法的核心思想 在抢占式访问权的基础上引入多个acceptor 保证一个epoch，只有proposer运行，proposer按照epoch递增的顺序依次运行。 新epoch的proposer采用“后者认同前者”的思路运行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取 值，不会破坏。 Paxos算法可以满足容错性要求 半数以下acceptor出现故障时，存活的acceptor仍然了可以生成var的确定性取值。 一旦var取值被确定，即使出现了半数以下acceptor故障，该取值也可以被获取，并且不再更改。 Paxos算法的livelock问题 新轮次的抢占会让旧轮次停止运行，如果每一轮次在第二阶段成功之前都被新一轮次抢占，则 导致活锁，怎么解决呢？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:4","series":null,"tags":[],"title":"Paxos算法学习","uri":"/paxos-algo/#propose的两阶段实现"},{"categories":[],"content":"Paxos Paxos在方案2的基础上引入多acceptor。 acceptor的实现保持不变，仍然采用“喜新厌旧”的原则运行。 Paxos采用了少数acceptor服从多数的思路（少数服从多数）。 在方案2中，一旦某个epoch的取值f被系统里仅有的acceptor接受，那么我们就认为var的取值被确定了。那么在Paxos中，我们定义，一旦某epoch的取值f被半数以上acceptor接受，则认为此取值被确定为f，不再更改。 Acceptor的实现不变Propose的两阶段实现propose(var,V)第一阶段：选定epoch，获取epoch访问权和对应var的取值。 获取半数以上acceptor的访问权和对应的一组var取值。 因为半数以上和半数以上必然存在交集，那么就可以保证，一个epoch最多只会有一个proposer拿到访问权，进入第二阶段运行。 propose(var,V)第二阶段：采用后者认同前者的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值， 不会破坏。 如果proposer在第一阶段获取到的var取值都为空，则旧epoch无法形成确定性取值。此时努力使成为确定性取值。 向所有的epoch对应的所有acceptor提交取值。 如果收到半数以上成功，则返回。 否则，则返回error（被新的epoch抢占或者accepor故障）。 如果说var的取值存在，那么就要认同最大accepted_epoch对应的取值f，努力使成为确定性取值。 如果f已经出现了半数以上，则说明f已经是确定性取值，直接返回 如果说f只是出现了半数以下，那此时f可能是确定性取值，也可能不是，不管怎样，此时的epoch都会认同这个f，向所有的acceptor提交这个取值 ​ 我们想象一下，当proposer1提交的被acceptor接受，epoch1形成了确定性取值，紧接着下一个就是proposer2的提交的epoch2，proposer2肯定是可以获取到至少一个确定性取值，并且在epoch2获取到的所有取值里面，epoch1是一个最大的epoch，所以epoch2会认可epoch1提交的取值f，以此类推，后面的epoch也都会认可epoch1提交的取值f，不会进行更改。 ​ 画图讲解下第一阶段 ​ proposer1向所有的acceptor发出prepare请求，并且返回var的当前取值，全部为空。 ​ proposer1发现所有的取值为空，这个时候proposer1就可以选定自己的取值V1为确定性取值向所有的acceptor发送accept请求。proposer1进入第二阶段，向第一个acceptor发出请求。 ​ 在这个时候，P2进入第一阶段，向acceptor发出prepare请求。使用epoch2企图抢占访问权。P2向前两个acceptor发出了prepare请求。 ​ epoch1的访问权直接失效，epoch2获取到了访问权，acceptor向P2返回了节点当前保存的结果。P2进入了第二阶段，在P2发起accept请求之前，P1继续向另外的两个节点发送accept请求。 ​ 在这个情况中，第二个acceptor会拒绝P1的请求，因为epoch1访问权失效，第三个acceptor接受了V1这个取值并且返回成功。这个时候，epoch1已经形成了确定性取值V1，也是P1的取值V1。 ​ 这个时候，P2开始在第二阶段向acceptor发起accept请求。它选定取值里面最大的epoch的取值，也就是epoch1提交的V1，然后开始让acceptor接受V1。 ​ 所以在这种情况下，我们可以看到P2也形成了确定性取值V1，因为它是直接选择epoch1提交的取值V1，所以即使epoch1和epoch2都形成了确定性取值，这两个取值不会发生冲突。 ​ 我们可以假设，P1的后两个accept请求没有成功发出去，那么epoch1无法形成确定性取值，epoch2也会照样选择V1来形成确定性取值，也不会形成冲突。 Paxos——总结Paxos算法的核心思想 在抢占式访问权的基础上引入多个acceptor 保证一个epoch，只有proposer运行，proposer按照epoch递增的顺序依次运行。 新epoch的proposer采用“后者认同前者”的思路运行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取 值，不会破坏。 Paxos算法可以满足容错性要求 半数以下acceptor出现故障时，存活的acceptor仍然了可以生成var的确定性取值。 一旦var取值被确定，即使出现了半数以下acceptor故障，该取值也可以被获取，并且不再更改。 Paxos算法的livelock问题 新轮次的抢占会让旧轮次停止运行，如果每一轮次在第二阶段成功之前都被新一轮次抢占，则 导致活锁，怎么解决呢？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:4","series":null,"tags":[],"title":"Paxos算法学习","uri":"/paxos-algo/#paxos总结"},{"categories":[],"content":"Paxos Paxos在方案2的基础上引入多acceptor。 acceptor的实现保持不变，仍然采用“喜新厌旧”的原则运行。 Paxos采用了少数acceptor服从多数的思路（少数服从多数）。 在方案2中，一旦某个epoch的取值f被系统里仅有的acceptor接受，那么我们就认为var的取值被确定了。那么在Paxos中，我们定义，一旦某epoch的取值f被半数以上acceptor接受，则认为此取值被确定为f，不再更改。 Acceptor的实现不变Propose的两阶段实现propose(var,V)第一阶段：选定epoch，获取epoch访问权和对应var的取值。 获取半数以上acceptor的访问权和对应的一组var取值。 因为半数以上和半数以上必然存在交集，那么就可以保证，一个epoch最多只会有一个proposer拿到访问权，进入第二阶段运行。 propose(var,V)第二阶段：采用后者认同前者的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值， 不会破坏。 如果proposer在第一阶段获取到的var取值都为空，则旧epoch无法形成确定性取值。此时努力使成为确定性取值。 向所有的epoch对应的所有acceptor提交取值。 如果收到半数以上成功，则返回。 否则，则返回error（被新的epoch抢占或者accepor故障）。 如果说var的取值存在，那么就要认同最大accepted_epoch对应的取值f，努力使成为确定性取值。 如果f已经出现了半数以上，则说明f已经是确定性取值，直接返回 如果说f只是出现了半数以下，那此时f可能是确定性取值，也可能不是，不管怎样，此时的epoch都会认同这个f，向所有的acceptor提交这个取值 ​ 我们想象一下，当proposer1提交的被acceptor接受，epoch1形成了确定性取值，紧接着下一个就是proposer2的提交的epoch2，proposer2肯定是可以获取到至少一个确定性取值，并且在epoch2获取到的所有取值里面，epoch1是一个最大的epoch，所以epoch2会认可epoch1提交的取值f，以此类推，后面的epoch也都会认可epoch1提交的取值f，不会进行更改。 ​ 画图讲解下第一阶段 ​ proposer1向所有的acceptor发出prepare请求，并且返回var的当前取值，全部为空。 ​ proposer1发现所有的取值为空，这个时候proposer1就可以选定自己的取值V1为确定性取值向所有的acceptor发送accept请求。proposer1进入第二阶段，向第一个acceptor发出请求。 ​ 在这个时候，P2进入第一阶段，向acceptor发出prepare请求。使用epoch2企图抢占访问权。P2向前两个acceptor发出了prepare请求。 ​ epoch1的访问权直接失效，epoch2获取到了访问权，acceptor向P2返回了节点当前保存的结果。P2进入了第二阶段，在P2发起accept请求之前，P1继续向另外的两个节点发送accept请求。 ​ 在这个情况中，第二个acceptor会拒绝P1的请求，因为epoch1访问权失效，第三个acceptor接受了V1这个取值并且返回成功。这个时候，epoch1已经形成了确定性取值V1，也是P1的取值V1。 ​ 这个时候，P2开始在第二阶段向acceptor发起accept请求。它选定取值里面最大的epoch的取值，也就是epoch1提交的V1，然后开始让acceptor接受V1。 ​ 所以在这种情况下，我们可以看到P2也形成了确定性取值V1，因为它是直接选择epoch1提交的取值V1，所以即使epoch1和epoch2都形成了确定性取值，这两个取值不会发生冲突。 ​ 我们可以假设，P1的后两个accept请求没有成功发出去，那么epoch1无法形成确定性取值，epoch2也会照样选择V1来形成确定性取值，也不会形成冲突。 Paxos——总结Paxos算法的核心思想 在抢占式访问权的基础上引入多个acceptor 保证一个epoch，只有proposer运行，proposer按照epoch递增的顺序依次运行。 新epoch的proposer采用“后者认同前者”的思路运行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取 值，不会破坏。 Paxos算法可以满足容错性要求 半数以下acceptor出现故障时，存活的acceptor仍然了可以生成var的确定性取值。 一旦var取值被确定，即使出现了半数以下acceptor故障，该取值也可以被获取，并且不再更改。 Paxos算法的livelock问题 新轮次的抢占会让旧轮次停止运行，如果每一轮次在第二阶段成功之前都被新一轮次抢占，则 导致活锁，怎么解决呢？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:4","series":null,"tags":[],"title":"Paxos算法学习","uri":"/paxos-algo/#paxos算法的核心思想"},{"categories":[],"content":"Paxos Paxos在方案2的基础上引入多acceptor。 acceptor的实现保持不变，仍然采用“喜新厌旧”的原则运行。 Paxos采用了少数acceptor服从多数的思路（少数服从多数）。 在方案2中，一旦某个epoch的取值f被系统里仅有的acceptor接受，那么我们就认为var的取值被确定了。那么在Paxos中，我们定义，一旦某epoch的取值f被半数以上acceptor接受，则认为此取值被确定为f，不再更改。 Acceptor的实现不变Propose的两阶段实现propose(var,V)第一阶段：选定epoch，获取epoch访问权和对应var的取值。 获取半数以上acceptor的访问权和对应的一组var取值。 因为半数以上和半数以上必然存在交集，那么就可以保证，一个epoch最多只会有一个proposer拿到访问权，进入第二阶段运行。 propose(var,V)第二阶段：采用后者认同前者的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值， 不会破坏。 如果proposer在第一阶段获取到的var取值都为空，则旧epoch无法形成确定性取值。此时努力使成为确定性取值。 向所有的epoch对应的所有acceptor提交取值。 如果收到半数以上成功，则返回。 否则，则返回error（被新的epoch抢占或者accepor故障）。 如果说var的取值存在，那么就要认同最大accepted_epoch对应的取值f，努力使成为确定性取值。 如果f已经出现了半数以上，则说明f已经是确定性取值，直接返回 如果说f只是出现了半数以下，那此时f可能是确定性取值，也可能不是，不管怎样，此时的epoch都会认同这个f，向所有的acceptor提交这个取值 ​ 我们想象一下，当proposer1提交的被acceptor接受，epoch1形成了确定性取值，紧接着下一个就是proposer2的提交的epoch2，proposer2肯定是可以获取到至少一个确定性取值，并且在epoch2获取到的所有取值里面，epoch1是一个最大的epoch，所以epoch2会认可epoch1提交的取值f，以此类推，后面的epoch也都会认可epoch1提交的取值f，不会进行更改。 ​ 画图讲解下第一阶段 ​ proposer1向所有的acceptor发出prepare请求，并且返回var的当前取值，全部为空。 ​ proposer1发现所有的取值为空，这个时候proposer1就可以选定自己的取值V1为确定性取值向所有的acceptor发送accept请求。proposer1进入第二阶段，向第一个acceptor发出请求。 ​ 在这个时候，P2进入第一阶段，向acceptor发出prepare请求。使用epoch2企图抢占访问权。P2向前两个acceptor发出了prepare请求。 ​ epoch1的访问权直接失效，epoch2获取到了访问权，acceptor向P2返回了节点当前保存的结果。P2进入了第二阶段，在P2发起accept请求之前，P1继续向另外的两个节点发送accept请求。 ​ 在这个情况中，第二个acceptor会拒绝P1的请求，因为epoch1访问权失效，第三个acceptor接受了V1这个取值并且返回成功。这个时候，epoch1已经形成了确定性取值V1，也是P1的取值V1。 ​ 这个时候，P2开始在第二阶段向acceptor发起accept请求。它选定取值里面最大的epoch的取值，也就是epoch1提交的V1，然后开始让acceptor接受V1。 ​ 所以在这种情况下，我们可以看到P2也形成了确定性取值V1，因为它是直接选择epoch1提交的取值V1，所以即使epoch1和epoch2都形成了确定性取值，这两个取值不会发生冲突。 ​ 我们可以假设，P1的后两个accept请求没有成功发出去，那么epoch1无法形成确定性取值，epoch2也会照样选择V1来形成确定性取值，也不会形成冲突。 Paxos——总结Paxos算法的核心思想 在抢占式访问权的基础上引入多个acceptor 保证一个epoch，只有proposer运行，proposer按照epoch递增的顺序依次运行。 新epoch的proposer采用“后者认同前者”的思路运行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取 值，不会破坏。 Paxos算法可以满足容错性要求 半数以下acceptor出现故障时，存活的acceptor仍然了可以生成var的确定性取值。 一旦var取值被确定，即使出现了半数以下acceptor故障，该取值也可以被获取，并且不再更改。 Paxos算法的livelock问题 新轮次的抢占会让旧轮次停止运行，如果每一轮次在第二阶段成功之前都被新一轮次抢占，则 导致活锁，怎么解决呢？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:4","series":null,"tags":[],"title":"Paxos算法学习","uri":"/paxos-algo/#paxos算法可以满足容错性要求"},{"categories":[],"content":"Paxos Paxos在方案2的基础上引入多acceptor。 acceptor的实现保持不变，仍然采用“喜新厌旧”的原则运行。 Paxos采用了少数acceptor服从多数的思路（少数服从多数）。 在方案2中，一旦某个epoch的取值f被系统里仅有的acceptor接受，那么我们就认为var的取值被确定了。那么在Paxos中，我们定义，一旦某epoch的取值f被半数以上acceptor接受，则认为此取值被确定为f，不再更改。 Acceptor的实现不变Propose的两阶段实现propose(var,V)第一阶段：选定epoch，获取epoch访问权和对应var的取值。 获取半数以上acceptor的访问权和对应的一组var取值。 因为半数以上和半数以上必然存在交集，那么就可以保证，一个epoch最多只会有一个proposer拿到访问权，进入第二阶段运行。 propose(var,V)第二阶段：采用后者认同前者的原则执行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取值， 不会破坏。 如果proposer在第一阶段获取到的var取值都为空，则旧epoch无法形成确定性取值。此时努力使成为确定性取值。 向所有的epoch对应的所有acceptor提交取值。 如果收到半数以上成功，则返回。 否则，则返回error（被新的epoch抢占或者accepor故障）。 如果说var的取值存在，那么就要认同最大accepted_epoch对应的取值f，努力使成为确定性取值。 如果f已经出现了半数以上，则说明f已经是确定性取值，直接返回 如果说f只是出现了半数以下，那此时f可能是确定性取值，也可能不是，不管怎样，此时的epoch都会认同这个f，向所有的acceptor提交这个取值 ​ 我们想象一下，当proposer1提交的被acceptor接受，epoch1形成了确定性取值，紧接着下一个就是proposer2的提交的epoch2，proposer2肯定是可以获取到至少一个确定性取值，并且在epoch2获取到的所有取值里面，epoch1是一个最大的epoch，所以epoch2会认可epoch1提交的取值f，以此类推，后面的epoch也都会认可epoch1提交的取值f，不会进行更改。 ​ 画图讲解下第一阶段 ​ proposer1向所有的acceptor发出prepare请求，并且返回var的当前取值，全部为空。 ​ proposer1发现所有的取值为空，这个时候proposer1就可以选定自己的取值V1为确定性取值向所有的acceptor发送accept请求。proposer1进入第二阶段，向第一个acceptor发出请求。 ​ 在这个时候，P2进入第一阶段，向acceptor发出prepare请求。使用epoch2企图抢占访问权。P2向前两个acceptor发出了prepare请求。 ​ epoch1的访问权直接失效，epoch2获取到了访问权，acceptor向P2返回了节点当前保存的结果。P2进入了第二阶段，在P2发起accept请求之前，P1继续向另外的两个节点发送accept请求。 ​ 在这个情况中，第二个acceptor会拒绝P1的请求，因为epoch1访问权失效，第三个acceptor接受了V1这个取值并且返回成功。这个时候，epoch1已经形成了确定性取值V1，也是P1的取值V1。 ​ 这个时候，P2开始在第二阶段向acceptor发起accept请求。它选定取值里面最大的epoch的取值，也就是epoch1提交的V1，然后开始让acceptor接受V1。 ​ 所以在这种情况下，我们可以看到P2也形成了确定性取值V1，因为它是直接选择epoch1提交的取值V1，所以即使epoch1和epoch2都形成了确定性取值，这两个取值不会发生冲突。 ​ 我们可以假设，P1的后两个accept请求没有成功发出去，那么epoch1无法形成确定性取值，epoch2也会照样选择V1来形成确定性取值，也不会形成冲突。 Paxos——总结Paxos算法的核心思想 在抢占式访问权的基础上引入多个acceptor 保证一个epoch，只有proposer运行，proposer按照epoch递增的顺序依次运行。 新epoch的proposer采用“后者认同前者”的思路运行。 在肯定旧epoch无法生成确定性取值时，新的epoch才会提交自己的value。 一旦旧epoch形成确定性取值，新的epoch肯定可以获取到此取值，并且会认同此取 值，不会破坏。 Paxos算法可以满足容错性要求 半数以下acceptor出现故障时，存活的acceptor仍然了可以生成var的确定性取值。 一旦var取值被确定，即使出现了半数以下acceptor故障，该取值也可以被获取，并且不再更改。 Paxos算法的livelock问题 新轮次的抢占会让旧轮次停止运行，如果每一轮次在第二阶段成功之前都被新一轮次抢占，则 导致活锁，怎么解决呢？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:4","series":null,"tags":[],"title":"Paxos算法学习","uri":"/paxos-algo/#paxos算法的livelock问题"},{"categories":[],"content":"思考题 在什么情况可以认为var的取值被确定，不再更改？ Paxos的两个阶段分别在做什么？ 一个epoch是否会有多个proposer进入第二阶段？ 在什么情况下，proposer可以将var的取值确定为自己提交的取值呢？ 在第二阶段，如果获取的var取值都为空，为什么可以保证旧epoch无法形成确定性取值？ 新epoch抢占成功之后，旧epoch的proposer将如何运行？ 如何保证新的epoch不会破坏已经达成的确定性取值？ 为什么在第二阶段存在var取值时，只需要考虑accepted_epoch最大的取值f？ 在形成确定性取值之后，出现了任意半数以下acceptor故障，为何确定性取值不会被更改？ 如果proposer在运行过程中，任意半数以下的acceptor出现故障，此时将如何运行？ 正在运行的proposer和任意半数以下acceptor都出现故障时，var的取值可能是什么情况？为 何之后新的proposer可以形成确定性取值？ ","date":"2021-09-14","objectID":"/paxos-algo/:1:5","series":null,"tags":[],"title":"Paxos算法学习","uri":"/paxos-algo/#思考题"},{"categories":[],"content":"参考资料分布式系列文章——Paxos算法原理与推导 ","date":"2021-09-14","objectID":"/paxos-algo/:1:6","series":null,"tags":[],"title":"Paxos算法学习","uri":"/paxos-algo/#参考资料"},{"categories":[],"content":"最近新入手了一部IPad Air 4，想着为了不让其成为爱奇艺播放器，发挥生产力功效，于是搜罗资料，查找能否在iPad上实现写代码的方案。最终找到两种方法： 利用SSH连接软件，在远程服务器上利用Vim、NEOVim等编辑器软件进行编码。 首先找到的是一款名为termius的软件，下载免费，使用需内购，可是我在下载下来之后进入软件始终都无法创建账号，也就无法进行内购使用了，放弃。网上看使用过的大佬说，并不推荐这种方式，因为编码的效率太低，而且有时切出软件一小段时间后，SSH连接会断开，体验非常差。 利用code-server部署一个网页版的VScode，即“云IDE”，这样工作区在不同的设备上都能同步，而且切出后不会掉线。将网页作为WebApp添加到主屏幕上后的体验也接近于原生App(前提是服务器的带宽不能太低)。 ","date":"2021-09-10","objectID":"/code-server/:0:0","series":null,"tags":[],"title":"云IDE：code-server安装使用","uri":"/code-server/#"},{"categories":[],"content":"环境准备云服务器，规格 2C4G： $ cat /etc/redhat-release CentOS Linux release 7.6.1810 (Core) ","date":"2021-09-10","objectID":"/code-server/:0:1","series":null,"tags":[],"title":"云IDE：code-server安装使用","uri":"/code-server/#环境准备"},{"categories":[],"content":"下载资源下载code-server在github上的安装包： $ wget https://github.com/cdr/code-server/releases/download/v3.11.0/code-server-3.11.0-linux-amd64.tar.gz # 解压安装包 $ tar -zxf code-server-3.11.0-linux-amd64.tar.gz \u0026\u0026 cd code-server-3.11.0-linux-amd64 # ","date":"2021-09-10","objectID":"/code-server/:0:2","series":null,"tags":[],"title":"云IDE：code-server安装使用","uri":"/code-server/#下载资源"},{"categories":[],"content":"启动设置登录web服务的密码，code-server要求以环境变量$PASSWORD为登录密码： $ export PASSWORD=\"123456\" 运行code-server $ ./code-server --port 8080 --host 0.0.0.0 --auth password 8080是端口,可以自己修改,注意不要与其他应用冲突。0.0.0.0是代表可以被所有ip访问. $ ./code-server --port 8080 --host 0.0.0.0 --auth password ***** Please use the script in bin/code-server instead! ***** This script will soon be removed! ***** See the release notes at https://github.com/cdr/code-server/releases/tag/v3.4.0 [2021-09-10T07:39:08.191Z] info code-server 3.11.0 4e8cd09ef0412dfc7b148b7639a692e20e4fd6dd [2021-09-10T07:39:08.192Z] info Using user-data-dir ~/.local/share/code-server [2021-09-10T07:39:08.206Z] info Using config file ~/.config/code-server/config.yaml [2021-09-10T07:39:08.206Z] info HTTP server listening on http://0.0.0.0:8080 [2021-09-10T07:39:08.206Z] info - Authentication is enabled [2021-09-10T07:39:08.206Z] info - Using password from ~/.config/code-server/config.yaml [2021-09-10T07:39:08.206Z] info - Not serving HTTPS 如图所示就是已经完成配置了。 ","date":"2021-09-10","objectID":"/code-server/:0:3","series":null,"tags":[],"title":"云IDE：code-server安装使用","uri":"/code-server/#启动"},{"categories":[],"content":"访问在浏览器中输入服务器ip+端口号：127.0.0.1:8080，出现登录页面，输入刚才所设置的密码123456登录，即可进入Web IDE ,愉快的进行coding吧~ ","date":"2021-09-10","objectID":"/code-server/:0:4","series":null,"tags":[],"title":"云IDE：code-server安装使用","uri":"/code-server/#访问"},{"categories":[],"content":"添加插件 LeetCode（力扣） 在vs-code中扩展力扣，可以实现在vs-code中答题了，方便快捷。 Thief-Book（一款摸鱼插件） 可以在vs-code底部状态栏浏览TXT文本，懂得都懂~ Markdown All in one(预览Markdown) asciiflow.cn可视化纯文本流程图绘制工具 在写Markdown流程图时，在也不用担心图片存哪的问题了，纯文本格式的流程图，可以直接插入Markdown的代码块中展示。 Go Python 在github上还有非常多好玩有用的优秀插件，可以自行去探索，最好能做出一款自己写的插件。 ","date":"2021-09-10","objectID":"/code-server/:0:5","series":null,"tags":[],"title":"云IDE：code-server安装使用","uri":"/code-server/#添加插件"},{"categories":[],"content":"2021-12-01更新","date":"2021-09-10","objectID":"/code-server/:0:6","series":null,"tags":[],"title":"云IDE：code-server安装使用","uri":"/code-server/#2021-12-01更新"},{"categories":[],"content":"踩坑坑点1登录密码如果使用环境变量，记得一定要使用大写的PASSWORD！！ 原因：因启动参数中的password是小写，导致我一直错误的认为环境变量应该跟它保持一致，也是小写。 ./code-server --port 8080 --host 0.0.0.0 --auth password 而当我使用命令export password=123456添加了小写的password的环境变量去登录界面登录时又提示密码错误，且登录界面提示密码在~/.config/code-server/config.yaml中，于是我按照提示复制yaml文件中的密码成功登录了。 此时我还没意识到环境变量password其实是没有生效的，然后又去改了yaml中的密码为$password环境变量的值，导致我一直以为环境变量是被使用的。 $ cat ~/.config/code-server/config.yaml bind-addr: 0.0.0.0:8080 auth: password password: 123456 cert: false 坑点2后面想到是否可以用域名+nginx反向代理的方式访问会更加便捷呢？步骤如下： 1、在服务器上安装nginx。 注意：需要安装ssl模块./configure --prefix=/usr/local/nginx --with-http_ssl_module --with-http_v2_module 2、在阿里云申请免费证书并下载nginx版本的证书到本地。 3、上传证书到服务器上，并解压到到/usr/local/nginx/conf/cert/下。 4、在nginx.conf的配置如下： server { listen 443; server_name code.xxx.com; access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; ssl on; ssl_certificate cert/xxx.pem; ssl_certificate_key cert/xxx.com.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; #表示使用的加密套件的类型。 ssl_protocols TLSv1.1 TLSv1.2 TLSv1.3; #表示使用的TLS协议的类型。 ssl_prefer_server_ciphers on; proxy_set_header Host $host; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection upgrade; proxy_set_header Accept-Encoding gzip; location / { proxy_pass http://localhost:8080; } } server { listen 80; server_name localhost; rewrite ^(.*)$ https://$host$1 permanent; # http重写到https } 踩坑点：最开始由于server模块中没有配置proxy_set_header请求头，导致到了登录界面输入密码，却无法跳转进入vs-code界面。后面查看coder官方文档发现，code-server要求请求需使用websocket协议才能进行通信。官网原文:https://coder.com/docs/code-server/latest/guide#using-lets-encrypt-with-nginx To work properly, your environment should have WebSockets enabled, which code-server uses to communicate between the browser and server.(为了正常工作，您的环境应该启用 WebSockets，代码服务器使用它在浏览器和服务器之间进行通信。) ","date":"2021-09-10","objectID":"/code-server/:0:7","series":null,"tags":[],"title":"云IDE：code-server安装使用","uri":"/code-server/#踩坑"},{"categories":[],"content":"踩坑坑点1登录密码如果使用环境变量，记得一定要使用大写的PASSWORD！！ 原因：因启动参数中的password是小写，导致我一直错误的认为环境变量应该跟它保持一致，也是小写。 ./code-server --port 8080 --host 0.0.0.0 --auth password 而当我使用命令export password=123456添加了小写的password的环境变量去登录界面登录时又提示密码错误，且登录界面提示密码在~/.config/code-server/config.yaml中，于是我按照提示复制yaml文件中的密码成功登录了。 此时我还没意识到环境变量password其实是没有生效的，然后又去改了yaml中的密码为$password环境变量的值，导致我一直以为环境变量是被使用的。 $ cat ~/.config/code-server/config.yaml bind-addr: 0.0.0.0:8080 auth: password password: 123456 cert: false 坑点2后面想到是否可以用域名+nginx反向代理的方式访问会更加便捷呢？步骤如下： 1、在服务器上安装nginx。 注意：需要安装ssl模块./configure --prefix=/usr/local/nginx --with-http_ssl_module --with-http_v2_module 2、在阿里云申请免费证书并下载nginx版本的证书到本地。 3、上传证书到服务器上，并解压到到/usr/local/nginx/conf/cert/下。 4、在nginx.conf的配置如下： server { listen 443; server_name code.xxx.com; access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; ssl on; ssl_certificate cert/xxx.pem; ssl_certificate_key cert/xxx.com.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; #表示使用的加密套件的类型。 ssl_protocols TLSv1.1 TLSv1.2 TLSv1.3; #表示使用的TLS协议的类型。 ssl_prefer_server_ciphers on; proxy_set_header Host $host; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection upgrade; proxy_set_header Accept-Encoding gzip; location / { proxy_pass http://localhost:8080; } } server { listen 80; server_name localhost; rewrite ^(.*)$ https://$host$1 permanent; # http重写到https } 踩坑点：最开始由于server模块中没有配置proxy_set_header请求头，导致到了登录界面输入密码，却无法跳转进入vs-code界面。后面查看coder官方文档发现，code-server要求请求需使用websocket协议才能进行通信。官网原文:https://coder.com/docs/code-server/latest/guide#using-lets-encrypt-with-nginx To work properly, your environment should have WebSockets enabled, which code-server uses to communicate between the browser and server.(为了正常工作，您的环境应该启用 WebSockets，代码服务器使用它在浏览器和服务器之间进行通信。) ","date":"2021-09-10","objectID":"/code-server/:0:7","series":null,"tags":[],"title":"云IDE：code-server安装使用","uri":"/code-server/#坑点1"},{"categories":[],"content":"踩坑坑点1登录密码如果使用环境变量，记得一定要使用大写的PASSWORD！！ 原因：因启动参数中的password是小写，导致我一直错误的认为环境变量应该跟它保持一致，也是小写。 ./code-server --port 8080 --host 0.0.0.0 --auth password 而当我使用命令export password=123456添加了小写的password的环境变量去登录界面登录时又提示密码错误，且登录界面提示密码在~/.config/code-server/config.yaml中，于是我按照提示复制yaml文件中的密码成功登录了。 此时我还没意识到环境变量password其实是没有生效的，然后又去改了yaml中的密码为$password环境变量的值，导致我一直以为环境变量是被使用的。 $ cat ~/.config/code-server/config.yaml bind-addr: 0.0.0.0:8080 auth: password password: 123456 cert: false 坑点2后面想到是否可以用域名+nginx反向代理的方式访问会更加便捷呢？步骤如下： 1、在服务器上安装nginx。 注意：需要安装ssl模块./configure --prefix=/usr/local/nginx --with-http_ssl_module --with-http_v2_module 2、在阿里云申请免费证书并下载nginx版本的证书到本地。 3、上传证书到服务器上，并解压到到/usr/local/nginx/conf/cert/下。 4、在nginx.conf的配置如下： server { listen 443; server_name code.xxx.com; access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; ssl on; ssl_certificate cert/xxx.pem; ssl_certificate_key cert/xxx.com.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; #表示使用的加密套件的类型。 ssl_protocols TLSv1.1 TLSv1.2 TLSv1.3; #表示使用的TLS协议的类型。 ssl_prefer_server_ciphers on; proxy_set_header Host $host; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection upgrade; proxy_set_header Accept-Encoding gzip; location / { proxy_pass http://localhost:8080; } } server { listen 80; server_name localhost; rewrite ^(.*)$ https://$host$1 permanent; # http重写到https } 踩坑点：最开始由于server模块中没有配置proxy_set_header请求头，导致到了登录界面输入密码，却无法跳转进入vs-code界面。后面查看coder官方文档发现，code-server要求请求需使用websocket协议才能进行通信。官网原文:https://coder.com/docs/code-server/latest/guide#using-lets-encrypt-with-nginx To work properly, your environment should have WebSockets enabled, which code-server uses to communicate between the browser and server.(为了正常工作，您的环境应该启用 WebSockets，代码服务器使用它在浏览器和服务器之间进行通信。) ","date":"2021-09-10","objectID":"/code-server/:0:7","series":null,"tags":[],"title":"云IDE：code-server安装使用","uri":"/code-server/#坑点2"},{"categories":["随笔"],"content":" 《娱乐至死》是美国批评家尼尔·波兹曼在1985年写成出版的，这本书主要阐述了在二十世纪后半叶美国文化中的重大变化也就是电视业的蓬勃发展和传统印刷业的没落所带来的诸多问题的批判和思考。 在传统印刷业，也就是所谓的“阐释时代”，信息的组织是具有逻辑和语境的，人们从中获得了思考和智慧。而随着电视的普及，进入电视时代的人们更愿意接受娱乐化的信息，而渐渐排斥原本具有严肃性的东西。一开始，很多严肃的新闻或者具有教育意义的节目，也都是通过电视来呈现给大众的，但久而久之，由于各种各样的原因，这些原本具有严肃性的东西等也都纷纷向娱乐靠拢。 似乎一切的内容都以娱乐的形式呈现，大量的信息充斥在人们的生活中，信息变得碎片化。虽然看似我们从电视中获取了很多新闻资讯、很多知识，但是这些信息是没有语境和逻辑的，我们并没有主动去思考或者说已经没有机会去思考这里面的真假，很多观点都是别人整理好后塞给我们的。 我们通过电视媒体，给自己制造了获取很多知识的假象，我们已经很少去真正思考信息的来源以及信息的真假，只是被动地接受，最后，看似收获了很多知识，实则一无所获。 进入互联网时代也是一样，我们心甘情愿的沦为娱乐的附庸，无脑的享受着各种各样的新闻、娱乐资讯，刷微博，刷抖音，刷b站，越来越偏向于不动大脑的开怀大笑，最后成为一个娱乐至死的物种。 读完这本书，我才后知后觉，过去做过的很多事情，譬如看了很多电影、书、纪录片，实际上我真正深入思考的有多少？就算是我爱看的历史纪录片，事实上更多时候我也是听听故事，并没有多少时刻去认真思考整个历史事件的起因、经过和结局对于历史的推进作用。 当然，如果生活中只存在严肃性的东西，禁止一切娱乐，那也太矫枉过正了，显得生活太枯燥。我们不应该禁止娱乐，更正确的方式，我想应该是减少娱乐的时间，只在碎片化的时间段内浏览一些娱乐资讯，更多大块的时间用来读书和思考，真正提高个人整体素质和境界。 ","date":"2021-06-17","objectID":"/amusing-to-death/:0:0","series":null,"tags":[],"title":"娱乐至死","uri":"/amusing-to-death/#"},{"categories":[],"content":"添加评论系统启用评论系统utterances 在hugo的配置文件（config.toml）中启用utterances，打开config.toml，添加如下： # Utterances comment 评论系统设置 (https://utteranc.es/) [params.page.comment.utterances] enable = true # owner/repo repo = \"YourUsername/YourUsername.github.io\" ##自己的github仓库地址 issueTerm = \"pathname\" label = \"\" lightTheme = \"github-light\" darkTheme = \"github-dark\" repo的格式为：github用户名/创建的仓库名 github上安装 utterances 首先必须在 github 上进行安装 utterances，访问 utterances应用程序 然后点击 Install 按钮进行安装。 在这里可以选择可以关联的存储库，可以选择我们所拥有的库(也包括未来建立的库)或者某一个仓库，这里只选择某一个需要进行评论的库，这样比较好。 安装完成即可，随后访问 utterances应用程序 就不再是安装而是是执行配置项目。 此时服务端配置已经完成，接着访问博客测试下评论。 ","date":"2021-06-04","objectID":"/theme-seo/:0:1","series":null,"tags":[],"title":"主题优化-添加评论系统和内置搜索","uri":"/theme-seo/#添加评论系统"},{"categories":[],"content":"添加评论系统启用评论系统utterances 在hugo的配置文件（config.toml）中启用utterances，打开config.toml，添加如下： # Utterances comment 评论系统设置 (https://utteranc.es/) [params.page.comment.utterances] enable = true # owner/repo repo = \"YourUsername/YourUsername.github.io\" ##自己的github仓库地址 issueTerm = \"pathname\" label = \"\" lightTheme = \"github-light\" darkTheme = \"github-dark\" repo的格式为：github用户名/创建的仓库名 github上安装 utterances 首先必须在 github 上进行安装 utterances，访问 utterances应用程序 然后点击 Install 按钮进行安装。 在这里可以选择可以关联的存储库，可以选择我们所拥有的库(也包括未来建立的库)或者某一个仓库，这里只选择某一个需要进行评论的库，这样比较好。 安装完成即可，随后访问 utterances应用程序 就不再是安装而是是执行配置项目。 此时服务端配置已经完成，接着访问博客测试下评论。 ","date":"2021-06-04","objectID":"/theme-seo/:0:1","series":null,"tags":[],"title":"主题优化-添加评论系统和内置搜索","uri":"/theme-seo/#启用评论系统utterances"},{"categories":[],"content":"添加评论系统启用评论系统utterances 在hugo的配置文件（config.toml）中启用utterances，打开config.toml，添加如下： # Utterances comment 评论系统设置 (https://utteranc.es/) [params.page.comment.utterances] enable = true # owner/repo repo = \"YourUsername/YourUsername.github.io\" ##自己的github仓库地址 issueTerm = \"pathname\" label = \"\" lightTheme = \"github-light\" darkTheme = \"github-dark\" repo的格式为：github用户名/创建的仓库名 github上安装 utterances 首先必须在 github 上进行安装 utterances，访问 utterances应用程序 然后点击 Install 按钮进行安装。 在这里可以选择可以关联的存储库，可以选择我们所拥有的库(也包括未来建立的库)或者某一个仓库，这里只选择某一个需要进行评论的库，这样比较好。 安装完成即可，随后访问 utterances应用程序 就不再是安装而是是执行配置项目。 此时服务端配置已经完成，接着访问博客测试下评论。 ","date":"2021-06-04","objectID":"/theme-seo/:0:1","series":null,"tags":[],"title":"主题优化-添加评论系统和内置搜索","uri":"/theme-seo/#github上安装-utterances"},{"categories":[],"content":"内置搜索系统 原理：在执行push操作触发Actions编译站点代码到./public目录后，再执行生成索引文件操作，生成index.json到./public目录，并自动上传文章索引至algolia上，以实现站内搜索功能。 algolia实现内置搜索 前往官方网站https://www.algolia.com/ 使用 GitHub 或 Google 帐号登录。登录完成后根据提示信息填写一些基本的信息即可，注册完成后前往 Dashboard，我们可以发现 Algolia 会默认给我们生成一个 app。 选择 Indices，添加一个新的索引，index-name索引名自定义填写，并记录下来，后面网站配置要用到。再选择API keys，记录“Search-Only API Key”、“Admin API Key”两个秘钥。 由于我这里使用的主题是LoveIt，主题配置文件config.toml内置支持algolia插件，所以只需要在站点目录下的config.toml中，配置刚刚生成的索引和Search-Only API Key即可： [root@web-blog web]# vim config.toml [languages.zh-cn.params.search] enable = true # 搜索引擎的类型 (\"lunr\", \"algolia\") type = \"algolia\" # 文章内容最长索引长度 contentLength = 4000 # 搜索框的占位提示语 placeholder = \"\" # 最大结果数目 maxResultLength = 10 # 结果内容片段长度 snippetLength = 50 # 搜索结果中高亮部分的 HTML 标签 highlightTag = \"em\" # 是否在搜索索引中使用基于 baseURL 的绝对路径 absoluteURL = false [languages.zh-cn.params.search.algolia] index = \"yuepu-blog\" #索引名称 appID = \"SSC09FNCJM\" #应用ID searchKey = \"b42948e51daaa93df92381c8e2ac0f93\" #Search-Only API Key 利用GitHub Action配置自动上传索引文件编辑GitHub Action的CI/CD 配置文件gh-pages.yml，安装algoliasearch，并且使用Node.js配置秘钥文件： [root@web-blog web]# vim .github/workflows/gh-pages.yml ... - name: Use Node.js uses: actions/setup-node@v1 with: node-version: '15.x' - name: Push Argolia Index run: | npm install algoliasearch #安装algoliasearch插件 node push_argolia_index.js #使用我们配置的js文件 env: ALGOLIA_ADMIN_KEY: ${{ secrets.ALGOLIA_ADMIN_KEY }} 然后在站点根目录新建push_argolia_index.js文件，内容如下： /* 上传 algolia 索引文件 参考：https://www.algolia.com/doc/guides/getting-started/quick-start/tutorials/quick-start-with-the-api-client/javascript/?client=javascript */ // For the default version const algoliasearch = require('algoliasearch'); const appID = \"747LJ10EI7\" const indexName = \"ryan-space\" const adminKey = process.env.ALGOLIA_ADMIN_KEY const indexFile = \"./public/index.json\" const client = algoliasearch(appID, adminKey); const index = client.initIndex(indexName); const indexJson = require(indexFile); index.saveObjects(indexJson, { autoGenerateObjectIDIfNotExist: true }).then(({ objectIDs }) =\u003e { console.log(objectIDs); }); 这里我们一直没有用到的Admin API Key，需要在Setting -\u003e Secrets，新建仓库秘钥，名字取为ALGOLIA_ADMIN_KEY，以便Action 和 js中调用。 至此，配置就完成了。 ","date":"2021-06-04","objectID":"/theme-seo/:0:2","series":null,"tags":[],"title":"主题优化-添加评论系统和内置搜索","uri":"/theme-seo/#内置搜索系统"},{"categories":[],"content":"内置搜索系统 原理：在执行push操作触发Actions编译站点代码到./public目录后，再执行生成索引文件操作，生成index.json到./public目录，并自动上传文章索引至algolia上，以实现站内搜索功能。 algolia实现内置搜索 前往官方网站https://www.algolia.com/ 使用 GitHub 或 Google 帐号登录。登录完成后根据提示信息填写一些基本的信息即可，注册完成后前往 Dashboard，我们可以发现 Algolia 会默认给我们生成一个 app。 选择 Indices，添加一个新的索引，index-name索引名自定义填写，并记录下来，后面网站配置要用到。再选择API keys，记录“Search-Only API Key”、“Admin API Key”两个秘钥。 由于我这里使用的主题是LoveIt，主题配置文件config.toml内置支持algolia插件，所以只需要在站点目录下的config.toml中，配置刚刚生成的索引和Search-Only API Key即可： [root@web-blog web]# vim config.toml [languages.zh-cn.params.search] enable = true # 搜索引擎的类型 (\"lunr\", \"algolia\") type = \"algolia\" # 文章内容最长索引长度 contentLength = 4000 # 搜索框的占位提示语 placeholder = \"\" # 最大结果数目 maxResultLength = 10 # 结果内容片段长度 snippetLength = 50 # 搜索结果中高亮部分的 HTML 标签 highlightTag = \"em\" # 是否在搜索索引中使用基于 baseURL 的绝对路径 absoluteURL = false [languages.zh-cn.params.search.algolia] index = \"yuepu-blog\" #索引名称 appID = \"SSC09FNCJM\" #应用ID searchKey = \"b42948e51daaa93df92381c8e2ac0f93\" #Search-Only API Key 利用GitHub Action配置自动上传索引文件编辑GitHub Action的CI/CD 配置文件gh-pages.yml，安装algoliasearch，并且使用Node.js配置秘钥文件： [root@web-blog web]# vim .github/workflows/gh-pages.yml ... - name: Use Node.js uses: actions/setup-node@v1 with: node-version: '15.x' - name: Push Argolia Index run: | npm install algoliasearch #安装algoliasearch插件 node push_argolia_index.js #使用我们配置的js文件 env: ALGOLIA_ADMIN_KEY: ${{ secrets.ALGOLIA_ADMIN_KEY }} 然后在站点根目录新建push_argolia_index.js文件，内容如下： /* 上传 algolia 索引文件 参考：https://www.algolia.com/doc/guides/getting-started/quick-start/tutorials/quick-start-with-the-api-client/javascript/?client=javascript */ // For the default version const algoliasearch = require('algoliasearch'); const appID = \"747LJ10EI7\" const indexName = \"ryan-space\" const adminKey = process.env.ALGOLIA_ADMIN_KEY const indexFile = \"./public/index.json\" const client = algoliasearch(appID, adminKey); const index = client.initIndex(indexName); const indexJson = require(indexFile); index.saveObjects(indexJson, { autoGenerateObjectIDIfNotExist: true }).then(({ objectIDs }) = { console.log(objectIDs); }); 这里我们一直没有用到的Admin API Key，需要在Setting - Secrets，新建仓库秘钥，名字取为ALGOLIA_ADMIN_KEY，以便Action 和 js中调用。 至此，配置就完成了。 ","date":"2021-06-04","objectID":"/theme-seo/:0:2","series":null,"tags":[],"title":"主题优化-添加评论系统和内置搜索","uri":"/theme-seo/#algolia实现内置搜索"},{"categories":[],"content":"内置搜索系统 原理：在执行push操作触发Actions编译站点代码到./public目录后，再执行生成索引文件操作，生成index.json到./public目录，并自动上传文章索引至algolia上，以实现站内搜索功能。 algolia实现内置搜索 前往官方网站https://www.algolia.com/ 使用 GitHub 或 Google 帐号登录。登录完成后根据提示信息填写一些基本的信息即可，注册完成后前往 Dashboard，我们可以发现 Algolia 会默认给我们生成一个 app。 选择 Indices，添加一个新的索引，index-name索引名自定义填写，并记录下来，后面网站配置要用到。再选择API keys，记录“Search-Only API Key”、“Admin API Key”两个秘钥。 由于我这里使用的主题是LoveIt，主题配置文件config.toml内置支持algolia插件，所以只需要在站点目录下的config.toml中，配置刚刚生成的索引和Search-Only API Key即可： [root@web-blog web]# vim config.toml [languages.zh-cn.params.search] enable = true # 搜索引擎的类型 (\"lunr\", \"algolia\") type = \"algolia\" # 文章内容最长索引长度 contentLength = 4000 # 搜索框的占位提示语 placeholder = \"\" # 最大结果数目 maxResultLength = 10 # 结果内容片段长度 snippetLength = 50 # 搜索结果中高亮部分的 HTML 标签 highlightTag = \"em\" # 是否在搜索索引中使用基于 baseURL 的绝对路径 absoluteURL = false [languages.zh-cn.params.search.algolia] index = \"yuepu-blog\" #索引名称 appID = \"SSC09FNCJM\" #应用ID searchKey = \"b42948e51daaa93df92381c8e2ac0f93\" #Search-Only API Key 利用GitHub Action配置自动上传索引文件编辑GitHub Action的CI/CD 配置文件gh-pages.yml，安装algoliasearch，并且使用Node.js配置秘钥文件： [root@web-blog web]# vim .github/workflows/gh-pages.yml ... - name: Use Node.js uses: actions/setup-node@v1 with: node-version: '15.x' - name: Push Argolia Index run: | npm install algoliasearch #安装algoliasearch插件 node push_argolia_index.js #使用我们配置的js文件 env: ALGOLIA_ADMIN_KEY: ${{ secrets.ALGOLIA_ADMIN_KEY }} 然后在站点根目录新建push_argolia_index.js文件，内容如下： /* 上传 algolia 索引文件 参考：https://www.algolia.com/doc/guides/getting-started/quick-start/tutorials/quick-start-with-the-api-client/javascript/?client=javascript */ // For the default version const algoliasearch = require('algoliasearch'); const appID = \"747LJ10EI7\" const indexName = \"ryan-space\" const adminKey = process.env.ALGOLIA_ADMIN_KEY const indexFile = \"./public/index.json\" const client = algoliasearch(appID, adminKey); const index = client.initIndex(indexName); const indexJson = require(indexFile); index.saveObjects(indexJson, { autoGenerateObjectIDIfNotExist: true }).then(({ objectIDs }) = { console.log(objectIDs); }); 这里我们一直没有用到的Admin API Key，需要在Setting - Secrets，新建仓库秘钥，名字取为ALGOLIA_ADMIN_KEY，以便Action 和 js中调用。 至此，配置就完成了。 ","date":"2021-06-04","objectID":"/theme-seo/:0:2","series":null,"tags":[],"title":"主题优化-添加评论系统和内置搜索","uri":"/theme-seo/#利用github-action配置自动上传索引文件"},{"categories":[],"content":"参考 Hugo 博客使用 utterances 作为评论系统 algolia官网 上传 algolia 索引文件 参考：https://www.algolia.com/doc/guides/getting-started/quick-start/tutorials/quick-start-with-the-api-client/javascript/?client=javascript ","date":"2021-06-04","objectID":"/theme-seo/:0:3","series":null,"tags":[],"title":"主题优化-添加评论系统和内置搜索","uri":"/theme-seo/#参考"},{"categories":[],"content":"Google-SRE教程 ","date":"2021-06-04","objectID":"/links/:0:0","series":null,"tags":[],"title":"学习资料","uri":"/links/#"},{"categories":[],"content":"wiki–运维文档 此社区目的有两点： 1.共同整理出标准文档，进行持续维护，方便大家查阅使用 2.一起研究出一些东西出来，推动国内的运维技术发展 ","date":"2021-06-04","objectID":"/links/:0:1","series":null,"tags":[],"title":"学习资料","uri":"/links/#wiki--运维文档httpswww52wikicn"},{"categories":[],"content":"K8s训练营 阳明的博客 GO example 中文版 鸟哥的Linux私房菜 ","date":"2021-06-04","objectID":"/links/:0:2","series":null,"tags":[],"title":"学习资料","uri":"/links/#k8s训练营httpswwwqikqiakcom"},{"categories":[],"content":" 感谢 @Ryan4Yin 提供的友链页面模板~ LoveIt主题菜单栏标签参考（https://zhaouncle.com） 在友链形成的网络中漫游，是一件很有意思的事情。 以前的人们通过信笺交流，而我们通过友链串联起一个「世界」。希望你我都能在这个「世界」中有所收获 注： 下方友链次序每次刷新页面随机排列。 ","date":"2021-05-31","objectID":"/friends/:0:0","series":null,"tags":[],"title":"友链","uri":"/friends/#"},{"categories":[],"content":"交换友链如果你觉得我的博客有些意思，而且也有自己的独立博客，欢迎与我交换友链~ 可通过 Issues 或者评论区提交友链申请，格式如下： 站点名称：Yuepu`s Blog 站点地址: https://pingyangblog.com/ 个人形象：https://pingyangblog.com/images/avatar.jpg 站点描述：不急，但是不停~ // 以下为样例内容，按照格式可以随意修改 var myFriends = [ [\"https://chee5e.space\", \"https://chee5e.space/images/avatar.jpg\", \"@芝士部落格\", \"有思想，也有忧伤和理想，芝士就是力量\"], [\"https://blog.k8s.li/\", \"/avatar.png\", \"@木子\", \"垃圾佬、搬砖社畜、运维工程师 0) { var rndNum = Math.floor(Math.random()*myFriends.length); var friendNode = document.createElement(\"li\"); var friend_link = document.createElement(\"a\"), friend_img = document.createElement(\"img\"), friend_name = document.createElement(\"h4\"), friend_about = document.createElement(\"p\") ; friend_link.target = \"_blank\"; friend_link.href = myFriends[rndNum][0]; friend_img.src=myFriends[rndNum][1]; friend_name.innerText = myFriends[rndNum][2]; friend_about.innerText = myFriends[rndNum][3]; friend_link.appendChild(friend_img); friend_link.appendChild(friend_name); friend_link.appendChild(friend_about); friendNode.appendChild(friend_link); targetList.appendChild(friendNode); myFriends.splice(rndNum, 1); } .linkpage ul { color: rgba(255,255,255,.15) } .linkpage ul:after { content: \" \"; clear: both; display: block } .linkpage li { float: left; width: 48%; position: relative; -webkit-transition: .3s ease-out; transition: .3s ease-out; border-radius: 5px; line-height: 1.3; height: 90px; display: block } .linkpage h3 { margin: 15px -25px; padding: 0 25px; border-left: 5px solid #51aded; background-color: #f7f7f7; font-size: 25px; line-height: 40px } .linkpage li:hover { background: rgba(230,244,250,.5); cursor: pointer } .linkpage li a { padding: 0 10px 0 90px } .linkpage li a img { width: 60px; height: 60px; border-radius: 50%; position: absolute; top: 15px; left: 15px; cursor: pointer; margin: auto; border: none } .linkpage li a h4 { color: #333; font-size: 18px; margin: 0 0 7px; padding-left: 90px } .linkpage li a h4:hover { color: #51aded } .linkpage li a h4, .linkpage li a p { cursor: pointer; white-space: nowrap; text-overflow: ellipsis; overflow: hidden; line-height: 1.4; margin: 0 !important; } .linkpage li a p { font-size: 12px; color: #999; padding-left: 90px } @media(max-width: 460px) { .linkpage li { width:97% } .linkpage ul { padding-left: 5px } } ","date":"2021-05-31","objectID":"/friends/:1:0","series":null,"tags":[],"title":"友链","uri":"/friends/#交换友链"},{"categories":null,"content":" 关于我 （ “曾以为走不出去的日子,现在都回不去了。”——村上春树 《且听风吟》） 保持独立思考，不急，但是不停。 昵称：乐谱 游戏：游戏热爱者，参与过MMORPG游戏《莽荒纪》（C++）的游戏模块开发和运维工作，也参与过H5游戏《九州幻境城》（lua）的服务端运维。 影视：看得最多的是动漫了，科幻、悬疑类型也很喜欢。 运动：跑步、游泳、登山。 编程语言： shell：工作语言。 Python：学习中。 曾经使用过但已经荒废的语言：Java|C++。 职业：运维工程师 目前主要以提升业务稳定性和服务响应为主的业务运维工作，目标是掌握python语言，成为运维开发工程师，并学习kubernetes，熟悉云原生技术圈，思考如何更好地利用这些技术优化基础设施，使基础设施能稳定高效地支撑业务不断成长。 理论基础：计算机网络和Linux 底层知识还很欠缺，数据结构和设计模式有时间可以看看，数据库、中间件等分布式原理知识知之甚少。还有太多需要补习的理论基础知识。 关于此博客 “对我来说，博客首先是一种知识管理工具，其次才是传播工具。我的技术文章，主要用来整理我还不懂的知识。我只写那些我还没有完全掌握的东西，那些我精通的东西，往往没有动力写。炫耀从来不是我的动机，好奇才是。\" ──阮一峰 目的是想让博客成为我在互联网世界的一张名片和一个入口。其实记录在哪里都能记录，现在移动端如此普及，但我更希望能创建一个统一的入口，能够对自己的所学所感进行思考和总结，使其以规范的方式展现出来。 注意事项博客中的内容说到底也只是我一家之言，我只能尽量去减少错漏，但不能保证内容的正确性！ 因此请带着批判的眼光看待本博客中的任何内容。 话外互联网浩如烟海，这个小站偏安一隅，如果它有幸被你发现，而且其中文字对你还有些帮助，那可真是太棒了！感谢有你~ ","date":"2021-05-27","objectID":"/about/:0:0","series":null,"tags":null,"title":"关于我","uri":"/about/#"},{"categories":null,"content":" 关于我 （ “曾以为走不出去的日子,现在都回不去了。”——村上春树 《且听风吟》） 保持独立思考，不急，但是不停。 昵称：乐谱 游戏：游戏热爱者，参与过MMORPG游戏《莽荒纪》（C++）的游戏模块开发和运维工作，也参与过H5游戏《九州幻境城》（lua）的服务端运维。 影视：看得最多的是动漫了，科幻、悬疑类型也很喜欢。 运动：跑步、游泳、登山。 编程语言： shell：工作语言。 Python：学习中。 曾经使用过但已经荒废的语言：Java|C++。 职业：运维工程师 目前主要以提升业务稳定性和服务响应为主的业务运维工作，目标是掌握python语言，成为运维开发工程师，并学习kubernetes，熟悉云原生技术圈，思考如何更好地利用这些技术优化基础设施，使基础设施能稳定高效地支撑业务不断成长。 理论基础：计算机网络和Linux 底层知识还很欠缺，数据结构和设计模式有时间可以看看，数据库、中间件等分布式原理知识知之甚少。还有太多需要补习的理论基础知识。 关于此博客 “对我来说，博客首先是一种知识管理工具，其次才是传播工具。我的技术文章，主要用来整理我还不懂的知识。我只写那些我还没有完全掌握的东西，那些我精通的东西，往往没有动力写。炫耀从来不是我的动机，好奇才是。\" ──阮一峰 目的是想让博客成为我在互联网世界的一张名片和一个入口。其实记录在哪里都能记录，现在移动端如此普及，但我更希望能创建一个统一的入口，能够对自己的所学所感进行思考和总结，使其以规范的方式展现出来。 注意事项博客中的内容说到底也只是我一家之言，我只能尽量去减少错漏，但不能保证内容的正确性！ 因此请带着批判的眼光看待本博客中的任何内容。 话外互联网浩如烟海，这个小站偏安一隅，如果它有幸被你发现，而且其中文字对你还有些帮助，那可真是太棒了！感谢有你~ ","date":"2021-05-27","objectID":"/about/:0:0","series":null,"tags":null,"title":"关于我","uri":"/about/#关于我"},{"categories":null,"content":" 关于我 （ “曾以为走不出去的日子,现在都回不去了。”——村上春树 《且听风吟》） 保持独立思考，不急，但是不停。 昵称：乐谱 游戏：游戏热爱者，参与过MMORPG游戏《莽荒纪》（C++）的游戏模块开发和运维工作，也参与过H5游戏《九州幻境城》（lua）的服务端运维。 影视：看得最多的是动漫了，科幻、悬疑类型也很喜欢。 运动：跑步、游泳、登山。 编程语言： shell：工作语言。 Python：学习中。 曾经使用过但已经荒废的语言：Java|C++。 职业：运维工程师 目前主要以提升业务稳定性和服务响应为主的业务运维工作，目标是掌握python语言，成为运维开发工程师，并学习kubernetes，熟悉云原生技术圈，思考如何更好地利用这些技术优化基础设施，使基础设施能稳定高效地支撑业务不断成长。 理论基础：计算机网络和Linux 底层知识还很欠缺，数据结构和设计模式有时间可以看看，数据库、中间件等分布式原理知识知之甚少。还有太多需要补习的理论基础知识。 关于此博客 “对我来说，博客首先是一种知识管理工具，其次才是传播工具。我的技术文章，主要用来整理我还不懂的知识。我只写那些我还没有完全掌握的东西，那些我精通的东西，往往没有动力写。炫耀从来不是我的动机，好奇才是。\" ──阮一峰 目的是想让博客成为我在互联网世界的一张名片和一个入口。其实记录在哪里都能记录，现在移动端如此普及，但我更希望能创建一个统一的入口，能够对自己的所学所感进行思考和总结，使其以规范的方式展现出来。 注意事项博客中的内容说到底也只是我一家之言，我只能尽量去减少错漏，但不能保证内容的正确性！ 因此请带着批判的眼光看待本博客中的任何内容。 话外互联网浩如烟海，这个小站偏安一隅，如果它有幸被你发现，而且其中文字对你还有些帮助，那可真是太棒了！感谢有你~ ","date":"2021-05-27","objectID":"/about/:0:0","series":null,"tags":null,"title":"关于我","uri":"/about/#关于此博客"},{"categories":null,"content":" 关于我 （ “曾以为走不出去的日子,现在都回不去了。”——村上春树 《且听风吟》） 保持独立思考，不急，但是不停。 昵称：乐谱 游戏：游戏热爱者，参与过MMORPG游戏《莽荒纪》（C++）的游戏模块开发和运维工作，也参与过H5游戏《九州幻境城》（lua）的服务端运维。 影视：看得最多的是动漫了，科幻、悬疑类型也很喜欢。 运动：跑步、游泳、登山。 编程语言： shell：工作语言。 Python：学习中。 曾经使用过但已经荒废的语言：Java|C++。 职业：运维工程师 目前主要以提升业务稳定性和服务响应为主的业务运维工作，目标是掌握python语言，成为运维开发工程师，并学习kubernetes，熟悉云原生技术圈，思考如何更好地利用这些技术优化基础设施，使基础设施能稳定高效地支撑业务不断成长。 理论基础：计算机网络和Linux 底层知识还很欠缺，数据结构和设计模式有时间可以看看，数据库、中间件等分布式原理知识知之甚少。还有太多需要补习的理论基础知识。 关于此博客 “对我来说，博客首先是一种知识管理工具，其次才是传播工具。我的技术文章，主要用来整理我还不懂的知识。我只写那些我还没有完全掌握的东西，那些我精通的东西，往往没有动力写。炫耀从来不是我的动机，好奇才是。\" ──阮一峰 目的是想让博客成为我在互联网世界的一张名片和一个入口。其实记录在哪里都能记录，现在移动端如此普及，但我更希望能创建一个统一的入口，能够对自己的所学所感进行思考和总结，使其以规范的方式展现出来。 注意事项博客中的内容说到底也只是我一家之言，我只能尽量去减少错漏，但不能保证内容的正确性！ 因此请带着批判的眼光看待本博客中的任何内容。 话外互联网浩如烟海，这个小站偏安一隅，如果它有幸被你发现，而且其中文字对你还有些帮助，那可真是太棒了！感谢有你~ ","date":"2021-05-27","objectID":"/about/:0:0","series":null,"tags":null,"title":"关于我","uri":"/about/#注意事项"},{"categories":null,"content":" 关于我 （ “曾以为走不出去的日子,现在都回不去了。”——村上春树 《且听风吟》） 保持独立思考，不急，但是不停。 昵称：乐谱 游戏：游戏热爱者，参与过MMORPG游戏《莽荒纪》（C++）的游戏模块开发和运维工作，也参与过H5游戏《九州幻境城》（lua）的服务端运维。 影视：看得最多的是动漫了，科幻、悬疑类型也很喜欢。 运动：跑步、游泳、登山。 编程语言： shell：工作语言。 Python：学习中。 曾经使用过但已经荒废的语言：Java|C++。 职业：运维工程师 目前主要以提升业务稳定性和服务响应为主的业务运维工作，目标是掌握python语言，成为运维开发工程师，并学习kubernetes，熟悉云原生技术圈，思考如何更好地利用这些技术优化基础设施，使基础设施能稳定高效地支撑业务不断成长。 理论基础：计算机网络和Linux 底层知识还很欠缺，数据结构和设计模式有时间可以看看，数据库、中间件等分布式原理知识知之甚少。还有太多需要补习的理论基础知识。 关于此博客 “对我来说，博客首先是一种知识管理工具，其次才是传播工具。我的技术文章，主要用来整理我还不懂的知识。我只写那些我还没有完全掌握的东西，那些我精通的东西，往往没有动力写。炫耀从来不是我的动机，好奇才是。\" ──阮一峰 目的是想让博客成为我在互联网世界的一张名片和一个入口。其实记录在哪里都能记录，现在移动端如此普及，但我更希望能创建一个统一的入口，能够对自己的所学所感进行思考和总结，使其以规范的方式展现出来。 注意事项博客中的内容说到底也只是我一家之言，我只能尽量去减少错漏，但不能保证内容的正确性！ 因此请带着批判的眼光看待本博客中的任何内容。 话外互联网浩如烟海，这个小站偏安一隅，如果它有幸被你发现，而且其中文字对你还有些帮助，那可真是太棒了！感谢有你~ ","date":"2021-05-27","objectID":"/about/:0:0","series":null,"tags":null,"title":"关于我","uri":"/about/#话外"},{"categories":[],"content":"hugo架构图hugo架构 \" hugo架构图 现在市面上的博客很多，如CSDN，博客园，简书等平台，可以直接在上面发表，用户交互做的好，写的文章百度也能搜索的到。缺点是比较不自由，会受到平台的各种限制和恶心的广告。 而自己购买域名和服务器，搭建博客的成本实在是太高了，不光是说这些购买成本，单单是花力气去自己搭这么一个网站，还要定期的维护它，对于我们大多数人来说，实在是没有这样的精力和时间。 那么就有第三种选择，直接在github page平台上托管我们的博客。这样就可以安心的来写作，又不需要定期维护，而且Hugo作为一个快速简洁的博客框架，用它来搭建博客真的非常容易。 ","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:0","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#"},{"categories":[],"content":"前言Hugo 是一个基于Go语言开发的静态博客框架，号称世界上最快的构建网站工具。本文是我在网上看的其他人的博客和一些up主的视频，通过他们的分享成功搭建好了的案例，在这里我也进行一次总结，方便以后使用。 ","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:1","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#前言"},{"categories":[],"content":"目的通过把博客文章的源代码托管到GitHub仓库，利用GitHub Actions for Hugo功能持续集成部署，利用GitHub Pages实现网站的发布和访问，生成一个自己专属的个人博客网站。 ","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:2","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#目的"},{"categories":[],"content":"流程及原理 本地新建文章，push到 Github仓库的 main分支。main分支存放博客文章的源码。 push 操作自动触发预先配置的Actions。 GitHub Action自动执行yml文件中的\"action\"，构建打包，推送至gh-pages分支。 通过 Github Pages生成的 URL 访问即可。 ","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:3","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#流程及原理"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—\u003eNew repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-\u003eSettings-\u003eSSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \u003cTHEMENAME\u003e\" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new \u003cSECTIONNAME\u003e/\u003cFILENAME\u003e.\u003cFORMAT\u003e\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#详细步骤"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#安装git和关联github"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#安装hugo"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#下载hugo"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#生成博客"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#下载主题"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#启动博客"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#写一篇文章"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#编译博客"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#推送到github"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#使用github-pages实现访问"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#使用github-action自动化部署"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#配置github_token"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#配置github-action"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#推送博客源码"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#修改pages源分支"},{"categories":[],"content":"详细步骤安装git和关联GitHub这里我选择的是在Linux上搭建的，所以可以直接通过yum一条命令就能实现安装Git，其他平台的安装就不赘述了，自行百度下吧。 安装git yum install -y git 创建GitHub账户和仓库 没账号的登录GitHub创建账号，有账号的直接登录账号，点击右上角的加号—New repository，创建一个仓库，名称必须为yourname.github.io, 其中yourname是你的github名称，按照这个规则创建才有用。点击Create repository完成创建。 本地Git关联远程的GitHub账户： 回到Linux中，用以下命令配置Github账户信息，用户名（Your Name）和邮箱（you@example.com）换成你自己的： git config --global user.email \"you@example.com\"； git config --global user.name \"Your Name\" 由于本地的 Git 仓库和 GitHub 仓库之间的传输是通过SSH加密的，所以我们需要配置验证信息,使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 输入命令之后，直接三个回车即可，默认不需要设置密码； 找到~/.ssh 的文件夹中的 id_rsa.pub 密钥，将内容全部复制： cat ~/.ssh/id_rsa.pub 回到GitHub中-Settings-SSH and GPG keys，新建SSH Key: New SSH key，填入刚刚复制的内容，粘贴到github的输入框中，点击Add SSH key即可保存本地的秘钥到github账号。 验证是否关联成功： [root@web-blog public]# ssh -T git@github.com You've successfully authenticated, but GitHub does not provide shell access 保存账号密码，避免每次pull、push操作都需要输入账号密码： git config --global credential.helper store 安装Hugo下载Hugo [root@web-blog ~]# wget https://github.com/gohugoio/hugo/releases/download/v0.80.0/hugo_0.80.0_Linux-64bit.tar.gz #解压后复制到bin目录 [root@web-blog ~]# tar -zxf hugo_0.80.0_Linux-64bit.tar.gz \u0026\u0026 cp hugo /use/local/bin #hugo version查看版本 [root@web-blog ~]# hugo version Hugo Static Site Generator v0.80.0-792EF0F4 linux/amd64 BuildDate: 2020-12-31T13:37:58Z 生成博客命令：hugo new site myblog myblog为博客的目录名，可以修改为你自己想取的名字。 [root@web-blog ~]# hugo new site myblog Congratulations! Your new Hugo site is created in /root/myblog. Just a few more steps and you're ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \"hugo new theme \" command. 2. Perhaps you want to add some content. You can add single files with \"hugo new /.\". 3. Start the built-in live server via \"hugo server\". Visit https://gohugo.io/ for quickstart guide and full documentation. 下载主题主题官网：https://themes.gohugo.io ，找到想要的主题，点进去，复制下载命令，我这里下载的是even主题，在myblog目录下： git clone https://github.com/olOwOlo/hugo-theme-even.git themes/even 主题被下载到站点目录myblog下的themes/even下。 启动博客下载完成之后需要把主题even下的./exampleSite/config.toml复制到站点根目录下，这个文件中有博客首页的一些配置项，如“关于”“标签”“分类”等的开关，设置为true或者把注释解开即可在博客上看到该项了。 为了测试文章排版效果，还需要把./exampleSite/content/下的所有文件复制到站点目录的content目录下： [root@web-blog myblog]# cp themes/even/exampleSite/config.toml ./ [root@web-blog myblog]# vim config.toml baseURL = \"https://example.com\" title = \"Your title\" themesDir = \"../..\" theme = \"even\" paginate = 8 [menu] [[menu.main]] identifier = \"home\" name = \"Home\" url = \"/\" weight = 1 [[menu.main]] identifier = \"tags\" name = \"Tags\" url = \"/tags/\" weight = 2 [[menu.main]] identifier = \"about\" name = \"About\" url = \"/about/\" weight = 3 #复制测试文本到站点目录 [root@web-blog myblog]# cp themes/even/exampleSite/content/* ./content [root@web-blog myblog]# ll content total 8 -rw-r--r-- 1 root root 486 May 13 17:02 about.md drwxr-xr-x 2 root root 4096 May 13 17:02 post 启动博客，在myblog目录下键入命令： [root@web-blog myblog]# hugo server Start building sites … | ZH-CN -------------------+-------- Pages | 8 Paginator pages | 0 Non-page files | 0 Static files | 38 Processed images | 0 Aliases | 1 Sitemaps | 1 Cleaned | 0 Built in 39 ms Watching for changes in /opt/myblog/{archetypes,content,data,layouts,static,themes} Watching for config changes in /opt/myblog/config.toml Environment: \"development\" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop 打开浏览器访问http://localhost:1313/，预览博客网页效果。按Ctrl+C可以停止服务。 写一篇文章 [root@web-blog myblog]# hugo new post/index.md /opt/myblog/content/post/index.md created 生成的 Markdown 文件在myblog/context/post目录下： [root@web-blog myblog]# vim /opt/myblog/content/post/index.md --- title: \"index\" date: 2021-03-30T15:56:50+08:00 draft: true --- 我们可以使用typora一类的Markdown编辑器编写好文章后再复制粘贴进去。 编译博客预览主题效果满意之后就可以编译了： [root@web-blog myblo","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:4","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#域名绑定"},{"categories":[],"content":"搭建遇到的问题hugo配置文件参数错误在本地使用hugo server命令进行本地编译预览时报错: WARN 2020/02/17 20:51:06 found no layout file for \"HTML\" for \"page\": You should create a template file which matches Hugo Layouts Lookup Rules for this combination. 意思为：“找不到用于“页面”的“ HTML”布局文件”。 原因是没有指定所使用的主题。由于hugo new site mysite新建出来的站点目录中，存放主题的目录名为“themes”，导致我以为hugo的站点配置文件config.toml里指定的主题键名为”themes“，而实际应该是“theme”才对，才能正常编译。 [root@web-blog myblog]# vim themes/even/exampleSite/config.toml baseURL = \"http://localhost:1313/\" languageCode = \"en\" defaultContentLanguage = \"en\" # en / zh-cn / ... (This field determines which i18n file to use) title = \"Even - A super concise theme for Hugo\" preserveTaxonomyNames = true enableRobotsTXT = true enableEmoji = true theme = \"even\" 编译成功访问页面没有文章显示使用hugo new post/index.md新建的文章，是以./archetypes/default.md为模板创建的，默认的draft的值为true，hugo在编译时会忽略所有draft为true的文章，导致编译成功访问站点时发现没有文章显示。 解决办法：文章中draft（草稿）的值需设置为false，或者去掉./archetypes/default.md文件中的draft参数 每次git push之后，刷新站点就显示404写完文章push到github上之后，再刷新站点会显示404，网页找不到。然后到github pages检查发现之前绑定的域名被清空了。 解决办法：需要在gh-pages.yaml文件中加上cname选项，值为自己的域名。 - name:Deployuses:peaceiris/actions-gh-pages@v3with:github_token:${{ secrets.ACCESS_TOKEN }}publish_dir:./publiccname:domain.com ","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:5","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#搭建遇到的问题"},{"categories":[],"content":"搭建遇到的问题hugo配置文件参数错误在本地使用hugo server命令进行本地编译预览时报错: WARN 2020/02/17 20:51:06 found no layout file for \"HTML\" for \"page\": You should create a template file which matches Hugo Layouts Lookup Rules for this combination. 意思为：“找不到用于“页面”的“ HTML”布局文件”。 原因是没有指定所使用的主题。由于hugo new site mysite新建出来的站点目录中，存放主题的目录名为“themes”，导致我以为hugo的站点配置文件config.toml里指定的主题键名为”themes“，而实际应该是“theme”才对，才能正常编译。 [root@web-blog myblog]# vim themes/even/exampleSite/config.toml baseURL = \"http://localhost:1313/\" languageCode = \"en\" defaultContentLanguage = \"en\" # en / zh-cn / ... (This field determines which i18n file to use) title = \"Even - A super concise theme for Hugo\" preserveTaxonomyNames = true enableRobotsTXT = true enableEmoji = true theme = \"even\" 编译成功访问页面没有文章显示使用hugo new post/index.md新建的文章，是以./archetypes/default.md为模板创建的，默认的draft的值为true，hugo在编译时会忽略所有draft为true的文章，导致编译成功访问站点时发现没有文章显示。 解决办法：文章中draft（草稿）的值需设置为false，或者去掉./archetypes/default.md文件中的draft参数 每次git push之后，刷新站点就显示404写完文章push到github上之后，再刷新站点会显示404，网页找不到。然后到github pages检查发现之前绑定的域名被清空了。 解决办法：需要在gh-pages.yaml文件中加上cname选项，值为自己的域名。 - name:Deployuses:peaceiris/actions-gh-pages@v3with:github_token:${{ secrets.ACCESS_TOKEN }}publish_dir:./publiccname:domain.com ","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:5","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#hugo配置文件参数错误"},{"categories":[],"content":"搭建遇到的问题hugo配置文件参数错误在本地使用hugo server命令进行本地编译预览时报错: WARN 2020/02/17 20:51:06 found no layout file for \"HTML\" for \"page\": You should create a template file which matches Hugo Layouts Lookup Rules for this combination. 意思为：“找不到用于“页面”的“ HTML”布局文件”。 原因是没有指定所使用的主题。由于hugo new site mysite新建出来的站点目录中，存放主题的目录名为“themes”，导致我以为hugo的站点配置文件config.toml里指定的主题键名为”themes“，而实际应该是“theme”才对，才能正常编译。 [root@web-blog myblog]# vim themes/even/exampleSite/config.toml baseURL = \"http://localhost:1313/\" languageCode = \"en\" defaultContentLanguage = \"en\" # en / zh-cn / ... (This field determines which i18n file to use) title = \"Even - A super concise theme for Hugo\" preserveTaxonomyNames = true enableRobotsTXT = true enableEmoji = true theme = \"even\" 编译成功访问页面没有文章显示使用hugo new post/index.md新建的文章，是以./archetypes/default.md为模板创建的，默认的draft的值为true，hugo在编译时会忽略所有draft为true的文章，导致编译成功访问站点时发现没有文章显示。 解决办法：文章中draft（草稿）的值需设置为false，或者去掉./archetypes/default.md文件中的draft参数 每次git push之后，刷新站点就显示404写完文章push到github上之后，再刷新站点会显示404，网页找不到。然后到github pages检查发现之前绑定的域名被清空了。 解决办法：需要在gh-pages.yaml文件中加上cname选项，值为自己的域名。 - name:Deployuses:peaceiris/actions-gh-pages@v3with:github_token:${{ secrets.ACCESS_TOKEN }}publish_dir:./publiccname:domain.com ","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:5","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#编译成功访问页面没有文章显示"},{"categories":[],"content":"搭建遇到的问题hugo配置文件参数错误在本地使用hugo server命令进行本地编译预览时报错: WARN 2020/02/17 20:51:06 found no layout file for \"HTML\" for \"page\": You should create a template file which matches Hugo Layouts Lookup Rules for this combination. 意思为：“找不到用于“页面”的“ HTML”布局文件”。 原因是没有指定所使用的主题。由于hugo new site mysite新建出来的站点目录中，存放主题的目录名为“themes”，导致我以为hugo的站点配置文件config.toml里指定的主题键名为”themes“，而实际应该是“theme”才对，才能正常编译。 [root@web-blog myblog]# vim themes/even/exampleSite/config.toml baseURL = \"http://localhost:1313/\" languageCode = \"en\" defaultContentLanguage = \"en\" # en / zh-cn / ... (This field determines which i18n file to use) title = \"Even - A super concise theme for Hugo\" preserveTaxonomyNames = true enableRobotsTXT = true enableEmoji = true theme = \"even\" 编译成功访问页面没有文章显示使用hugo new post/index.md新建的文章，是以./archetypes/default.md为模板创建的，默认的draft的值为true，hugo在编译时会忽略所有draft为true的文章，导致编译成功访问站点时发现没有文章显示。 解决办法：文章中draft（草稿）的值需设置为false，或者去掉./archetypes/default.md文件中的draft参数 每次git push之后，刷新站点就显示404写完文章push到github上之后，再刷新站点会显示404，网页找不到。然后到github pages检查发现之前绑定的域名被清空了。 解决办法：需要在gh-pages.yaml文件中加上cname选项，值为自己的域名。 - name:Deployuses:peaceiris/actions-gh-pages@v3with:github_token:${{ secrets.ACCESS_TOKEN }}publish_dir:./publiccname:domain.com ","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:5","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#每次git-push之后刷新站点就显示404"},{"categories":[],"content":"参考链接Hugo官网：https://gohugo.io/ Hugo中文网：https://www.gohugo.cn/hosting-and-deployment/hosting-on-github/ Hugo中文帮助手册：https://hugo.aiaide.com/ Github Action 官方文档 GitHub Actions 入门教程 ","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:6","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#参考链接"},{"categories":[],"content":"Git操作命令总结 git push git push 命用于从将本地的分支版本上传到远程并合并。命令格式如下： git push \u003c远程主机名\u003e \u003c本地分支名\u003e:\u003c远程分支名\u003e 如果本地分支名与远程分支名相同，则可以省略冒号： git push \u003c远程主机名\u003e \u003c本地分支名\u003e git push -f 覆盖远程GitHub仓库的代码，强制推送。主要是为了解决本地仓库内容和远程仓库不一致而导致的push失败报错的问题，（在正常的开发项目中一般不建议这样操作，因为会覆盖所有其他成员提交的代码，只保留你自己的，属于危险操作！）： git push -f origin master #强制推送到origin源 git push -u origin master #正常推送到origin源 git checkout -b main #创建main分支并切换到main分支 git remote -v #查看本地添加的源地址 添加主题：使用git添加子模块的方式添加主题源地址，信息保存在.gitmodule git submodule add https://github.com/halogenica/beautifulhugo.git themes/beautifulhugo ","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:7","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#git操作命令总结"},{"categories":[],"content":"2021.07.12更新因GitHub宣布从 2021 年 8 月 13 日开始，我们将在对 Git 操作进行身份验证时不再接受帐户密码，并将要求使用基于令牌的身份验证。所以本地使用Git操作时，原先使用的账号密码验证身份的方式将被弃用，改成 用户名+token 的方式。 解决方法：点击GitHub头像-\u003eSetting -\u003e Developer settings -\u003e Personal access tokens -\u003e Generate new token，生成一个新的令牌。注意：生成之后需要立马复制下来，因为秘钥只会出现一次。 回到Git，需要清除之前使用的账户名和密码： vim ~/.gitconfig # 或者 cat /etc/git/.gitconfig [credential] # helper = store 注释掉这一行 再使用git push操作，此时会弹出需要验证账户密码，账户填写GitHub账户名，密码填写刚刚生成的token令牌。push成功之后，使用git config --global credential.helper store保存账户和令牌，下次再push就不用再输入账户密码了。 ","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:8","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#20210712更新"},{"categories":[],"content":"2021.08.12更新：Github Actions自动部署Hugo到Gitee同时刷新Gitee Pages Gitee仓库填入公钥 将id_rsa.pub 填入gitee仓库-\u003e settings→Deploy keys→add personal public key中 Github仓库填入私钥 将id_rsa 填入github仓库-\u003e Settings→Secret→New repository secre 用于之后的程序环境配置访问，命名为GITEE_RSA_PRIVATE_KEY 增加Actions代码 在 .github/workflows/gh-pages.yml文件中新增以下代码： sync: #同步到gitee仓库 needs: deploy runs-on: ubuntu-latest steps: - name: Sync to Gitee uses: wearerequired/git-mirror-action@master env: SSH_PRIVATE_KEY: ${{ secrets.GITEE_RSA_PRIVATE_KEY }} with: # 来源仓库 source-repo: \"git@github.com:JohntunLiu/myblog.git\" # 目标仓库 destination-repo: \"git@gitee.com:JohntunLiu/JohntunLiu.git\" reload-pages: #加载gitee-pages needs: sync runs-on: ubuntu-latest steps: - name: Build Gitee Pages uses: yanglbme/gitee-pages-action@main with: # 注意替换为你的 Gitee 用户名 gitee-username: JohntunLiu # 注意在 Settings-\u003eSecrets 配置 GITEE_PASSWORD gitee-password: ${{ secrets.GITEE_PASSWORD }} # 注意替换为你的 Gitee 仓库，仓库名严格区分大小写，请准确填写，否则会出错 gitee-repo: JohntunLiu/JohntunLiu # 要部署的分支，默认是 master，若是其他分支，则需要指定（指定的分支必须存在） branch: gh-pages commit 提交之后即每次push都会同步代码至gitee仓库上。 ","date":"2021-05-27","objectID":"/setup-hugo-blog/:0:9","series":null,"tags":["搭建"],"title":"Hugo+GitHub Action+Github Pages搭建个人博客","uri":"/setup-hugo-blog/#20210812更新github-actions自动部署hugo到gitee同时刷新gitee-pages"}]